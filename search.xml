<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2019%2F01%2F19%2Fnginx%2F</url>
    <content type="text"><![CDATA[Nginx介绍&ensp;&ensp;&ensp;&ensp;Nginx（发音同 engine x）是一款轻量级的Web 服务器／反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，最初供俄国大型的入口网站及搜寻引擎Rambler（俄文：Рамблер）使用。 其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页伺服器中表现较好.目前中国大陆使用nginx网站用户有：新浪、网易、 腾讯,另外知名的微网志Plurk也使用nginx。 Nginx的优点 高并发量：根据官方给出的数据，能够支持高达 50,000 个并发连接数的响应 内存消耗少：处理静态文件，同样起web 服务，比apache 占用更少的内存及资源，所有它是轻量级的 简单稳定：配置简单，基本在一个conf文件中配置，性能比较稳定，可以7*24小时长时间不间断运行 模块化程度高：Nginx是高度模块化的设计，编写模块相对简单，包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter，支持 SSL 和 TLSSNI。 支持Rwrite重写规则：能够根据域名、URL的不同， 将HTTP请求分发到不同的后端服务器群组。 低成本：Nginx可以做高并发的负载均衡，且Nginx是开源免费的，如果使用F5等硬件来做负载均衡，硬件成本比较高。 支持多系统：Nginx代码完全用C语言从头写成，已经移植到许多体系结构和操作系统，包括：Linux、FreeBSD、Solaris、Mac OS X、AIX以及Microsoft Windows，由于Nginx是免费开源的，可以在各系统上编译并使用。 nginx的程序架构web服务相关的功能 虚拟主机（server） 支持 keep-alive 和管道连接 访问日志（支持基于日志缓冲提高其性能） url rewirte 路径别名 基于IP及用户的访问控制 支持速率限制及并发数限制 重新配置和在线升级而无须中断客户的工作进程 Memcached 的 GET 接口 master/worker结构 一个master进程： ​ 负载加载和分析配置文件、管理worker进程、平滑升级 一个或多个worker进程 ​ 处理并响应用户请求 缓存相关的进程： ​ cache loader：载入缓存对象​ cache manager：管理缓存对象 nginx模块&ensp;&ensp;&ensp;&ensp;nginx高度模块化，但其模块早期不支持DSO机制；1.9.11版本支持动态装载和卸载 模块分类 核心模块：是 Nginx 服务器正常运行 必不可少 的模块，提供 错误日志记录 、配置文件解析 、 事件驱动机制 、 进程管理 等核心功能 标准HTTP模块：提供 HTTP 协议解析相关的功能，比如： 端口配置 、 网页编码设置 、 HTTP响应头设置 等等 可选HTTP模块：主要用于扩展标准的 HTTP 功能，让 Nginx 能处理一些特殊的服务，比如： Flash 多媒体传输 、解析 GeoIP 请求、 网络传输压缩 、 安全协议 SSL 支持等 邮件服务模块：主要用于支持 Nginx 的 邮件服务 ，包括对 POP3 协议、IMAP 协议和 SMTP协议的支持 第三方模块：是为了扩展 Nginx 服务器应用，完成开发者自定义功能，比如：Json 支持、 Lua 支持等 nginx的功用 静态的web资源服务器 ​ html，图片，js，css，txt等静态资源 结合FastCGI/uWSGI/SCGI等协议反向代理动态资源请求 http/https协议的反向代理 imap4/pop3协议的反向代理 tcp/udp协议的请求转发（反向代理） 配置文件的组成部分 主配置文件：nginx.conf 子配置文件 include conf.d/*.conf fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 主程序文件：/usr/sbin/nginx​ Unit File：nginx.service nginx配置主配置文件的配置指令​ directive value [value2 …]; 注意：(1) 指令必须以分号结尾(2) 支持使用配置变量​ 内建变量：由Nginx模块引入，可直接引用​ 自定义变量：由用户使用set命令定义​ set variable_name value;​ 引用变量：$variable_name 主配置文件结构：四部12345678910111213141516main block：主配置段，即全局配置段，对http,mail都有效 event &#123; ... &#125; #事件驱动相关的配置 http &#123; ... &#125; #http/https 协议相关配置段 mail &#123; ... &#125; #mail 协议相关配置段 stream &#123; ... &#125; #stream 服务器相关配置段 Main 全局配置段常见的配置指令分类 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置1、user 指定worker进程的运行身份，如组不指定，默认和用户名同名 ​ Syntax: user user [group];​ Default: user nobody nobody;​ Context: main 2、pid /PATH/TO/PID_FILE;指定存储nginx主进程进程号码的文件路径； 3、include file | mask;指明包含进来的其它配置文件片断； 4、load_module file;指明要装载的动态模块； 性能优化相关的配置1、worker_processes number | auto;​ worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数；​ auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask …;​ worker_cpu_affinity auto [cpumask];提高缓存命中率​ CPU MASK：​ 00000000：​ 0000 0001：0号CPU​ 0000 0010：1号CPU​ 0000 0100：2号CPU​ … …​ 0000 0011：0和1号CPU；3、worker_priority number;​ 指定worker进程的nice值，设定worker进程优先级；[-20,20] 4、worker_rlimit_nofile number;​ worker进程所能够打开的文件数量上限； 调试、定位问题1、daemon on|off;​ 是否以守护进程方式运行Nignx； 2、master_process on|off;​ 是否以master/worker模型运行nginx；默认为on； 3、error_log file [level]; 事件驱动相关的配置123events &#123; ...&#125; ​1、worker_connections number;​ 每个worker进程所能够打开的最大并发连接数数量；​​ worker_processes * worker_connections​2、use method;​ 指明并发连接请求的处理方法；​​ 示例: use epoll;​3、accept_mutex on | off;​ 处理新的连接请求的方法；on意味着由各worker轮流处理新请求，Off意味着每个新请求的到达都会通知所有的worker进程； http协议相关的配置结构1234567891011121314151617181920http &#123; ... ... #各server的全局配置 server &#123; ... &#125; #每个server用于定义一个虚拟主机； server &#123; ... listen server_name root alias location [OPERATOR] URL &#123; ... if CONDITION &#123; ... &#125; &#125; &#125;&#125; ngx_http_core_module与套接字相关的配置1、server { … }​ 配置一个虚拟主机； 12345server &#123; listen address[:PORT]|PORT; server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; &#125; 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE​ listen address[:port][default_server] [ssl][http2 | spdy] [backlog=number][rcvbuf=size] [sndbuf=size] ​ default_server：设定为默认虚拟主机；​ ssl：限制仅能够通过ssl连接提供服务；​ backlog=number：后援队列长度；​ rcvbuf=size：接收缓冲区大小；​ sndbuf=size：发送缓冲区大小； 3、server_name name …;​ 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串；​ 支持通配任意长度的任意字符；server_name .magedu.com www.magedu.*​ 支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+.magedu.com$ 12345匹配机制： (1) 首先是字符串精确匹配; (2) 左侧*通配符； (3) 右侧*通配符； (4) 正则表达式； 定义路径相关的配置：1、root path;设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径；可用的位置：http, server, location, if in location； 2、location [ = | ~ | ~* | ^~ ] uri { … } 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； 123456789101112=：对URI做精确匹配； location = / &#123; ... &#125;例如, http://www.magedu.com/ 匹配http://www.magedu.com/index.html 不匹配~：对URI做正则表达式模式匹配，区分字符大小写；~*：对URI做正则表达式模式匹配，不区分字符大小写；^~：对URI的左半部分做匹配检查，不区分字符大小写；不带符号：以URI为前缀的所有uri； 匹配优先级从高到低：=, ^~, ～/～*，不带符号； 例： 1234567891011121314151617181920212223242526272829303132333435[root@node01 ~]#vim /etc/nginx/nginx.conf # for more information. include /etc/nginx/conf.d/*.conf; server &#123; listen 8080; server_name node01; # root "/ngx/html"; location / &#123; root "/web/nginx/html"; &#125; location /images/ &#123; root "/ngx/html"; &#125; &#125;[root@node01 ~]#mkdir /ngx/html -pv[root@node01 ~]#vim /ngx/html/index.html &lt;h1&gt;node01&lt;/h1&gt; [root@node01 ~]#mkdir /web/nginx/html -pv[root@node01 html]#vim index.html &lt;h1&gt;This is new node01&lt;/h1&gt;[root@node01 ~]#mkdir /ngx/html/images[root@node01 ~]#vim /ngx/html/images/index.html /ngx/html/images/index.html [root@node01 ~]#mkdir /web/nginx/html/images[root@node01 ~]#vim /web/nginx/html/images/index.html /web/nginx/html/images/index.html[root@node01 ~]#curl 192.168.183.148:8080 &lt;h1&gt;This is new node01&lt;/h1&gt;如果把root "/web/nginx/html";注释掉[root@node01 ~]#curl 192.168.183.148:8080&lt;h1&gt;node01&lt;/h1&gt; [root@node01 ~]#curl 192.168.183.148:8080/images//ngx/html/images/index.html 3、alias path;&ensp;&ensp;&ensp;&ensp;定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同；​ (a) root，给定的路径对应于location中的/uri/左侧的/；​ (b) alias，给定的路径对应于location中的/uri/右侧的/； 例 1234567891011121314151617181920212223[root@node01 ~]#vim /etc/nginx/nginx.conf # for more information. include /etc/nginx/conf.d/*.conf; server &#123; listen 8080; server_name node01; # root "/ngx/html"; location /images/ &#123; alias "/ngx/html/"; &#125; &#125;[root@node01 ~]#mkdir /ngx/html -pv[root@node01 ~]#vim /ngx/html/index.html &lt;h1&gt;node01&lt;/h1&gt;[root@node01 ~]#mkdir /ngx/html/images[root@node01 ~]#vim /ngx/html/images/index.html /ngx/html/images/index.html结论：[root@node01 ~]#curl 192.168.183.148:8080/images/&lt;h1&gt;node01&lt;/h1&gt;如果把alias "/ngx/html/";换成root "/ngx/html/";[root@node01 ~]#curl 192.168.183.148:8080/images//ngx/html/images/index.html 4、index file ...;​ 默认资源；http, server, location； 5、error_page code ... [=[response]] uri; 1234error_page 404 /404.html; location = /404.html &#123; root "/www/error_pages"; &#125; 6、try_files file ... uri; ​ try_files file ... =code;按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如果所有文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误 123456location /images/ &#123; try_files $uri /images/default.gif;&#125; #说明：/images/default.gif是URIlocation / &#123; try_files $uri $uri/index.html $uri.html =404;&#125; 定义客户端请求的相关配置1、keepalive_timeout timeout [header_timeout];​ 设定保持连接超时时长，0表示禁止长连接，默认为75s2、keepalive_requests number;​ 在一次长连接上所允许请求的资源的最大数量，默认为1003、keepalive_disable none | browser ...;​ 对哪种浏览器禁用长连接4、send_timeout time;​ 向客户端发送响应报文的超时时长，此处是指两次写操作之间的间隔时长，而非整个响应过程的传输时长 5、client_body_buffer_size size;​ 用于接收每个客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由下面client_body_temp_path指令所定义的位置6、client_body_temp_path path [level1 [level2 [level3]]];​ 设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量目录名为16进制的数字； 1234client_body_temp_path /var/tmp/client_body 1 2 21 1级目录占1位16进制，即2^4=16个目录 0-f2 2级目录占2位16进制，即2^8=256个目录 00-ff2 3级目录占2位16进制，即2^8=256个目录 00-ff 对客户端进行限制的相关配置1、 limit_rate rate;​ 限制响应给客户端的传输速率，单位是bytes/second,默认值0表示无限制2、limit_except method … { … }，仅用于location限制客户端使用除了指定的请求方法之外的其它方法method:GET, HEAD, POST, PUT, DELETE，MKCOL, COPY, MOVE,OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH 1234limit_except GET &#123; allow 192.168.1.0/24; deny all;&#125;#除了GET之外其它方法仅允许192.168.1.0/24网段主机使用 文件操作优化的配置1、 aio on | off | threads[=pool];​ 是否启用aio功能2、 directio size | off;​ 当文件大于等于给定大小时，例如directio 4m，同步（直接）写磁盘，而非写缓存3、 open_file_cache off; 1open_file_cache max=N [inactive=time]; nginx可以缓存以下三种信息：​ 文件元数据：文件的描述符、文件大小和最近一次的修改时间​ 打开的目录结构​ 没有找到的或者没有权限访问的文件的相关信息​ max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现管理​ inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于 open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项，将被删除 4、 open_file_cache_errors on | off;​ 是否缓存查找时发生错误的文件一类的信息,默认值为off5、 open_file_cache_min_uses number;open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项,默认值为16、 open_file_cache_valid time;​ 缓存项有效性的检查频率,默认值为60s ngx_http_access_module&ensp;&ensp;&ensp;&ensp;可实现基于ip的访问控制功能 1、 allow address | CIDR | unix: | all;2、 deny address | CIDR | unix: | all;​ http, server, location, limit_except​ 自上而下检查，一旦匹配，将生效，条件严格的置前示例： 1234567location / &#123; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all;&#125; ngx_http_auth_basic_module&ensp;&ensp;&ensp;&ensp;实现基于用户的访问控制，使用basic机制进行用户认证1、 auth_basic string | off;2、 auth_basic_user_file file; 1234location /admin/ &#123;auth_basic "Admin Area";auth_basic_user_file /etc/nginx/.ngxpasswd;&#125; 用户口令文件：1、明文文本：格式name:password:comment2、加密文本：由htpasswd命令实现​ httpd-tools所提供 ngx_http_stub_status_module&ensp;&ensp;&ensp;&ensp;用于输出nginx的基本状态信息1、输出信息示例： 12345[root@node01 ~]#curl -s 192.168.183.148:8080/nginx_statusActive connections: 1 server accepts handled requests 111 111 114 Reading: 0 Writing: 1 Waiting: 0 Active connections:当前状态，活动状态的连接数 accepts：统计总值，已经接受的客户端请求的总数 handled：统计总值，已经处理完成的客户端请求的总数 requests：统计总值，客户端发来的总的请求数 Reading：当前状态，正在读取客户端请求报文首部的连接的连接数 Writing：当前状态，正在向客户端发送响应报文过程中的连接数 Waiting：当前状态，正在等待客户端发出请求的空闲连接数 示例： 123location /nginx_status &#123; stub_status;&#125; ngx_http_log_module&ensp;&ensp;&ensp;&ensp;指定日志格式记录请求1、 log_format name string …;string可以使用nginx核心模块及其它模块内嵌的变量2、 access_log path [format [buffer=size] [gzip[=level]][flush=time][if=condition]];​ access_log off;​ 访问日志文件路径，格式及相关的缓冲的配置​ buffer=size​ flush=time示例 123llog_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; 3、open_log_file_cache max=N [inactive=time][min_uses=N][valid=time]; open_log_file_cache off;​ 缓存各日志文件相关的元数据信息 ​ max：缓存的最大文件描述符数量 ​ min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项 ​ inactive：非活动时长 ​ valid：验证缓存中各缓存项是否为活动项的时间间隔 4、 open_log_file_cache max=N [inactive=time][min_uses=N][valid=time];open_log_file_cache off; 缓存各日志文件相关的元数据信息​ max：缓存的最大文件描述符数量​ min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项​ inactive：非活动时长​ valid：验证缓存中各缓存项是否为活动项的时间间隔 ngx_http_gzip_module1、ngx_http_gzip_module​ 用gzip方法压缩响应数据，节约带宽2、 gzip on | off;​ 启用或禁用gzip压缩3、 gzip_comp_level level;​ 压缩比由低到高：1 到 9,默认：14、 gzip_disable regex …;​ 匹配到客户端浏览器不执行压缩5、 gzip_min_length length;​ 启用压缩功能的响应报文大小阈值6、 gzip_http_version 1.0 | 1.1;​ 设定启用压缩功能时，协议的最小版本,默认：1.17、 gzip_buffers number size;​ 支持实现压缩功能时缓冲区数量及每个缓存区的大小,默认：32 4k 或 16 8k8、 gzip_types mime-type …;​ 指明仅对哪些类型的资源执行压缩操作；即压缩过滤器,默认包含有text/html，不用显示指定，否则出错9、 gzip_vary on | off;​ 如果启用压缩，是否在响应报文首部插入“Vary: Accept-Encoding”10、 gzip_proxied off | expired | no-cache | no-store | private |no_last_modified | no_etag | auth | any …;​ nginx充当代理服务器时，对于后端服务器的响应报文，在何种条件下启用压缩功能​ off：不启用压缩​ expired，no-cache, no-store，private：对后端服务器的响应报文首部​ Cache-Control值任何一个，启用压缩功能示例： 12345gzip on;gzip_comp_level 6;gzip_min_length 64;gzip_proxied any;gzip_types text/xml text/css application/javascript; ngx_http_ssl_module1、 ssl on | off;​ 为指定虚拟机启用HTTPS protocol， 建议用listen指令代替2、 ssl_certificate file;​ 当前虚拟主机使用PEM格式的证书文件3、 ssl_certificate_key file;​ 当前虚拟主机上与其证书匹配的私钥文件4、 ssl_protocols [SSLv2][SSLv3] [TLSv1][TLSv1.1] [TLSv1.2];支持ssl协议版本，默认为后三个5、 ssl_session_cache off | none | [builtin[:size]][shared:name:size];​ none: 通知客户端支持ssl session cache，但实际不支持​ builtin[:size]：使用OpenSSL内建缓存，为每worker进程私有​ [shared:name:size]：在各worker之间使用一个共享的缓存6、 ssl_session_timeout time;​ 客户端连接可以复用ssl session cache中缓存的有效时长，默认5m示例： 12345678910server &#123; listen 443 ssl; server_name www.magedu.com; root /vhosts/ssl/htdocs; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m;&#125; ngx_http_rewrite_module&ensp;&ensp;&ensp;&ensp;将用户请求的URI基于PCRE regex所描述的模式进行检查，而后完成重定向替换 1、 rewrite regex replacement [flag]将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查隐含有循环机制,但不超过10次；如果超过，提示500响应码，[flag]所表示的标志位用于控制此循环机制如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端, 即永久重定向301 [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环，不建议在location中使用 break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环，建议在location中使用 redirect：临时重定向，重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；使用相对路径,或者http://或https://开头，状态码：302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求，状态码：301 12345678910111213141516171819202122232425262728示例：把本地192.168.183.148:8080/以bbs或forum开头的都跳转到192.168.183.148:10080/forum下[root@node01 ~]#vim /etc/nginx/nginx.confserver &#123; listen 8080; server_name node01;# root "/ngx/html"; location / &#123; root "/web/nginx/html"; &#125; location ~* ^/(bbs|forum) &#123; rewrite ^/(bbs|forum)/(.*)$ http://192.168.183.148:10080/$2; &#125; &#125; server &#123; server_name forum.magedu.com; listen 10080; root "/web/nginx/forum"; &#125;[root@node01 html]#ll /web/nginx/total 0drwxr-xr-x 2 root root 24 Jan 10 09:34 forumdrwxr-xr-x 5 root root 62 Jan 10 09:46 html[root@node01 html]#ll /web/nginx/html/total 2drwxr-xr-x 2 root root 6 Jan 10 09:46 bbsdrwxr-xr-x 2 root root 24 Jan 10 09:22 forum 2、 rewrite_log on | off;是否开启重写日志, 发送至error_log（notice level） ngx_http_referer_module&ensp;&ensp;&ensp;&ensp;用来阻止Referer首部无有效值的请求访问，可防止盗链 1、 valid_referers none|blocked|server_names|string …;定义referer首部的合法可用值，不能匹配的将是非法值​ none：请求报文首部没有referer首部​ blocked：请求报文有referer首部，但无有效值​ server_names：referer首部中包含本主机名​ arbitrary_string：任意字符串，但可使用*作通配符​ regular expression：被指定的正则表达式模式匹配到的字符串,要使用~开头 12345示例：valid_referers none block server_names *.magedu.com;if ($invalid_referer) &#123; return 403 http://www.magedu.com;&#125; ngx_http_proxy_module&ensp;&ensp;&ensp;&ensp;转发请求至另一台主机 1、proxy_pass URL;​ Context: location, if in location, limit_except​ 注意：proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； 12345678910server &#123; listen 80; server_name HOSTNAME; location /uri/ &#123; proxy_pass http://hos[:port]; 最后没有/ &#125;&#125; 在客户端输入http://HOSTNAME/uri --&gt; http://host/uri proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri； ​ proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri 123456789server &#123; listen 80; server_name HOSTNAME; location /uri/ &#123; proxy_pass http://host/new_uri/; &#125;&#125; 在客户端输入http://HOSTNAME/uri/ --&gt; http://host/new_uri/ ​ 如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后； 123456789server &#123; listen 80; server_name HOSTNAME; location ~|~* /uri/ &#123; proxy http://host; 不能加/ &#125;&#125; http://HOSTNAME/uri/ --&gt; http://host/uri/； 2、proxy_set_header field value;​ 设定发往后端主机的请求报文的请求首部的值；Context: http, server, location 12proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 3、proxy_cache_path​ 定义可用于proxy功能的缓存；Context: http 1proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 4、 proxy_cache zone | off; 默认off&ensp;&ensp;&ensp;&ensp;指明调用的缓存，或关闭缓存机制；Context:http, server, location 5、 proxy_cache_key string;&ensp;&ensp;&ensp;&ensp;缓存中用于“键”的内容默认值：proxy_cache_key $scheme$proxy_host$request_uri; 6、 proxy_cache_valid [code …] time;&ensp;&ensp;&ensp;&ensp;定义对特定响应码的响应内容的缓存时长定义在http{…}中示例:​ proxy_cache_valid 200 302 10m;​ proxy_cache_valid 404 1m;​ ngx_http_proxy_module示例：在http配置定义缓存信息 123456789101112proxy_cache_path /var/cache/nginx levels=1:1:1 keys_zone=proxycache:20minactive=120s max_size=2G;说明：proxy_cache:20m 指内存中缓存的大小，主要用于存放key和metadata（如：使用次数）max_size=1g 指磁盘存入文件内容的缓存空间最大值调用缓存功能，需要定义在相应的配置段，如server&#123; proxy_cache proxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; proxy_cache_methods GET HEAD; &#125; 7、 proxy_cache_use_stale;proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...在被代理的后端服务器出现哪种情况下，可直接使用过期的缓存响应客户端 8、 proxy_cache_methods GET | HEAD | POST …;&ensp;&ensp;&ensp;&ensp;对哪些客户端请求方法对应的响应进行缓存，GET和HEAD方法总是被缓存 9、 proxy_hide_header field;&ensp;&ensp;&ensp;&ensp;默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad,X-Accel-等，用于隐藏后端服务器特定的响应首部 10、 proxy_connect_timeout time;&ensp;&ensp;&ensp;&ensp;定义与后端服务器建立连接的超时时长，如超时会出现502错误，默认为60s，一般不建议超出75s 11、 proxy_send_timeout time;&ensp;&ensp;&ensp;&ensp;将请求发送给后端服务器的超时时长；默认为60s 12、 proxy_read_timeout time;&ensp;&ensp;&ensp;&ensp;等待后端服务器发送响应报文的超时时长，默认为60s ngx_http_headers_module&ensp;&ensp;&ensp;&ensp;向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值 1、 add_header name value [always];添加自定义首部 123add_header X-Via $server_addr;add_header X-Cache $upstream_cache_status;add_header X-Accel $server_name; 2、 add_trailer name value [always];添加自定义响应信息的尾部 ngx_http_fastcgi_module&ensp;&ensp;&ensp;&ensp;转发请求到FastCGI服务器，不支持php模块方式 1、 fastcgi_pass address;address为后端的fastcgi server的地址可用位置：location, if in location 2、 fastcgi_index name;fastcgi默认的主页资源示例：fastcgi_index index.php; 3、 fastcgi_param parameter value [if_not_empty];设置传递给 FastCGI服务器的参数值，可以是文本，变量或组合例1：1）在后端服务器先配置fpm server和mariadb-server2）在前端nginx服务上做以下配置： 123456789101112location ~* \.php$ &#123; fastcgi_pass 172.17.0.3:9000 #后端fpm服务器IP:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /app/php$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; &#125; 例2：通过/pm_status和/ping来获取fpm server状态信息 123456 location ~* ^/(pm_status|ping)$ &#123; fastcgi_pass 后端fpm服务器IP:9000; (如：172.17.0.3:9000;) fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; &#125;在浏览器端输入http://192.168.83.148/ping 4123fastcgi_cache_path path [levels=levels][use_temp_path=on|off] keys_zone=name:size[inactive=time][max_size=size] [manager_files=number][manager_sleep=time][manager_threshold=time][loader_files=number] [loader_sleep=time][loader_threshold=time] [purger=on|off][purger_files=number] [purger_sleep=time][purger_threshold=time]; 定义fastcgi的缓存； 123456789path #缓存位置为磁盘上的文件系统max_size=size#磁盘path路径中用于缓存数据的缓存空间上限levels=levels：缓存目录的层级数量，以及每一级的目录数量示例： levels=1:2:2 keys_zone=name:size#k/v映射的内存空间的名称及大小inactive=time #非活动时长 5、 fastcgi_cache zone | off;调用指定的缓存空间来缓存数据可用位置：http, server, location 6、 fastcgi_cache_key string;定义用作缓存项的key的字符串示例：fastcgi_cache_key $request_rui; 7、 fastcgi_cache_methods GET | HEAD | POST …;为哪些请求方法使用缓存 8、 fastcgi_cache_min_uses number;缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项 9、 fastcgi_keep_conn on | off;收到后端服务器响应后，fastcgi服务器是否关闭连接，建议启用长连接 10、 fastcgi_cache_valid [code …] time;不同的响应码各自的缓存时长 例： 1234567891011121314151617181920http &#123; fastcgi_cache_path /var/cache/fcgi levels=1:2 keys_zone=fcgicache:20m inactive=120s max_size=2G;...server &#123;... location ~* \.php$ &#123; fastcgi_pass 172.17.0.3:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /appdata$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; ... &#125; &#125; &#125; ngx_http_upstream_module&ensp;&ensp;&ensp;&ensp;用于将多个服务器定义成服务器组，而由proxy_pass, fastcgi_pass等指令进行引用 1、 upstream name { … }&ensp;&ensp;&ensp;&ensp;定义后端服务器组，会引入一个新的上下文默认调度算法是wrrContext: http 12345upstream httpdsrvs &#123; server ...#172.17.0.4 [weight=2] server ...#172.17.0.10 ... &#125; 2、 server address [parameters];&ensp;&ensp;&ensp;&ensp;在upstream上下文中server成员，以及相关的参数；Context:upstreamaddress的表示格式：​ unix:/PATH/TO/SOME_SOCK_FILE​ IP[:PORT] ​ HOSTNAME[:PORT] parameters: ​ weight=number 权重，默认为1 ​ max_conns 连接后端报务器最大并发活动连接数，1.11.5后支持 max_fails=number 失败尝试最大次数；超出此处指定的次数时，server将被标 记为不可用,默认为1 ​ fail_timeout=time 后端服务器标记为不可用状态的连接超时时长，默认10s ​ backup 将服务器标记为“备用”，即所有服务器均不可用时才启用 ​ down 标记为“不可用”，实现灰度发布 1234567server &#123; listen 80; server_name www.magedu.com; location / &#123; proxy_pass http://httpdsrvs; &#125; &#125; 3、 ip_hash 源地址hash调度方法 4、 least_conn 最少连接调度算法，当server拥有不同的权重时其为wlc， ​ 当所有后端主机连接数相同时，则使用wrr，适用于长连接 5、 hash key [consistent] 基于指定的key的hash表来实现对请求的调度，此处的key可以直接文本、变量或二者组合​ 作用：将请求分类，同一类请求将发往同一个upstream server，使用consistent参数，将使用ketama一致性hash算法，适用于后端是Cache服务器（如varnish）时使用 12hash $request_uri consistent; #适用于缓存层hash $remote_addr; 6、 keepalive 连接数N;​ 为每个worker进程保留的空闲的长连接数量，可节约nginx端口，并减少连接管理的消耗一致性hash算法 7、 health_check [parameters];​ 健康状态检测机制；只能用于location上下文常用参数：​ interval=time检测的频率，默认为5秒​ fails=number：判定服务器不可用的失败检测次数；默认为1次​ passes=number：判定服务器可用的失败检测次数；默认为1次​ uri=uri：做健康状态检测测试的目标uri；默认为/​ match=NAME：健康状态检测的结果评估调用此处指定的match配置块 注意：仅对nginx plus有效 8、 match name { … }​ 对backend server做健康状态检测时，定义其结果判断机制；只能用于http上下文 常用的参数：​ status code[ code …]: 期望的响应状态码​ header HEADER[operator value]：期望存在响应首部，也可对期望的响应首部的值基于比较操作符和值进行比较​ body：期望响应报文的主体部分应该有的内容 注意：仅对nginx plus有效 ngx_stream_core_module&ensp;&ensp;&ensp;&ensp;模拟反代基于tcp或udp的服务连接，即工作于传输层的反代或调度 1、 stream { … }​ 定义stream相关的服务；Context:main 1234567891011stream &#123; upstream mysqlsrvs &#123; server 192.168.22.2:3306; server 192.168.22.3:3306; least_conn; &#125; server &#123; listen 10.1.0.6:3306; proxy_pass mysqlsrvs; &#125;&#125; 2、 listen 12345listen address:port [ssl] [udp] [proxy_protocol] [backlog=number] [bind][ipv6only=on|off] [reuseport][so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];listen address:port [ssl][udp] [proxy_protocol][backlog=number] [bind][ipv6only=on|off] [reuseport][so_keepalive=on|off|[keepidle]: keepintvl:keepcnt; ngx_stream_proxy_module可实现代理基于TCP，UDP (1.9.13), UNIX-domain sockets的数据流1、 proxy_pass address;​ 指定后端服务器地址2、 proxy_timeout timeout;​ 无数据传输时，保持连接状态的超时时长,默认为10m3、 proxy_connect_timeout time;​ 设置nginx与被代理的服务器尝试建立连接的超时时长,默认为60s示例 12345678910111213stream &#123; upstream mysqlsrvs &#123; server 172.17.0.6:3306; server 172.17.0.7:3306; hash $remote_addr consistent; &#125; server &#123; listen 3306; proxy_pass mysqlsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; &#125;&#125; 实现Nginx高并发Linux内核优化&ensp;&ensp;&ensp;&ensp;由于默认的Linux内核参数考虑的是最通用场景，这明显不符合用于支持高并发访问的Web服务器的定义，所以需要修改Linux内核参数，是的Nginx可以拥有更高的性能,根据业务特点来进行调整，当Nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，期内核参数的调整都是不同的，这里针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单的配置,修改/etc/sysctl.conf来更改内核参数 fs.file-max = 999999 ​ 表示单个进程较大可以打开的句柄数 net.ipv4.tcp_tw_reuse = 1 ​ 参数设置为 1 ，表示允许将TIME_WAIT状态的socket重新用于新的TCP链接，这对于服务器来说意义重大，因为总有大量TIME_WAIT状态的链接存在 net.ipv4.tcp_keepalive_time = 600 ​ 当keepalive启动时，TCP发送keepalive消息的频度；默认是2小时，将其设置为10分钟，可更快的清理无效链接 net.ipv4.tcp_fin_timeout = 30 ​ 当服务器主动关闭链接时，socket保持在FIN_WAIT_2状态的较大时间 net.ipv4.tcp_max_tw_buckets = 5000 ​ 这个参数表示操作系统允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息,默认为8000，过多的TIME_WAIT套接字会使Web服务器变慢 net.ipv4.ip_local_port_range = 1024 65000 ​ 定义UDP和TCP链接的本地端口的取值范围 net.ipv4.tcp_rmem = 10240 87380 12582912 ​ 定义了TCP接受缓存的最小值、默认值、较大值 net.ipv4.tcp_wmem = 10240 87380 12582912 ​ 定义TCP发送缓存的最小值、默认值、较大值 net.core.netdev_max_backlog = 8096 ​ 当网卡接收数据包的速度大于内核处理速度时，会有一个列队保存这些数据包。这个参数表示该列队的较大值 net.core.rmem_default = 6291456​ 表示内核套接字接受缓存区默认大小 net.core.wmem_default = 6291456​ 表示内核套接字发送缓存区默认大小 net.core.rmem_max = 12582912​ 表示内核套接字接受缓存区较大大小 net.core.wmem_max = 12582912​ 表示内核套接字发送缓存区较大大小注意：以上的四个参数，需要根据业务逻辑和实际的硬件成本来综合考虑 net.ipv4.tcp_syncookies = 1​ 与性能无关。用于解决TCP的SYN攻击 net.ipv4.tcp_max_syn_backlog = 8192​ 这个参数表示TCP三次握手建立阶段接受SYN请求列队的较大长度，默认1024，将其设置的大一些可使出现Nginx繁忙来不及accept新连接时，Linux不至于丢失客户端发起的链接请求 net.ipv4.tcp_tw_recycle = 1​ 这个参数用于设置启用timewait快速回收 net.core.somaxconn=262114​ 选项默认值是128，这个参数用于调节系统同时发起的TCP连接数，在高并发的请求中，默认的值可能会导致链接超时或者重传，因此需要结合高并发请求数来调节此值。 net.ipv4.tcp_max_orphans=262114​ 选项用于设定系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤立链接将立即被复位并输出警告信息。这个限制指示为了防止简单的DOS攻击，不用过分依靠这个限制甚至认为的减小这个值，更多的情况是增加这个值]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>模块</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis高可用与集群]]></title>
    <url>%2F2019%2F01%2F14%2Fredis%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[一：redis 高可用与集群&ensp;&ensp;&ensp;&ensp;虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦redis服务器本身出现系统故障、硬件故障等问题后，就会直接造成数据的丢失，因此需要使用另外的技术来解决单点问题。 1：配置reids 主从主备模式，可以实现Redis数据的跨主机备份。 &ensp;&ensp;&ensp;&ensp;程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server，此模式不需要在程序里面配置Redis服务器的真实IP地址，当后期Redis服务器IP地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的IP地址设置。 1.1：Slave主要配置&ensp;&ensp;&ensp;&ensp;Redis Slave 也要开启持久化并设置和master同样的连接密码，因为后期slave会有提升为master的可能,Slave端切换master同步后会丢失之前的所有数据。 一旦某个Slave成为一个master的slave，Redis Slave服务会清空当前redis服务器上的所有数据并将master的数据导入到自己的内存，但是断开同步关系后不会删除当前已经同步过的数据。 1.1.1：Slave的配置的两种方法1.1.1.1：修改配置文件123456789[root@slave-redis ~]#vim /etc/redis.conf bind 0.0.0.0 requirepass 123456 #可以给加上密码 slaveof 192.168.183.155 6379 masterauth 123456 #主要改上面四项 slave-read-only yes slave-serve-stale-data yes[root@slave-redis ~]#systemctl restart redis 1.1.1.2：命令行配置当前状态为master，需要转换为slave角色并指向master服务器的IP+PORT+Password123456[root@slave-redis ~]#redic-cli127.0.0.1:6379&gt; SLAVEOF 192.168.183.155 6379OK127.0.0.1:6379&gt; CONFIG SET masterauth 123456OK#上面是临时生效 1.1.2：同步日志1234567891011[root@slave-redis ~]#tail /var/log/redis/redis.log 4362:S 13 Jan 11:03:05.824 * Connecting to MASTER 192.168.183.155:63794362:S 13 Jan 11:03:05.824 * MASTER &lt;-&gt; SLAVE sync started4362:S 13 Jan 11:03:05.825 * Non blocking connect for SYNC fired the event.4362:S 13 Jan 11:03:05.826 * Master replied to PING, replication can continue...4362:S 13 Jan 11:03:05.838 * Partial resynchronization not possible (no cached master)4362:S 13 Jan 11:03:05.965 * Full resync from master: 50d58c28d9314edbf815581709bbe1aca05347fe:14362:S 13 Jan 11:03:05.965 * MASTER &lt;-&gt; SLAVE sync: receiving 102 bytes from master4362:S 13 Jan 11:03:05.965 * MASTER &lt;-&gt; SLAVE sync: Flushing old data4362:S 13 Jan 11:03:05.966 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory4362:S 13 Jan 11:03:05.966 * MASTER &lt;-&gt; SLAVE sync: Finished with success 1.1.3：当前slave状态1234567891011121314151617127.0.0.1:6379&gt; info Replication# Replicationrole:slavemaster_host:192.168.183.155master_port:6379master_link_status:upmaster_last_io_seconds_ago:8master_sync_in_progress:0slave_repl_offset:715slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 1.1.4：存配置到redis.conf：1234567891011121314127.0.0.1:6379&gt; config rewriteOK127.0.0.1:6379&gt; exit[root@slave-redis ~]#tail /etc/redis.conf hz 10# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes# Generated by CONFIG REWRITEslaveof 192.168.183.155 6379masterauth "123456" 1.1.5：重启slave验证12345678910111213141516171819[root@slave-redis ~]#systemctl restart redis[root@slave-redis ~]#redis-cli127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.183.155master_port:6379master_link_status:upmaster_last_io_seconds_ago:7master_sync_in_progress:0slave_repl_offset:1989slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 1.1.6：验证slave数据123127.0.0.1:6379&gt; keys *1) "key1"2) "key" 1.1.7：slave 状态只读无法写入数据12127.0.0.1:6379&gt; set key1 value1(error) READONLY You can't write against a read only slave. 1.1.8：Master日志1234567891011[root@master-redis ~]#tail /var/log/redis/redis.log 61981:M 13 Jan 11:03:05.913 * Synchronization with slave 192.168.183.154:6379 succeeded61981:M 13 Jan 11:20:32.391 # Connection with slave 192.168.183.154:6379 lost.61981:M 13 Jan 11:20:32.406 * Slave 192.168.183.154:6379 asks for synchronization61981:M 13 Jan 11:20:32.406 * Full resync requested by slave 192.168.183.154:637961981:M 13 Jan 11:20:32.406 * Starting BGSAVE for SYNC with target: disk61981:M 13 Jan 11:20:32.408 * Background saving started by pid 6464064640:C 13 Jan 11:20:32.410 * DB saved on disk64640:C 13 Jan 11:20:32.410 * RDB: 4 MB of memory used by copy-on-write61981:M 13 Jan 11:20:32.480 * Background saving terminated with success61981:M 13 Jan 11:20:32.480 * Synchronization with slave 192.168.183.154:6379 succeeded 1.1.9：主从复制过程&ensp;&ensp;&ensp;&ensp;Redis支持主从复制分为全量同步和增量同步，首次同步是全量同步，主从同步可以让从服务器从主服务器备份数据，而且从服务器还可与有从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的，其收到从服务器的sync(2.8版本之前是PSYNC)命令会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到一个缓冲区里面，bgsave执行完成之后并生成的将RDB文件发送给客户端，客户端将收到后的RDB文件载入自己的内存，然后主redis将缓冲区的内容在全部发送给从redis，之后的同步从服务器会发送一个offset的位置(等同于MySQL的binlog的位置)给主服务器，主服务器检查后位置没有错误将此位置之后的数据包括写在缓冲区的积压数据发送给redis从服务器，从服务器将主服务器发送的挤压数据写入内存，这样一次完整的数据同步，再之后再同步的时候从服务器只要发送当前的offset位 置给主服务器，然后主服务器根据响应的位置将之后的数据发送给从服务器保存到其内存即可。 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 1）从服务器连接主服务器，发送SYNC命令； 2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令； 3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步。 1.1.10：主从同步优化&ensp;&ensp;&ensp;&ensp;Redis在2.8版本之前没有提供增量部分复制的功能，当网络闪断或者slave Redis重启之后会导致主从之间的全量同步，即从2.8版本开始增加了部分复制的功能。 repl-diskless-sync no #yes为支持disk，master将RDB文件先保存到磁盘在发送给slave，no为maste直接将RDB文件发送给slave，默认即为使用no，Master RDB文件不需要与磁盘交互。 repl-diskless-sync-delay 5 #Master准备好RDB文件后等等待传输时间 repl-ping-slave-period 10 #slave端向server端发送pings的时间区间设置，默认为10秒 repl-timeout 60 #设置超时时间 repl-disable-tcp-nodelay no #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，前者关注性能，后者关注一致性 repl-backlog-size 1mb #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式：b repl-backlog-size = 允许从节点最大中断时长 主实例offset每秒写入量，比如master每秒最大写入64mb，最大允许60秒，那么就要设置为64mb60秒=3840mb(3.8G)= repl-backlog-ttl 3600 #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则表示永远不释放这部份内存。 slave-priority 100 #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。 min-slaves-to-write 0 # min-slaves-max-lag 10 #设置当一个master端的可用slave少于N个，延迟时间大于M秒时，不接收写操作。 Master的重启会导致master_replid发生变化，slave之前的master_replid就和master不一致从而会引发所有slave的全量同步。 1.1.11：slave切换master当前状态：1234567891011121314151617127.0.0.1:6379&gt; info Replication# Replicationrole:slavemaster_host:192.168.183.155master_port:6379master_link_status:upmaster_last_io_seconds_ago:7master_sync_in_progress:0slave_repl_offset:4694slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 停止slave同步并查看当前状态：1234567891011127.0.0.1:6379&gt; SLAVEOF no one #临时生效OK127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:0master_repl_offset:5184repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 测试能否写入数据：123127.0.0.1:6379&gt; set key3 value3OK127.0.0.1:6379&gt; #### 12 二：redis 集群&ensp;&ensp;&ensp;&ensp;上一个步骤的主从架构无法实现master和slave角色的自动切换，即当master出现redis服务异常、主机断电、磁盘损坏等问题导致master无法使用，而redis高可用无法实现自故障转移(将slave提升为master)，需要手动改环境配置才能切换到slave redis服务器，另外也无法横向扩展Redis服务的并行写入性能，当单台Redis服务器性能无法满足业务写入需求的时候就必须需要一种方式解决以上的两个核心问题，即： 1.master和slave角色的无缝切换，让业务无感知从而不影响业务使用 ； 2.可以横向动态扩展Redis服务器，从而实现多台服务器并行写入以实现更高并发的目的。 Redis 集群实现方式：客户端分片 代理分片 Redis Cluster 2.1：Sentinel(哨兵)&ensp;&ensp;&ensp;&ensp;Sentinel 进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用，其已经被集成在redis2.6+的版本中，Redis的哨兵模式到了2.8版本之后就稳定了下来。一般在生产环境也建议使用Redis的2.8版本的以后版本。哨兵(Sentinel) 是一个分布式系统，你可以在一个架构中运行多个哨兵(sentinel) 进程，这些进程使用流言协议(gossipprotocols)来接收关于Master主服务器是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master。 &ensp;&ensp;&ensp;&ensp;每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息，以确认对方是否”活”着，如果发现对方在指定配置时间(可配置的)内未得到回应，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” ，英文名称：Subjective Down，简称SDOWN。 &ensp;&ensp;&ensp;&ensp;当“哨兵群”中的多数Sentinel进程在对Master主服务器做出 SDOWN 的判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，这种方式就是“客观宕机”，英文名称是：Objectively Down， 简称 ODOWN。 &ensp;&ensp;&ensp;&ensp;通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务器节点，然后自动修改相关配置，并开启故障转移（failover）。 Sentinel 机制可以解决master和slave角色的切换问题。 2.1.1：配置redis主从服务器2.1.1.1：手动配置master需要手动先指定某一台Redis服务器为master，然后将其他slave服务器使用命令配置为master服务器的slave 1234[root@master-redis ~]#vim /etc/redis.conf bind 0.0.0.0 requirepass 123456[root@master-redis ~]#systemctl restart redis 2.1.1.2：服务器A配置slave123456789[root@slave-redis ~]#vim /etc/redis.conf bind 0.0.0.0 requirepass 123456 #可以给加上密码 slaveof 192.168.183.155 6379 masterauth 123456 #主要改上面四项 slave-read-only yes slave-serve-stale-data yes[root@slave-redis ~]#systemctl restart redis 2.1.1.3：服务器B配置slave12345678[root@slave1-redis ~]#vim /etc/redis.conf bind 0.0.0.0 requirepass 123456 slaveof 192.168.183.155 6379 masterauth 123456 slave-read-only yes slave-serve-stale-data yes[root@slave-redis ~]#systemctl restart redis 2.1.1.4：当前master状态123456789101112[root@master-redis ~]#redis-cli -a 123456127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.183.154,port=6379,state=online,offset=50562,lag=1slave1:ip=192.168.183.153,port=6379,state=online,offset=50997,lag=0master_repl_offset:50997repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:50996 2.1.2：编辑配置文件sentinel.conf2.1.2.1：master 配置哨兵可以不和Redis服务器部署在一起, 123456789[root@master-redis ~]#vim /etc/redis-sentinel.confbind 0.0.0.0port 26379sentinel monitor mymaster 192.168.183.155 6379 2sentinel auth-pass mymaster 123456sentinel down-after-milliseconds mymaster 30000 #(SDOWN)主观下线的时间sentinel parallel-syncs mymaster 1 #发生故障转移时候同时向新master同步数据的slave数量，数字越小总同步时间越长sentinel failover-timeout mymaster 180000 #所有slaves指向新的master所需的超时时间sentinel deny-scripts-reconfig yes 2.1.2.2：Slave 配置123456[root@slave-redis ~]#vim /etc/redis-sentinel.conf bind 0.0.0.0port 26379sentinel deny-scripts-reconfig yessentinel monitor mymaster 192.168.183.155 6379 2sentinel auth-pass mymaster 123456 2.1.2.3：Slave1配置123456[root@slave1-redis ~]#vim /etc/redis-sentinel.conf bind 0.0.0.0port 26379sentinel deny-scripts-reconfig yessentinel monitor mymaster 192.168.183.155 6379 2sentinel auth-pass mymaster 123456 2.1.2.4：启动哨兵三台哨兵都要启动 1[root@master-redis ~]#systemctl start redis-sentinel.service 2.1.2.3：验证端口1234[root@master-redis ~]#ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:26379 *:* LISTEN 0 128 *:6379 *:* 2.1.2.4：哨兵日志1234567891011[root@master-redis ~]#tail /var/log/redis/sentinel.log70507:X 13 Jan 16:58:43.089 # +sdown master mymaster 192.168.183.155 637970507:X 13 Jan 16:58:43.140 # +new-epoch 170507:X 13 Jan 16:58:43.144 # +vote-for-leader a1862470710ec770e8818de80d3a6b06f0fc9388 170507:X 13 Jan 16:58:43.147 # +odown master mymaster 192.168.183.155 6379 #quorum 3/270507:X 13 Jan 16:58:43.147 # Next failover delay: I will not start a failover before Sun Jan 13 17:04:43 201970507:X 13 Jan 16:58:44.272 # +config-update-from sentinel a1862470710ec770e8818de80d3a6b06f0fc9388 192.168.183.154 26379 @ mymaster 192.168.183.155 637970507:X 13 Jan 16:58:44.277 # +switch-master mymaster 192.168.183.155 6379 192.168.183.153 637970507:X 13 Jan 16:58:44.283 * +slave slave 192.168.183.154:6379 192.168.183.154 6379 @ mymaster 192.168.183.153 637970507:X 13 Jan 16:58:44.283 * +slave slave 192.168.183.155:6379 192.168.183.155 6379 @ mymaster 192.168.183.153 637970507:X 13 Jan 16:58:49.288 # +sdown slave 192.168.183.155:6379 192.168.183.155 6379 @ mymaster 192.168.183.153 6379 2.1.2.5：当前redis 状态1234567891011127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.183.154,port=6379,state=online,offset=717856,lag=0slave1:ip=192.168.183.153,port=6379,state=online,offset=717856,lag=0master_repl_offset:717856repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:717855 2.1.2.6：当前sentinel状态尤其是最后一行，涉及到master IP是多少，有几个slave，有几个sentinels，必须是符合全部服务器数量的。 12345678910[root@master-redis ~]#redis-cli -p 26379127.0.0.1:26379&gt; info Sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=mymaster,status=ok,address=192.168.183.155:6379,slaves=2,sentinels=3127.0.0.1:26379&gt; 2.1.2.7：停止Redis Master测试故障转移1[root@master-redis ~]#systemctl stop redis 查看master信息： 1234567891011127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.183.154,port=6379,state=online,offset=386953,lag=1master_repl_offset:387098repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:387097127.0.0.1:6379&gt; 查看哨兵信息： 12345678910[root@master-redis ~]#redis-cli -p 26379 127.0.0.1:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=mymaster,status=ok,address=192.168.183.153:6379,slaves=2,sentinels=3127.0.0.1:26379&gt; 故障转移时sentinel 的信息： 123456789101112131415161718192021[root@master-redis ~]#tail -n20 /var/log/redis/sentinel.log `-._ _.-' `-.__.-' 70507:X 13 Jan 16:54:22.693 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.70507:X 13 Jan 16:54:22.697 # Sentinel ID is 3f42cd492af4ace415ec11659d0f63a6bd806a6b70507:X 13 Jan 16:54:22.697 # +monitor master mymaster 192.168.183.155 6379 quorum 270507:X 13 Jan 16:54:22.698 * +slave slave 192.168.183.153:6379 192.168.183.153 6379 @ mymaster 192.168.183.155 637970507:X 13 Jan 16:54:22.699 * +slave slave 192.168.183.154:6379 192.168.183.154 6379 @ mymaster 192.168.183.155 637970507:X 13 Jan 16:54:23.453 * +sentinel sentinel a1862470710ec770e8818de80d3a6b06f0fc9388 192.168.183.154 26379 @ mymaster 192.168.183.155 637970507:X 13 Jan 16:54:33.026 * +sentinel sentinel 5f77dc65c6e8c44156418a64c4a8fa5da563a1cb 192.168.183.153 26379 @ mymaster 192.168.183.155 637970507:X 13 Jan 16:58:43.089 # +sdown master mymaster 192.168.183.155 637970507:X 13 Jan 16:58:43.140 # +new-epoch 170507:X 13 Jan 16:58:43.144 # +vote-for-leader a1862470710ec770e8818de80d3a6b06f0fc9388 170507:X 13 Jan 16:58:43.147 # +odown master mymaster 192.168.183.155 6379 #quorum 3/270507:X 13 Jan 16:58:43.147 # Next failover delay: I will not start a failover before Sun Jan 13 17:04:43 201970507:X 13 Jan 16:58:44.272 # +config-update-from sentinel a1862470710ec770e8818de80d3a6b06f0fc9388 192.168.183.154 26379 @ mymaster 192.168.183.155 637970507:X 13 Jan 16:58:44.277 # +switch-master mymaster 192.168.183.155 6379 192.168.183.153 637970507:X 13 Jan 16:58:44.283 * +slave slave 192.168.183.154:6379 192.168.183.154 6379 @ mymaster 192.168.183.153 637970507:X 13 Jan 16:58:44.283 * +slave slave 192.168.183.155:6379 192.168.183.155 6379 @ mymaster 192.168.183.153 637970507:X 13 Jan 16:58:49.288 # +sdown slave 192.168.183.155:6379 192.168.183.155 6379 @ mymaster 192.168.183.153 6379 2.1.2.8：故障转移后的redis配置文件故障转移后redis.conf中的replicaof行的master IP会被修改，sentinel.conf中的sentinel monitor IP会被修改。 123456789101112131415161718192021[root@slave-redis ~]#vim /etc/redis.conf# network partition slaves automatically try to reconnect to masters# and resynchronize with them.## slaveof &lt;masterip&gt; &lt;masterport&gt;slaveof 192.168.183.153 6379 #自动变成现在的masterip[root@slave-redis ~]#vim /etc/redis-sentinel.conf# Note that the master password is also used for slaves, so it is not# possible to set a different password in masters and slaves instances# if you want to be able to monitor these instances with Sentinel.## However you can have Redis instances without the authentication enabled# mixed with Redis instances requiring the authentication (as long as the# password set is the same for all the instances requiring the password) as# the AUTH command will have no effect in Redis instances with authentication# switched off.## Example:#sentinel monitor mymaster 192.168.183.153 6379 2 #这个也一样，自动变成新master ip 2.1.2.9：当前reids状态1234567891011121314151617181920[root@slave-redis ~]#redis-cli -a 123456127.0.0.1:6379&gt; info replication# Replicationrole:slavemaster_host:192.168.183.153master_port:6379master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:216328slave_priority:100slave_read_only:1connected_slaves:1slave0:ip=192.168.183.140,port=6379,state=online,offset=430638,lag=0master_repl_offset:431073repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:431072127.0.0.1:6379&gt; 2.2：Redis Cluster部署Redis cluster之前的分布式方案： 1) 客户端分区：由客户端程序决定key写分配和写入的redis node，但是需要客户端自己处理写入分配、高可用管理和故障转移等 2)代理方案：基于三方软件实现redis proxy，客户端先连接之代理层，由代理层实现key的写入分配，对客户端来说是有比较简单，但是对于集群管节点增减相对比较麻烦，而且代理本身也是单点和性能瓶颈。 &ensp;&ensp;&ensp;&ensp;在哨兵sentinel机制中，可以解决redis高可用的问题，即当master故障后可以自动将slave提升为master从而可以保证redis服务的正常使用，但是无法解决redis单机写入的瓶颈问题，即单机的redis写入性能受限于单机的内存大小、并发数量、网卡速率等因素，因此redis官方在redis 3.0版本之后推出了无中心架构的redis cluster机制，在无中心的redis集群汇中，其每个节点保存当前节点数据和整个集群状态,每个节点都和其他所有节点连接，特点如下： 1：所有Redis节点使用(PING-PING机制)互联 2：集群中某个节点的实效是整个集群中超过半数的节点监测都实效才算真正的实效 3：客户端不需要proxy即可直接连接redis，且客户端不需要连接集群中的所有节点，只要连接集群中的任何一个节点即可。 4：redis cluster把所有的redisnode映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上进行操作，因此有多少个reids node相当于redis 并发扩展了多少倍。 5：Redis集群预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候，会使用CRC16(key) mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上，从而有效解决单机瓶颈。​ 2.2.1：部署redis集群环境准备： 三台服务器，每台服务器启动6379端口，（192.168.183.155:6379 192.168.183.154:6379 192.168.183.153:6379 ） 2.2.1.1：创建redis cluster集群的前提：1.每个redis node节点采用相同的硬件配置、相同的密码 2.每个节点必须开启参数,设置配置文件，启用集群功能； 1234567[root@redis1 ~]#vim /etc/redis.confcluster-enabled #是否开启集群配置cluster-config-file #集群节点集群信息配置文件,每个节点都有一个,由redis生成和更新,配置时避免名称冲突cluster-node-timeout #集群节点互连超时的阈值，单位毫秒cluster-slave-validity-factor #进行故障转移时,salve会申请成为master。有时slave会和master失联很久导致数据较旧，这样的slave不应该成为master。这个配置用来判断slave是否和master失联时间过长。#以上四个参数都启用[root@redis1 ~]#systemctl start redis 2.2.1.2：启动redis后为每个节点分配slots； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@redis1 ~]#redis-cli -a 123456127.0.0.1:6379&gt; cluster infocluster_state:failcluster_slots_assigned:0cluster_slots_ok:0cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:1cluster_size:0cluster_current_epoch:0cluster_my_epoch:0cluster_stats_messages_sent:0cluster_stats_messages_received:0[root@redis1 ~]#redis-cli -c -h 192.168.183.155 -p 6379 -a 123456 cluster addslots &#123;0..5500&#125; OK[root@redis1 ~]#redis-cli -c -h 192.168.183.154 -p 6379 -a 123456 cluster addslots &#123;5501..11000&#125;OK[root@redis1 ~]#redis-cli -c -h 192.168.183.153 -p 6379 -a 123456 cluster addslots &#123;11001..16383&#125;OK[root@redis1 ~]#redis-cli -a 123456127.0.0.1:6379&gt; cluster infocluster_state:failcluster_slots_assigned:5501cluster_slots_ok:5501cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:1cluster_size:1cluster_current_epoch:0cluster_my_epoch:0cluster_stats_messages_sent:0cluster_stats_messages_received:0[root@redis2 ~]#redis-cli -a 123456127.0.0.1:6379&gt; cluster infocluster_state:failcluster_slots_assigned:5500cluster_slots_ok:5500cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:1cluster_size:1cluster_current_epoch:0cluster_my_epoch:0cluster_stats_messages_sent:0cluster_stats_messages_received:0[root@redis3 ~]#redis-cli -a 123456127.0.0.1:6379&gt; cluster infocluster_state:failcluster_slots_assigned:5383cluster_slots_ok:5383cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:1cluster_size:1cluster_current_epoch:0cluster_my_epoch:0cluster_stats_messages_sent:0cluster_stats_messages_received:0127.0.0.1:6379&gt; 2.2.1.3：设定集群成员关系；(CLUSTE MEET) 123456789101112131415161718192021127.0.0.1:6379&gt; CLUSTER MEET 192.168.183.154 6379OK127.0.0.1:6379&gt; CLUSTER MEET 192.168.183.153 6379OK127.0.0.1:6379&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:3cluster_size:3cluster_current_epoch:2cluster_my_epoch:2cluster_stats_messages_sent:57cluster_stats_messages_received:57127.0.0.1:6379&gt; set name tom(error) MOVED 5798 192.168.183.154:6379#在192.168.183.154上127.0.0.1:6379&gt; set name tomOK 2.3：redis扩展集群方案：除了Redis 官方自带的Redis cluster集群之外，还有一写开源的集群解决方案可供参考使用。 2.3.1：codis：&ensp;&ensp;&ensp;&ensp;Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有显著区别 (不支持的命令列表), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务。 &ensp;&ensp;&ensp;&ensp;codis-proxy相当于redis，即连接codis-proxy和连接redis是没有任何区别的，codis-proxy无状态，不负责记录是否在哪保存，数据在zookeeper记录，即codis proxy向zookeeper查询key的记录位置，proxy 将请求转发到一个组进行处理，一个组里面有一个master和一个或者多个slave组成，默认有1024个槽位，redis cluster 默认有16384个槽位，其把不同的槽位的内容放在不同的group。 Github 地址：https://github.com/CodisLabs/codis/blob/release3.2/doc/tutorial_zh.md 2.3.2：twemproxy：&ensp;&ensp;&ensp;&ensp;由Twemproxy代替客户端实现分片，即代替用户将数据分片并到不同的后端服务器进行读写，其还支持memcached，可以为proxy配置算法，缺点为twemproxy是瓶颈，不支持数据迁移，官方github地址https://github.com/twitter/twemproxy/ Github 地址：https://github.com/twitter/twemproxy 三：memcachedMemcache官网：http://memcached.org/ &ensp;&ensp;&ensp;&ensp;memcache本身没有像redis所具备的数据持久化功能，比如RDB和AOF都没有，但是可以通过做集群同步的方式，让各memcache服务器的数据进行同步，从而实现数据的一致性，即保证各memcache的数据是一样的，即使有任何一台或多台memcache发生故障，只要集群种有一台memcache可用就不会出现数据丢失，当其他memcache重新加入到集群的时候可以自动从有数据的memcache当中自动获取数据并提供服务。 &ensp;&ensp;&ensp;&ensp;Memcache借助了操作系统的libevent工具做高效的读写。libevent是个程序库，它将Linux的epoll、BSD类操作系统的kqueue等事件处理功能封装成统一的接口。即使对服务器的连接数增加，也能发挥高性能。memcached使用这个libevent库，因此能在Linux、BSD、Solaris等操作系统上发挥其高性能。 &ensp;&ensp;&ensp;&ensp;Memcache支持最大的内存存储对象为1M，超过1M的数据可以使用客户端压缩或拆分报错到做个key中，比较大的数据在进行读取的时候需要消耗的时间比较长，memcache最适合报错用户的session实现session共享，Memcached存储数据时, Memcached会去申请1MB的内存, 把该块内存称为一个slab, 也称为一个page。 memcached具有多种语言的客户端开发包，包括：Perl/PHP/JAVA/C/Python/Ruby/C#/ 3.1：单机部署：3.1.1：yum安装与启动：通过yum 安装是相对简单的安装方式 12345678910111213yum install memcached –yvim /etc/sysconfig/memcached PORT="11211" #监听端口 USER="memcached" #启动用户 MAXCONN="1024" #最大连接数 CACHESIZE="1024" #最大使用内存 OPTIONS="" #其他选项 3.1.2：编译安装：123456789101112131415yum install libevent libevent-devel –ypwd/usr/local/srctar xvf memcached-1.5.12.tar.gz./configure --prefix=/usr/local/memcachemake &amp;&amp; make install#启动memcached/usr/local/memcache/bin/memcached -u memcached -p 11211 -m 2048 -c 65536 &amp; 3.2：memcached集群部署架构：3.2.1：基于magent的部署架构：&ensp;&ensp;&ensp;&ensp;该部署方式依赖于magent实现高可用，应用端通过负载服务器连接到magent，然后再由magent代理用户应用请求到memcached处理，底层的memcached为双主结构会自动同步数据，本部署方式存在magent单点问题因此需要两个magent做高可用。 3.2.2：简化后的部署架构：&ensp;&ensp;&ensp;&ensp;但magent已经有很长时间没有更新，因此可以不再使用magent，直接通过负载均衡连接之memcached，任然有两台memcached做高可用，memcached会自动同步数据保持数据一致性，即使一台memcached故障也不影响业务正常运行，故障的memcached修复上线后再自动从另外一台同步数据即可保持数据一致性。 4.1.3：部署repcached http://repcached.sourceforge.net/]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础]]></title>
    <url>%2F2019%2F01%2F14%2Fredis%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一：缓存概念&ensp;&ensp;&ensp;&ensp;缓存是为了调节速度不一致的两个或多个不同的物质的速度，在中间对速度较快的一方起到一个加速访问速度较慢的一方的作用，比如CPU的一级、二级缓存是保存了CPU最近经常访问的数据，内存是保存CPU经常访问硬盘的数据，而且硬盘也有大小不一的缓存，甚至是物理服务器的raid 卡有也缓存，都是为了起到加速CPU 访问硬盘数据的目的，因为CPU的速度太快了，CPU需要的数据硬盘往往不能在短时间内满足CPU的需求，因此PCU缓存、内存、Raid 卡以及硬盘缓存就在一定程度上满足了CPU的数据需求，即CPU 从缓存读取数据可以大幅提高CPU的工作效率。 1.1：系统缓存1.1.1：buffer与cachebuffer：缓冲也叫写缓冲，一般用于写操作，可以将数据先写入内存在写入磁盘，buffer 一般用于写缓冲，用于解决不同介质的速度不一致的缓冲，先将数据临时写入到里自己最近的地方，以提高写入速度，CPU会把数据线写到内存的磁盘缓冲区，然后就认为数据已经写入完成看，然后内核的线程在后面的时间在写入磁盘，所以服务器突然断电会丢失内存中的部分数据。 cache：缓存也叫读缓存，一般用于读操作，CPU读文件从内存读，如果内存没有就先从硬盘读到内存再读到CPU，将需要频繁读取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。 1.1.2：cache的保存位置客户端：浏览器 内存：本地服务器、远程服务器 硬盘：本机硬盘、远程服务器硬盘 速度对比： 客户端浏览器-内存-远程内存-硬盘-远程硬盘。 1.2：CDN缓存1.2.1：CDN概念&ensp;&ensp;&ensp;&ensp;内容分发网络（Content Delivery Network），通过将服务内容分发至全网加速节点，利用全球调度系统使用户能够就近获取，有效降低访问延迟，提升服务可用性。 第一降低机房的使用带宽，因为很多资源通过CDN就直接返回用户了； 第二解决不同运营商之间的互联，因为可以让联通的网络访问联通，让电信的网络访问电信，起到加速用户访问的目的； 第三：解决用户访问的地域问题，就近返回用户资源。 百度CDN：https://cloud.baidu.com/product/cdn.html 阿里CDN：https://www.aliyun.com/product/cdn 腾讯CDN：https://www.qcloud.com/product/cdn 1.2.2：CDN主要优势&ensp;&ensp;&ensp;&ensp;提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，再其次的放在云存储，这样兼顾了速度与成本。缓存-缓存到最快的地方如内存，缓存的数据准确命中率高，访问速度就快 调度准确-将用户调度到最近的边缘节点 性能优化-CDN 专门用于缓存响应速度快 安全相关-抵御攻击 节省带宽：由于用户请求由边缘节点响应，因此大幅降低到源站带宽。 1.3：应用层缓存&ensp;&ensp;&ensp;&ensp;Nginx、PHP等web服务可以设置应用缓存以加速响应用户请求，另外有些解释性语言比如PHP/Python不能直接运行，需要先编译成字节码，但字节码需要解释器解释为机器码之后才能执行，因此字节码也是一种缓存，有时候会出现程序代码上线后字节码没有更新的现象。 1.4：其他层面缓存CPU缓存(L1的数据缓存和L1的指令缓存)、二级缓存、三级缓存 磁盘缓存 RAID卡 分布式缓存：redis、memcache 二：redis部署2.1.1：redis简介：&ensp;&ensp;&ensp;&ensp;Redis(Remote Dictionary Server)在2009年发布，开发者Salvatore Sanfilippo是意大利开发者，他本想为自己的公司开发一个用于替换MySQL的产品Redis，但是没有想到他把Redis开源后大受欢迎，短短几年，Redis就有了很大的用户群体，目前国内外使用的公司有知乎网、新浪微博、GitHub等 &ensp;&ensp;&ensp;&ensp;redis是一个开源的、遵循BSD协议的、基于内存的而且目前比较流行的键值数据库(key-value database)，是一个非关系型数据库，redis提供将内存通过网络远程共享的一种服务，提供类似功能的还有memcache，但相比memcache，redis还提供了易扩展、高性能、具备数据持久性等功能。Redis在高并发、低延迟环境要求比较高的环境使用量非常广泛 2.1.2：redis对比memcached支持数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文件中恢复数据到内存继续使用。 支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zet(有序集合) 支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF。 支持更大的value数据：memcache单个key value最大只支持1MB，而redis最大支持512MB。 Redis 是单线程，而memcache是多线程，所以单机情况下没有memcache并发高，但redis 支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。 支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提升性能和数据安全性。 都是基于C语言开发。 2.1.3：redis 典型应用场景Session 共享：常见于web集群中的Tomcat或者PHP中多web服务器session共享 消息队列：ELK的日志缓存、部分业务的订阅发布系统 计数器：访问排行榜、商品浏览数等和次数相关的场景 缓存：数据查询、电商网站商品信息、新闻内容 微博/微信社交场合：共同好友、点赞评论等 2.2：Redis安装及使用官方下载地址：http://download.redis.io/releases/ 2.2.1：yum安装redis12345[root@centos7 ~]#yum -y install redis[root@centos7 ~]#systemctl start redis 端口号6379[root@centos7 ~]#systemctl enable redis[root@centos7 ~]# redis-cli 127.0.0.1:6379&gt; info 2.2.2：编译安装redis下载当前最新release版本redis 源码包： 2.2.2.1：编译安装命令官方的安装命令： https://redis.io/download123456789101112[root@centos7 src]#pwd/usr/local/src[root@centos7 src]#tar xf redis-5.0.3.tar.gz[root@centos7 src]#cd redis-5.0.3[root@centos7 src]#pwd/usr/local/src/redis-5.0.3[root@centos7 redis-5.0.3]#make PREFIX=/usr/local/redis [MALLOC=libc] install[root@centos7 redis-5.0.3]#ll /usr/local/redis/total 0drwxr-xr-x 2 root root 134 Dec 27 11:28 bin[root@centos7 redis-5.0.3]#mkdir /usr/local/redis/etc[root@centos7 redis-5.0.3]#cp redis.conf /usr/local/redis/etc/ 2.2.2.2：前台启动redis1[root@centos7 redis-5.0.3]#/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 2.2.2.3：解决当前的警告提示2.2.2.3.1：tcp-backlogThe backlog argument defines the maximum length to which the queue of pending connections for sockfd may grow. If a connection request arrives when the queue is full, the client may receive an error with an indication of ECONNREFUSED or, if the underlying protocol supports retransmission, the request may be ignored so that a later reattempt at connection succeeds. backlog参数控制的是三次握手的时候server端收到client ack确认号之后的队列值。12vim /etc/sysctl.conf net.core.somaxconn = 512 2.2.2.3.2：vm.overcommit_memory​ 0、表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 ​ 1、表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 ​ 2、表示内核允许分配超过所有物理内存和交换空间总和的内存12vim /etc/sysctl.conf vm.overcommit_memory = 1 2.2.2.3.3：transparent hugepage开启大页内存动态分配，需要关闭让redis 负责内存管理。1echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 2.2.2.4：编辑redis服务启动脚本1234567891011121314151617181920[root@centos7 ~]#vim /usr/lib/systemd/system/redis.service[Unit]Description=Redis persistent key-value databaseAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf --supervised systemdExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPIDType=notifyUser=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755 [Install]WantedBy=multi-user.target 2.2.2.5：创建redis 用户和数据目录123[root@centos7 ~]#groupadd -g 1000 redis &amp;&amp; useradd -u 1000 -g 1000 redis -s /sbin/nologin[root@centos7 ~]#mkdir -pv /usr/local/redis/&#123;logs,data,run&#125;[root@centos7 ~]#chown redis.redis -R /usr/local/redis/ 2.2.2.6：创建命令软连接1[root@centos7 ~]#ln -sv /usr/local/redis/bin/redis-* /usr/bin/ 2.2.2.7：重启redis服务1[root@centos7 ~]#systemctl restart redis 2.2.2.8：使用客户端连接redis1[root@centos7 ~]#/usr/local/redis/bin/redis-cli -h IP 2.2.2.9：编译安装后的命令12345678[root@redis-s1 ~]# ll /usr/local/redis/bin/total 32656-rwxr-xr-x 1 redis redis 4365488 Dec 13 09:21 redis-benchmark #redis性能测试工具-rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 redis-check-aof #AOF文件检查工具-rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 redis-check-rdb #RDB文件检查工具-rwxr-xr-x 1 redis redis 4800752 Dec 13 09:21 redis-cli #redis #客户端工具lrwxrwxrwx 1 redis redis 12 Dec 13 09:21 redis-sentinel -&gt; redis-server #哨兵，软连接到server-rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 #redis-server #redis 服务端 2.2.3：连接到Redis主要分为运维人员的连接和程序的连接 2.2.3.1：本机非密码连接1redis-cli 2.2.3.2：跨主机非密码连接1redis-cli -h HOSTNAME/IP -p PORT 2.2.3.3：跨主机密码连接1redis-cli -h HOSTNAME/IP -p PORT -a PASSWORD 2.2.3.4：python连接方式123456789101112#!/bin/env python#Author: ZhangJieimport redisimport timepool = redis.ConnectionPool(host="192.168.7.101", port=6379,password="")r = redis.Redis(connection_pool=pool)for i in range(100): r.set("k%d" % i,"v%d" % i) time.sleep(1) data=r.get("k%d" % i) print(data) 三：redis配置文件 基本配置项 网络配置项 持久化相关配置 复制相关的配置 安全相关配置 Limit相关的配置 SlowLog相关的配置 INCLUDES Advanced配置 3.1：网络配置项bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP protected-mode yes #redis3.2 之后加入的新特性，在没有设置bind IP和密码的时候只允许访问127.0.0.1:6379 port 6379 #监听端口 tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值。 timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时。 tcp-keepalive 300 #tcp 会话保持时间 3.2：通用配置项daemonize no #认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes,当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面 supervised no #和操作系统相关参数，可以设置通过upstart和systemd管理Redis守护进程，centos 7以后都使用systemd pidfile /var/run/redis_6379.pid #pid文件路径 loglevel notice #日志级别 logfile “” #日志路径 databases 16 #设置db 库数量，默认16个库 always-show-logo yes #在启动redis 时是否显示log 3.3：快照配置项save 900 1 #在900秒内有一个键内容发生更改就出就快照机制 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes #快照出错时是否禁止redis 写入操作 rdbcompression yes #持久化到RDB文件时，是否压缩，”yes”为压缩，”no”则反之 rdbchecksum yes #是否开启RC64校验，默认是开启 dbfilename dump.rdb #快照文件名 dir ./ #快照文件保存路径​ 3.4：复制相关的配置slave-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式： 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求; 如果slave-serve-stale-data设置为no，除去指定的命令之外的任何请求都会返回一个错误”SYNC with master in progress”。 slave-read-only yes #是否设置从库只读 repl-diskless-sync no #是否使用socket方式复制数据，目前redis复制提供两种方式，disk和socket，如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件，有2种方式： disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave， disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件， socket的方式就是一个个slave顺序复制，只有在磁盘速度缓慢但是网络相对较快的情况下才使用socket方式，否则使用默认的disk方式 repl-diskless-sync-delay 5 #diskless复制的延迟时间，设置0为关闭，一旦复制开始还没有结束之前，master节点不会再接收新slave的复制请求，直到下一次开始 repl-ping-slave-period 10 #slave根据master指定的时间进行周期性的PING 监测 repl-timeout 60 #复制链接超时时间，需要大于repl-ping-slave-period，否则会经常报超时 repl-disable-tcp-nodelay no #在socket模式下是否在slave套接字发送SYNC之后禁用 TCP_NODELAY， 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒; 如果你选择了 “no” 数据传输到salve的延迟将会减少但要使用更多的带宽 repl-backlog-size 1mb #复制缓冲区大小，只有在slave连接之后才分配内存。 repl-backlog-ttl 3600 #多次时间master没有slave连接，就清空backlog缓冲区。 slave-priority 100 #当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。 3.5：安全相关配置requirepass foobared #设置redis 连接密码 rename-command #重命名一些高危命令 3.6：Limit相关的配置maxclients 10000 #最大连接客户端 maxmemory #最大内存，单位为bytes字节，8G内存的计算方式$$8(G)1024(MB)1024(KB)*1024(Kbyte)$$需要注意的是slave的输出缓冲区是不计算在maxmemory内。 3.7：APPEND ONLY MODEappendonly no #是否开启AOF日志记录，默认 redis 使用的是 rdb 方式持久化，这种方式在许多应用中已经足够用了。但是 redis 如果中途宕机，会导致可能有几分钟的数据丢失，根据 save 来策略进行持久化，Append Only File 是另一种持久化方式，可以提供更好的持久化特性。Redis 会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时 Redis 都会先把这个文件的数据读入内存里，先忽略 RDB 文件。 appendfilename “appendonly.aof” #AOF文件名 appendfsync everysec #aof 持久化策略的配置； no 表示不执行fsync,由操作系统保证数据同步到磁盘； always表示每次写入都执行fsync，以保证数据同步到磁盘； everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。 no-appendfsync-on-rewrite no #在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步策略,主要考虑磁盘IO开支和请求阻塞时间。默认为no,表示”不暂缓”,新的aof记录仍然会被立即同步，Linux的默认fsync策略是30秒，如果为yes 可能丢失30秒数据，但由于yes性能较好而且会避免出现阻塞因此比较推荐。 auto-aof-rewrite-percentage 100 # 当Aof log增长超过指定比例时，重写log file， 设置为0表示不自动重写Aof 日志，重写是为了使aof体积保持最小，而确保保存最完整的数据。 auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件尺寸 aof-load-truncated yes #是否加载由于其他原因导致的末尾异常的AOF文件(主进程被kill/断电等) aof-use-rdb-preamble yes #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF格式的内存则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）。 3.8： LUA SCRIPTINGlua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒 3.9： REDIS CLUSTERcluster-enabled yes #是否开启集群模式，默认是单机模式 cluster-config-file nodes-6379.conf #由node节点自动生成和的集群配置文件 cluster-node-timeout 15000 #集群中node节点连接超时时间 cluster-replica-validity-factor 10 #在执行故障转移的时候可能有些节点和master断开一段时间数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移 cluster-migration-barrier 1 #一个主节点拥有的至少正常工作的从节点，即如果主节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。 cluster-require-full-coverage yes #集群槽位覆盖，如果一个主库宕机且没有备库就会出现集群槽位不全，那么yes情况下redis集群槽位验证不全就不再对外提供服务，而no则可以继续使用但是会出现查询数据查不到的情况(因为有数据丢失)。 cluster-replica-no-failover no 3.10： SLOW LOG&ensp;&ensp;&ensp;&ensp;Slow log 是 Redis 用来记录查询执行时间的日志系统，slow log 保存在内存里面，读写速度非常快，因此你可以放心地使用它，不必担心因为开启 slow log 而损害 Redis 的速度。 slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。 slowlog-max-len 128 #记录多少条慢日志保存在队列，超出后会删除最早的，以此滚动删除 1234567891011121314151617127.0.0.1:6379&gt; slowlog len(integer) 14127.0.0.1:6379&gt; slowlog get(integer) 14(integer) 1544690617(integer) 4&quot;slowlog&quot;127.0.0.1:6379&gt; SLOWLOG resetOK 3.2：redis持久化&ensp;&ensp;&ensp;&ensp;redis 虽然是一个内存级别的缓存程序，即redis 是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略保存到硬盘上，从而实现数据持久保存的目的，redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF 3.2.1：RDB模式RDB：基于时间的快照，只保留当前最新的一次快照，特点是执行速度比较快，缺点是可能会丢失从上次快照到当前快照未完成之间的数据。 &ensp;&ensp;&ensp;&ensp;RDB实现的具体过程Redis从主进程先fork出一个子进程，使用写时复制机制，子进程将内存的数据保存为一个临时文件，比如dump.rdb.temp，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保存每一次做RDB快照的时候保存的数据都是完整的，因为直接替换RDB文件的时候可能会出现突然断电等问题而导致RDB文件还没有保存完整就突然关机停止保存而导致数据丢失的情况，可以手动将每次生成的RDB文件进程备份，这样可以最大化保存历史数据。 3.2.2：RDB模式的优缺点优点： RDB快照保存了某个时间点的数据，可以通过脚本执行bgsave(非阻塞)或者save(阻塞)命令自定义时间点北备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本。 可以最大化o的性能，因为父进程在保存RDB 文件的时候唯一要做的是fork出一个子进程，然后的-操作都会有这个子进程操作，父进程无需任何的IO操作 RDB在大量数据比如几个G的数据，恢复的速度比AOF的快 缺点： 不能时时的保存数据，会丢失自上一次执行RDB备份到当前的内存数据 数据量非常大的时候，从父进程fork的时候需要一点时间，可能是毫秒或者秒 3.2.3：AOF模式AOF:按照操作顺序依次将操作添加到指定的日志文件当中，特点是数据安全性相对较高，缺点是即使有些操作是重复的也会全部记录。 &ensp;&ensp;&ensp;&ensp;AOF和RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使redis服务器发生故障的话顶多也就丢失1秒钟之内的数据，也可以设置不同的fsync策略，或者设置每次执行命令的时候执行fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的IO影响 3.2.4：AOF模式优缺点 AOF的文件大小要大于RDB格式的文件 根据所使用的fsync策略(fsync是同步内存中redis所有已经修改的文件到存储设备)，默认是appendfsync everysec即每秒执行一次fsync 四：redis 数据类型4.1：字符串(string)&ensp;&ensp;&ensp;&ensp;字符串是所有编程语言中最常见的和最常用的数据类型，而且也是redis最基本的数据类型之一，而且redis中所有的key的类型都是字符串。 4.1.1：添加一个key1234127.0.0.1:6379&gt; set key1 value1OK127.0.0.1:6379&gt; type key1string 4.1.2：获取一个key的内容12127.0.0.1:6379&gt; get key1"value1" 4.1.3：删除一个key12127.0.0.1:6379&gt; del key1(integer) 1 4.1.4：批量设置多个key12127.0.0.1:6379&gt; MSET key1 value1 key2 value2OK 4.1.5：批量获取多个key12127.0.0.1:6379&gt; MSET key1 value1 key2 value2OK 4.1.6：追加数据1234127.0.0.1:6379&gt; APPEND key1 append(integer) 12127.0.0.1:6379&gt; get key1"value1append" 4.1.7：数值递增123456127.0.0.1:6379&gt; set num 10OK127.0.0.1:6379&gt; INCR num(integer) 11127.0.0.1:6379&gt; get num"11" 4.1.8：数值递减123456127.0.0.1:6379&gt; set num 10OK127.0.0.1:6379&gt; decr num(integer) 9127.0.0.1:6379&gt; get num"9" 4.1.9：返回字符串key长度12127.0.0.1:6379&gt; strlen key1(integer) 12 4.2：列表(list)&ensp;&ensp;&ensp;&ensp;列表是一个双向可读写的管道，其头部是左侧尾部是右侧，一个列表最多可以包含2^32-1个元素即4294967295个元素。 4.2.1：生成列表并插入数据1234127.0.0.1:6379&gt; LPUSH list1 jack(integer) 1127.0.0.1:6379&gt; TYPE list1list 4.2.2：向列表追加数据1234127.0.0.1:6379&gt; LPUSH list1 tom(integer) 2127.0.0.1:6379&gt; RPUSH list1 jack(integer) 3 4.2.3：获取列表长度12127.0.0.1:6379&gt; LLEN list1(integer) 3 4.2.4：移除列表数据1234127.0.0.1:6379&gt; RPOP list1 #最后一个"jack"127.0.0.1:6379&gt; LPOP list1 #第一个"tom" 4.3：集合(set)&ensp;&ensp;&ensp;&ensp;Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 4.3.1：生成集合key12345678127.0.0.1:6379&gt; SADD set1 v1 (integer) 1127.0.0.1:6379&gt; SADD set2 v2 v4(integer) 2127.0.0.1:6379&gt; TYPE set1set127.0.0.1:6379&gt; TYPE set2set 4.3.2：追加数值追加的时候不能追加已经存在的数值12345678127.0.0.1:6379&gt; SADD set1 v2 v3 v4(integer) 3127.0.0.1:6379&gt; SADD set1 v2 #没有追加成功(integer) 0127.0.0.1:6379&gt; TYPE set1set127.0.0.1:6379&gt; TYPE set2set 4.3.3：查看集合的所有数据12345678127.0.0.1:6379&gt; SMEMBERS set11) "v4"2) "v1"3) "v3"4) "v2"127.0.0.1:6379&gt; SMEMBERS set21) "v4"2) "v2" 4.2.4：获取集合的差集差集：已属于A而不属于B的元素称为A与B的差（集）123127.0.0.1:6379&gt; SDIFF set1 set21) "v1"2) "v3" 4.3.5：获取集合的交集交集：已属于A且属于B的元素称为A与B的交（集）123127.0.0.1:6379&gt; SINTER set1 set21) "v4"2) "v2" 4.3.6：获取集合的并集并集：已属于A或属于B的元素为称为A与B的并（集）12345127.0.0.1:6379&gt; SUNION set1 set21) "v2"2) "v4"3) "v1"4) "v3" 4.4：sorted set(有序集合)&ensp;&ensp;&ensp;&ensp;Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员，不同的是每个元素都会关联一个double(双精度浮点型)类型的分数，redis正是通过分数来为集合中的成员进行从小到大的排序，序集合的成员是唯一的,但分数(score)却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)， 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 4.4.1：生成有序集合123456789101112127.0.0.1:6379&gt; ZADD zset1 1 v1 (integer) 1127.0.0.1:6379&gt; ZADD zset1 2 v2(integer) 1127.0.0.1:6379&gt; ZADD zset1 2 v3(integer) 1127.0.0.1:6379&gt; ZADD zset1 3 v4(integer) 1127.0.0.1:6379&gt; TYPE zset1zset127.0.0.1:6379&gt; TYPE zset2none 排行案例： 123456789192.168.7.104:6379&gt; ZADD paihangbang 10 key1 20 key2 30 key3(integer) 3192.168.7.104:6379&gt; ZREVRANGE paihangbang 0 -1 withscores1) "key3"2) "30"3) "key2"4) "20"5) "key1"6) "10" 4.4.2：批量添加多个数值12127.0.0.1:6379&gt; ZADD zset2 1 v1 2 v2 4 v3 5 v5(integer) 4 4.4.3：获取集合的长度数1234127.0.0.1:6379&gt; ZCARD zset1 (integer) 4127.0.0.1:6379&gt; ZCARD zset2(integer) 4 4.4.4：基于索引返回数值12345678127.0.0.1:6379&gt; ZRANGE zset1 1 31) "v2"2) "v3"3) "v4"127.0.0.1:6379&gt; ZRANGE zset1 0 21) "v1"2) "v2"3) "v3" 4.4.5：返回某个数值的索引12345127.0.0.1:6379&gt; ZRANK zset1 v2(integer) 1127.0.0.1:6379&gt; ZRANK zset1 v3(integer) 2 4.5：哈希(hash)&ensp;&ensp;&ensp;&ensp;hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象,Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。 4.5.1：生成hash key1234567127.0.0.1:6379&gt; HSET hset1 name tom (integer) 1127.0.0.1:6379&gt; HSET hset1 age 18(integer) 1或者 127.0.0.1:6379&gt; HMSET hset1 name tom age 18127.0.0.1:6379&gt; TYPE hset1hash 4.5.2：获取hash key字段值1234127.0.0.1:6379&gt; HGET hset1 name"tom"127.0.0.1:6379&gt; HGET hset1 age"18" 4.5.3：删除一个hash key的字段12127.0.0.1:6379&gt; HDEL hset1 age(integer) 1 4.5.4：获取所有hash表中的字段12345127.0.0.1:6379&gt; HMSET hset1 name tom age 19(integer) 1127.0.0.1:6379&gt; HKEYS hset11) "name"2) "age" 五：消息队列&ensp;&ensp;&ensp;&ensp;消息队列主要分为两种，分别是生产者消费者模式和发布者订阅者模式，这两种模式Redis都支持。 5.1：生产者消费者模式&ensp;&ensp;&ensp;&ensp;在生产者消费者(Producer/Consumer)模式下，上层应用接收到的外部请求后开始处理其当前步骤的操作，在执行完成后将已经完成的操作发送至指定的频道(channel)当中，并由其下层的应用监听该频道并继续下一步的操作，如果其处理完成后没有下一步的操作就直接返回数据给外部请求，如果还有下一步的操作就再将任务发布到另外一个频道，由另外一个消费者继续监听和处理。 5.1.1：模式介绍&ensp;&ensp;&ensp;&ensp;生产者消费者模式下，多个消费者同时监听一个队里，但是一个消息只能被最先抢到消息的消费者消费，即消息任务是一次性读取和处理，此模式在分布式业务架构中非常常用，比较常用的软件还有RabbitMQ、Kafka、RocketMQ、ActiveMQ等 5.1.2：队列介绍&ensp;&ensp;&ensp;&ensp;队列当中的 消息由不同的生产者写入也会有不同的消费者取出进行消费处理，但是买一个消息一定是只能被取出一次也就是被消费一次。 5.1.3：生产者发布消息12345678910111213[root@centos7 ~]# redis-cli127.0.0.1:6379&gt; AUTH 123456OK127.0.0.1:6379&gt; LPUSH channel1 msg1 #从管道的左侧写入(integer) 1127.0.0.1:6379&gt; LPUSH channel1 msg2(integer) 2127.0.0.1:6379&gt; LPUSH channel1 msg3(integer) 3127.0.0.1:6379&gt; LPUSH channel1 msg4(integer) 4127.0.0.1:6379&gt; LPUSH channel1 msg5(integer) 5 5.1.4：查看队列所有消息123456127.0.0.1:6379&gt; LRANGE channel1 0 -11) "msg5"2) "msg4"3) "msg3"4) "msg2"5) "msg1" 5.1.5：消费者消费消息123456789101112127.0.0.1:6379&gt; RPOP channel1 #从管道的右侧消费"msg1"127.0.0.1:6379&gt; RPOP channel1"msg2"127.0.0.1:6379&gt; RPOP channel1"msg3"127.0.0.1:6379&gt; RPOP channel1"msg4"127.0.0.1:6379&gt; RPOP channel1"msg5"127.0.0.1:6379&gt; RPOP channel1(nil) 5.1.6：再次验证队列消息12127.0.0.1:6379&gt; LRANGE channel1 0 -1 (empty list or set) #队列中的消息已经被已全部消费完毕 5.2：发布者订阅模式5.2.1：模式简介&ensp;&ensp;&ensp;&ensp;在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到同样的一份消息，这种模式类似于是收音机模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容。 此模式常用语群聊天、群通知、群公告等场景。 Subscriber：订阅者 Publisher：发布者 Channel：频道 5.2.2：订阅者监听频道12345678[root@centos ~]# redis-cli 127.0.0.1:6379&gt; AUTH 123456OK127.0.0.1:6379&gt; SUBSCRIBE channel1 #订阅者订阅指定的频道Reading messages... (press Ctrl-C to quit)1) "subscribe"2) "channel1"3) (integer) 1 5.2.3：发布者发布消息12345127.0.0.1:6379&gt; PUBLISH channel1 test1 #发布者发布消息(integer) 2127.0.0.1:6379&gt; PUBLISH channel1 test2(integer) 2127.0.0.1:6379&gt; 5.2.4：订阅多个频道订阅指定的多个频道 1SUBSCRIBE channel1 channel2 5.2.5：订阅所有频道1127.0.0.1:6379&gt; PSUBSCRIBE * 5.2.6：订阅匹配的频道1PSUBSCRIBE chann* #匹配订阅多个频道 六：redis其他命令6.1：查看当前redis配置、以及不重启更改redis配置等1127.0.0.1:6379&gt; CONFIG GET * 6.1.1：更改最大内存12345127.0.0.1:6379&gt; CONFIG set maxmemory 8589934592OK127.0.0.1:6379&gt; CONFIG get maxmemory 1) "maxmemory"2) "8589934592" 6.1.2：设置连接密码（临时有效）123456789101112127.0.0.1:6379&gt; [root@centos7 ~]#redis-cli127.0.0.1:6379&gt; CONFIG SET requirepass 123456OK127.0.0.1:6379&gt; CONFIG GET requirepass(error) NOAUTH Authentication requirepass.127.0.0.1:6379&gt; AUTH 123456OK127.0.0.1:6379&gt; CONFIG GET requirepass1) "requirepass"2) "123456"127.0.0.1:6379&gt;OK 6.2：显示当前节点redis运行状态信息1127.0.0.1:6379&gt; info 6.3：切换数据库123127.0.0.1:6379&gt; SELECT 1ok127.0.0.1:6379[1]&gt; 6.4：查看当前库下的所有key1127.0.0.1:6379&gt; keys * 6.5：手动在后台执行RDB持久化操作1127.0.0.1:6379&gt;BGSAVE 6.6：返回当前库下的所有key 数量1127.0.0.1:6379&gt;DBSIZE 6.7：清空当前数据库1127.0.0.1:6379&gt;FLUSHDB 6.8：清空所有数据库1127.0.0.1:6379&gt;FLUSHALL]]></content>
      <categories>
        <category>nosql</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[企业级调度器LVS]]></title>
    <url>%2F2019%2F01%2F05%2F%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E5%BA%A6%E5%99%A8LVS%2F</url>
    <content type="text"><![CDATA[Cluster集群&ensp;&ensp;&ensp;&ensp; Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统• Linux Cluster类型：​ • LB：Load Balancing，负载均衡​ • HA：High Availiablity，高可用，SPOF（single Point Of failure）• 分布式系统：​ 分布式存储：云盘​ 分布式计算：hadoop，Spark • 系统扩展方式：​ Scale UP：向上扩展(更换性能更好的设备)​ Scale Out：向外扩展(Cluster) Cluster分类LB Cluster的实现 硬件 F5 Big-IP Citrix Netscaler A10 A10 软件 lvs：Linux Virtual Server,支持四层调度 nginx：支持七层调度，阿里七层SLB使用Tengine haproxy：支持七层调度 ats：apache traffic server，yahoo捐助 perlbal：Perl 编写 pound 基于工作的协议层次划分 传输层（通用）：DPORT 器 nginx：stream haproxy：mode tcp 应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server： http：nginx, httpd, haproxy(mode http), … fastcgi：nginx, httpd, … mysql：mysql-proxy, LVS&ensp;&ensp;&ensp;&ensp;LVS(Linux Virtual Server)即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案。 工作原理VS: Virtual Server，负责调度RS: Real Server，负责真正提供服务L4：四层路由器或交换机 当用户向负载均衡调度器（Director Server）发起请求，调度器将请求发往至内核空间 PREROUTING链首先会接收到用户请求，判断目标IP确定是本机IP，将数据包发往INPUT链 IPVS是工作在INPUT链上的，当用户请求到达INPUT时，IPVS会将用户请求和自己已定义好的集群服务进行比对，如果用户请求的就是定义的集群服务，那么此时IPVS会强行修改数据包里的目标IP地址及端口，并将新的数据包发往POSTROUTING链 POSTROUTING链接收数据包后发现目标IP地址刚好是自己的后端服务器，那么此时通过选路，将数据包最终发送给后端的服务器 LVS的组成LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。​ ipvsadm：用户空间的命令行工具，规则管理器，用于管理集群服务及相关的RealServer；​ ipvs：工作于内核空间的netfilter的INPUT钩子之上的框架； lvs集群类型中的术语 VS：Virtual Server，Director Server(DS) , Dispatcher(调度器)，Load Balancer.指的是前端负载均衡器节点。 RS：Real Server(lvs), upstream server(nginx) , backend server(haproxy).后端真实的工作服务器。 CIP：Client IP.访问客户端的IP地址。 VIP: Virtual serve IP.向外部直接面向用户请求，作为用户请求的目标的IP地址。 DIP: Director IP,主要用于和内部主机通讯的IP地址。 RIP: Real server IP.后端服务器的IP地址。 • 访问流程：CIP VIP == DIP RIP LVS负载均衡调度算法静态算法：仅根据算法本身和请求报文特征惊醒调度 轮询调度(RR) &ensp;&ensp;&ensp;&ensp;轮询调度（Round Robin 简称’RR’）算法就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器，不管后端 RS 配置和处理能力，非常均衡地分发下去。 加权轮询(WRR) &ensp;&ensp;&ensp;&ensp;加权轮询（Weight Round Robin 简称’WRR’）算法主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 源地址散列调度(SH) &ensp;&ensp;&ensp;&ensp;源地址散列调度（Source Hashing 简称’SH’）算法先根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同，它的算法流程与目标地址散列调度算法的基本相似。 目标地址散列调度(DH) &ensp;&ensp;&ensp;&ensp;目标地址散列调度（Destination Hashing 简称’DH’）算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。 动态算法：额外考虑后端各RS的当前的负载状态 最少连接(lc) &ensp;&ensp;&ensp;&ensp;最少连接（ Least Connections 简称’LC’）算法会根据后端 RS 的连接数来决定把请求分发给谁，比如 RS1 连接数比 RS2 连接数少，那么请求就优先发给 RS1 加权最小连接调度(WLC) &ensp;&ensp;&ensp;&ensp;加权最少连接（Weight Least Connections 简称’WLC’）算法是最小连接调度的超集，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 最短的期望的延迟(SED) &ensp;&ensp;&ensp;&ensp;最短的期望的延迟调度（Shortest Expected Delay 简称’SED’）算法基于WLC算法。举个例子吧，ABC三台服务器的权重分别为1、2、3 。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用SED算法后会进行一个运算 A：（1+1）/1=2 B：（1+2）/2=3/2 C：（1+3）/3=4/3 就把请求交给得出运算结果最小的服务器。 永不排队(NQ) &ensp;&ensp;&ensp;&ensp;永不排队（Never Queue 简称’NQ’）算法，无需队列。如果有realserver的连接数等于0就直接分配过去，不需要在进行SED运算。 基于局部的最少连接(LBLC) &ensp;&ensp;&ensp;&ensp;基于局部的最少连接调度（Locality-Based Least Connections 简称’LBLC’）算法是针对请求报文的目标IP地址的 负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和Cache命中率，从而提升整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则使用’最少连接’的原则选出一个可用的服务器，将请求发送到服务器。 6.带复制的基于局部性的最少连接 &ensp;&ensp;&ensp;&ensp;带复制的基于局部性的最少连接（Locality-Based Least Connections with Replication 简称’LBLCR’）算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统，它与LBLC算法不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。按’最小连接’原则从该服务器组中选出一一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按’最小连接’原则从整个集群中选出一台服务器，将该服务器加入到这个服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。 lvs集群的类型lvs-nat：修改请求报文的目标IP,多目标IP的DNATlvs-dr：操纵封装新的MAC地址lvs-tun：在原请求IP报文之外新加一个IP首部lvs-fullnat：修改请求报文的源和目标IP lvs-nat模式 lvs-nat：本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发（1）RIP和DIP应在同一个IP网络，且应使用私网地址；RS的网关要指向DIP（2）请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈（3）支持端口映射，可修改请求报文的目标PORT（4）VS必须是Linux系统，RS可以是任意OS系统 LVS-DR模式 DR模式IP包调度过程 LVS-DR： Direct Routing，直接路由，LVS默认模式,应用最广泛,通过为请求报文重新封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变 Director和各RS都配置有VIP 确保前端路由器将目标IP为VIP的请求报文发往Director （1） 在前端网关做静态绑定VIP和Director的MAC地址 （2） 在RS上使用arptables工具 12arptables -A IN -d $VIP -j DROParptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP ​ （3） 在RS上修改内核参数以限制arp通告及应答级别 12/proc/sys/net/ipv4/conf/all/arp_ignore/proc/sys/net/ipv4/conf/all/arp_announce ​ 限制响应级别：arp_ignore ​ 0：默认值，表示可使用本地任意接口上配置的任意地址进行响应 ​ 1: 仅在请求的目标IP配置在本地主机的接收到请求报文的接口上时，才给予响应 ​ 限制通告级别：arp_announce ​ 0：默认值，把本机所有接口的所有信息向每个接口的网络进行通告 ​ 1：尽量避免将接口信息向非直接连接网络进行通告 ​ 2：必须避免将接口信息向非本网络进行通告 RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director RS和Director要在同一个物理网络 请求报文要经由Director，但响应报文不经由Director，而由RS直接发往Client 不支持端口映射（端口不能修败） RS可使用大多数OS系统 lvs-tun模式 lvs-tun： 转发方式：不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而在原IP报文之外再封装一个IP首部（源IP是DIP，目标IP是RIP），将报文发往挑选出的目标RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP）(1) DIP, VIP, RIP都应该是公网地址(2) RS的网关一般不能指向DIP(3) 请求报文要经由Director，但响应不经由Director(4) 不支持端口映射(5) RS的OS须支持隧道功能 lvs-fullnat模式lvs-fullnat：通过同时修改请求报文的源IP地址和目标IP地址进行转发CIP –&gt; DIPVIP –&gt; RIP(1) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关一般不会指向DIP(2) RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还要将其发往Client(3) 请求和响应报文都经由Director(4) 支持端口映射注意：此类型kernel默认不支持 ipvsadmipvsadm包构成程序包：ipvsadmUnit File: ipvsadm.service主程序：/usr/sbin/ipvsadm规则保存工具：/usr/sbin/ipvsadm-save规则重载工具：/usr/sbin/ipvsadm-restore配置文件：/etc/sysconfig/ipvsadm-config ipvsadm命令管理集群服务​增、改： 1ipvsadm -A|E -t|u|f service-address [-s scheduler][-p [timeout]] 删除： 1ipvsadm -D -t|u|f service-address service-address：-t|u|f：​ -t: TCP协议的端口，VIP:TCP_PORT​ -u: UDP协议的端口，VIP:UDP_PORT​ -f：firewall MARK，标记，一个数字[-s scheduler]：指定集群的调度算法，默认为wlc 查看 1ipvsadm -A|E -t|u|f service-address [-s scheduler][-p [timeout]] [-M netmask][--pe persistence_engine] [-b sched-flags] 清空定义的所有内容 1ipvsadm –C 清空计数器 1ipvsadm -Z [-t|u|f service-address] 查看 1ipvsadm -L|l [options] –numeric, -n：以数字形式输出地址和端口号（和 -L|l 连起来使用只能写在后面）–exact：扩展信息，精确值–connection，-c：当前IPVS连接输出–stats：统计信息–rate ：输出速率信息 ipvs规则 1/proc/net/ip_vs ipvs连接1/proc/net/ip_vs_conn 保存：建议保存至/etc/sysconfig/ipvsadm123ipvsadm-save &gt; /PATH/TO/IPVSADM_FILEipvsadm -S &gt; /PATH/TO/IPVSADM_FILEsystemctl stop ipvsadm.service 重载123ipvsadm-restore &lt; /PATH/FROM/IPVSADM_FILEipvsadm -R &lt; /PATH/FROM/IPVSADM_FILEsystemctl restart ipvsadm.service 管理集群上的RS：增、改、删增、改： 1ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m][-w weight] 删： 1ipvsadm -d -t|u|f service-address -r server-address server-address：rip[:port] 如省略port，不作端口映射选项：lvs类型：-g: gateway, dr类型，默认-i: ipip, tun类型-m: masquerade, nat类型-w weight：权重 实现lvs-nat实验用宿主机模拟Director Server，容器模拟两个Real Server。 在宿一台主机先用docker pull镜像，做宿主机 1[root@centos7 ~]#docker image pull busybox 配置两个容器并启动httpd服务1234567891011121314151617181920212223另开一个终端[root@centos7 ~]#docker run --name rs1 -it --network bridge -v /vols/rsl:/data/web/html busybox/ # httpd -h /data/web/html// # netstat -ntlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 :::80 :::* LISTEN 宿主机[root@centos7 rsl]#vim /vols/rsl/index.html &lt;h1&gt;RS1&lt;/h1&gt; 再开一个终端[root@centos7 ~]#docker run --name rs2 -it --network bridge -v /vols/rs2:/data/web/html busybox/ # httpd -h /data/web/html// # netstat -ntlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 :::80 :::* LISTEN 宿主机[root@centos7 rs2]#vim /vols/rsl/index.html &lt;h1&gt;RS2&lt;/h1&gt; index.html的内容不一样，是为了演示调度效果 在宿主机上修改iptables forward 链的规则 12345678[root@centos7 rs2]#which iptables/usr/sbin/iptables[root@centos7 rs2]#vim /usr/lib/systemd/system/docker.service 在ExecStart下面加上一行 ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT[root@centos7 rs2]#systemctl daemon-reload重启会导致docker关闭，故手动添加一条规则[root@centos7 rsl]#iptables -P FORWARD ACCEPT 在宿主机上添加ipvsadm规则 123456789101112131415[root@centos7 ~]#ipvsadm -A -t 192.168.146.154:80 -s wrr[root@centos7 ~]#ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.146.154:80 wrr[root@centos7 ~]#ipvsadm -a -t 192.168.146.154:80 -r 172.17.0.2:80 -m -w 1[root@centos7 ~]#ipvsadm -a -t 192.168.146.154:80 -r 172.17.0.3:80 -m -w 1 [root@centos7 ~]#ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.146.154:80 wrr -&gt; 172.17.0.2:80 Masq 1 0 0 -&gt; 172.17.0.3:80 Masq 1 0 0 在另外一个终端发请求进行模拟1[root@centos7 ~]#while true; do curl 192.168.146.154;sleep 0.5; done 实现lvs-DR实验准备三台虚拟机，分别为node01、node02、node03. node01为Director Server（192.168.146.152），node02（192.168.146.154）、node03（192.168.146.139）为Real Server。 配置DS的VIP，给ens37起个别名，并且只广播给自己 1[root@node01 ~]#ifconfig ens37:0 192.168.146.100 netmask 255.255.255.255 broadcast 192.168.146.100 up 配置RS（写RS的配置脚本） 1234567891011121314151617181920212223242526272829#!/bin/bashvip=192.168.146.100mask='255.255.255.255'interface="lo:0"case $1 instart) iptables -F echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $interface $vip netmask $mask broadcast $vip up route add -host $vip dev $interface ;;stop) ifconfig $interface down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ;;*) echo "Usage: $(basename $0) start|stop" exit 1 ;;esac 分别在node02、node03上运行脚本 12[root@node02 ~]#bash setkpara.sh start[root@node03 ~]#bash setkpara.sh start 配置DS ipvsadm 12345678910[root@node01 ~]#ipvsadm -A -t 192.168.146.100:80 -s wrr[root@node01 ~]#ipvsadm -a -t 192.168.146.100:80 -r 192.168.146.154:80 -g -w 2 [root@node01 ~]#ipvsadm -a -t 192.168.146.100:80 -r 192.168.146.139:80 -g -w 3[root@node01 ~]#ipvsadm -LnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.146.100:80 wrr -&gt; 192.168.146.139:80 Route 3 0 0 -&gt; 192.168.146.154:80 Route 2 0 0 在另外一个终端发请求进行模拟 1[root@centos7 ~]#while true ;do curl 192.168.146.100;sleep .5;done 在调度器node01查下ipvsadm 1234567[root@node01 ~]#ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.146.100:80 wrr -&gt; 192.168.146.139:80 Route 3 0 90 -&gt; 192.168.146.154:80 Route 2 0 60 调度器可以写成脚本（vs的配置脚本） 123456789101112131415161718192021222324252627282930#!/bin/bashvip='192.168.146.100'interface='ens37:0'mask='255.255.255.255'port='80'rs1='192.168.146.154'rs2='192.168.146.139'scheduler='wrr'type='-g'weight1='2'weight2='3'case $1 instart) ifconfig $interface $vip netmask $mask broadcast $vip up iptables -F ipvsadm -A -t $&#123;vip&#125;:$&#123;port&#125; -s $scheduler ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs1&#125; $type -w $&#123;weight1&#125; ipvsadm -a -t $&#123;vip&#125;:$&#123;port&#125; -r $&#123;rs2&#125; $type -w $&#123;weight2&#125; ;; stop) ipvsadm -C ifconfig $interface down ;;*) echo "Usage $(basename $0) start|stop" exit 1esac FireWall Mark&ensp;&ensp;&ensp;&ensp;MARK target 可用于给特定的报文打标记 –set-mark value 其中：value 可为0xffff格式，表示十六进制数字 借助于防火墙标记来分类报文，而后基于标记定义集群服务；可将多个不同的应用使用同一个集群服务进行调度 实现方法： • 在Director主机打标记： 1iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport --dports $port1,$port2, -j MARK --set-mark NUMBER • 在Director主机基于标记定义集群服务： 1ipvsadm -A -f NUMBER [options] 根据上面lvs-dr实验，在rs两台服务器上分别增加一个端口配置文件 123456789101112131415161718192021222324252627282930[root@node02 ~]#vim /etc/httpd/conf.d/myvhosts.confListen 8080&lt;VirtualHost *:80&gt; ServerName "192.168.146.154" DocumentRoot "/www/vhost1" &lt;Directory "www/vhost1"&gt; Options none AllowOverride none Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8080&gt; ServerName "192.168.146.154" DocumentRoot "/www/vhost2" &lt;Directory "www/vhost2"&gt; Options none AllowOverride none Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;[root@node02 ~]#mkdir -pv /www/vhost&#123;1,2&#125;[root@node02 ~]#vim /www/vhost1/index.html&lt;h1&gt;node02:80&lt;/h1&gt;[root@node02 ~]#vim /www/vhost2/index.html&lt;h1&gt;node02:8080&lt;/h1&gt;另外一台做同样的修改 把上述调度器的脚本修改下 12345678910111213141516171819202122232425262728293031323334#!/bin/bashvip='192.168.146.100'interface='ens37:0'mask='255.255.255.255'port1='80'port2='8080'rs1='192.168.146.154'rs2='192.168.146.139'scheduler='wrr'type='-g'weight1='2'weight2='3'number='7'proto='tcp'case $1 instart) ifconfig $interface $vip netmask $mask broadcast $vip up iptables -F iptables -t mangle -A PREROUTING -d $vip -p $proto -m multiport --dports $port1,$port2 -j MARK --set-mark $number ipvsadm -A -f $&#123;number&#125; -s $scheduler ipvsadm -a -f $&#123;number&#125; -r $&#123;rs1&#125; $type -w $&#123;weight1&#125; ipvsadm -a -f $&#123;number&#125; -r $&#123;rs2&#125; $type -w $&#123;weight2&#125; ;; stop) ipvsadm -C ifconfig $interface down ;;*) echo "Usage $(basename $0) start|stop" exit 1esac 在另外一个终端发请求进行模拟1[root@centos7 ~]#while true; do curl 192.168.146.100;do curl 192.168.146.100:8080;sleep 0.5; done 持久连接 session 绑定：对共享同一组RS的多个集群服务，需要统一进行绑定，lvs sh算法无法实现 持久连接（ lvs persistence ）模板：实现无论使用任何调度算法，在一段时间内（默认360s ），能够实现将来自同一个地址的请求始终发往同一个RS 1ipvsadm -A|E -t|u|f service-address [-s scheduler][-p [timeout]] 持久连接实现方式： 每端口持久（PPC）：每个端口定义为一个集群服务，每集群服务单独调度 每防火墙标记持久（PFWMC）：基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity 每客户端持久（PCC）：基于0端口（表示所有服务）定义集群服务，即将客户端对所有应用的请求都调度至后端主机，必须定义为持久模式]]></content>
      <categories>
        <category>lvs</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible的高级用法之playbook和roles]]></title>
    <url>%2F2018%2F12%2F02%2FAnsible%E7%9A%84%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95%E4%B9%8Bplaybook%E5%92%8Croles%2F</url>
    <content type="text"><![CDATA[playbook概念playbook是由一个或多个“play” 组成的列表play的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。 Task实际是调用ansible的一个module，将多个play组织在一个playbook中，即可以让它们联合起来，按事先编排的机制执行预定义的动作Playbook采用YAML语言编写 YAML介绍&ensp;&ensp;&ensp;&ensp;YAML是一个可读性高的用来表达资料序列的格式。 YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。 Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者. YAML Ain’t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言） 特性 YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 YAML语法简介 在单一档案中，可用连续三个连字号(—)区分多个档案。另外，还有选择性的连续三个点号( … )用来表示档案结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结合换行来实现的 YAML文件内容是区别大小写的，k/v的值均需大小写敏感 k/v的值可同行写也可换行写。同行使用:分隔 v可是个字符串，也可是另一个列表 一个完整的代码块功能需最少元素需包括 name: task 一个name只能包括一个task YAML文件扩展名通常为yml或yaml List：列表，其所有元素均使用“-” 打头示例： 123456# A list of tasty fruits - Apple- Orange- Strawberry- Mango Dictionary：字典，通常由多个key与value构成示例： 12345---# An employee record name: Example Developer job: Developer skill: Elite 也可以将key:value放置于{}中进行表示，用,分隔多个key:value 示例： 123---# An employee record &#123;name: Example Developer, job: Developer, skill: Elite&#125; YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔示例1234567891011121314name: John Smithage: 41gender: Malespouse:name: Jane Smithage: 37gender: Femalechildren:- name: Jimmy Smithage: 17gender: Male- name: Jenny Smithage 13gender: Female Playbook核心元素 Hosts 执行的远程主机列表 Tasks 任务集 Varniables 内置变量或自定义变量在playbook中调用 Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。 ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断 1ansible-playbook –t tagsname useradd.yml playbook基础组件Hosts&ensp;&ensp;&ensp;&ensp;playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。 hosts用于指定要执行指定任务的主机，须事先定义在主机清单中可以是如下形式：1234one.example.comone.example.com:two.example.com192.168.1.50192.168.1.* Websrvs:dbsrvs 或者，两个组的并集Websrvs:&amp;dbsrvs 与，两个组的交集webservers:!phoenix 在websrvs组，但不在dbsrvs组示例: - hosts: websrvs：dbsrvs remote_user&ensp;&ensp;&ensp;&ensp;用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户12345678- hosts: websrvsremote_user: roottasks:- name: test connectionping:remote_user: magedusudo: yes 默认sudo为rootsudo_user:wang sudo为wang task列表和action&ensp;&ensp;&ensp;&ensp;play的主体部分是task list。 task list中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后，再开始第二个任务task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。如果未提供name，则action的结果将用于输出 tasks：任务列表两种格式： action: module arguments module: arguments 建议使用注意：shell和command模块后面跟命令，而非key=value 任务可以通过”tags“打标签，可在ansible-playbook命令上使用-t指定进行调用示例：12345678910111213141516tasks: - name: disable selinux command: /sbin/setenforce 0 如果命令或脚本的退出码不为零，可以使用如下方式替代 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 或者使用ignore_errors来忽略错误信息 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 运行playbook的方式 ansible-playbook &lt;filename.yml&gt; … [options] 常见选项:–check -C 只检测可能会发生的改变，但不真正执行操作–list-hosts 列出运行任务的主机123456789[root@centos7 playbook]#ansible-playbook test.yml --list-hostsplaybook: test.yml play #1 (appsrvs): appsrvs TAGS: [] pattern: [u'appsrvs'] hosts (2): 192.168.183.132 192.168.183.129 –list-tags 列出tag123456[root@centos7 playbook]#ansible-playbook test.yml --list-tags playbook: test.yml play #1 (appsrvs): appsrvs TAGS: [] TASK TAGS: [] –list-tasks 列出task1234567[root@centos7 playbook]#ansible-playbook test.yml --list-tasksplaybook: test.yml play #1 (appsrvs): appsrvs TAGS: [] tasks: first task TAGS: [] second task TAGS: [] –limit 主机列表 只针对主机列表中的主机执行1[root@centos7 playbook]#ansible-playbook test.yml --limit 192.168.183.129 -v -vv -vvv 显示过程 Playbook示例安装httpd，并且开机启动1234567891011121314151617181920212223242526272829303132333435363738[root@cetos7 ~]#vim /etc/ansible/hosts ##[dbservers]##db01.intranet.mydomain.net##db02.intranet.mydomain.net##10.25.1.56##10.25.1.57# Here's another example of host ranges, this time there are no# leading 0s:## db-[99:101]-node.example.com [appsrvs] #添加分组192.168.183.132192.168.183.129~ "/etc/ansible/hosts" 50L, 1100C 47,0-1 Bot[root@centos7 playbook]#vim httpd.yml ---- hosts: appsrvs remote_user: root tasks: - name: creat group group: name=apache system=yes gid=80 - name: creat user user: name=apache group=apache uid=80 shell=/sbin/nologin home=/usr/share/httpd system=yes password='$1$MrKn.0gj$CvMvkger.03UzBwQIrya.0' - name: install package yum: name=httpd - name: config file copy: src=/root/playbook/httpd.conf dest=/etc/httpd/conf/ backup=yes - name: service service: name=httpd state=started enabled=yes ~[root@centos7 playbook]#ansible-playbook httod.yml handlers和notify结合使用触发条件Handlers是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生变化时，才会采取一定的操作Notify此action可用于在每个play的最后被触发，这样可避免多次有改变发生时每次都执行指定的操 作，仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称handler，也即notify中调用handler中定义的操作 &ensp;&ensp;&ensp;&ensp;如果httpd.conf文件内容修改了再运行一遍httpd.yml，只有config file发生改变，其他任务不会继续做了，所以把上述的playbook改写一下,加上notify和handlers：12345678910111213141516171819202122[root@centos7 playbook]#vim httpd.yml ---- hosts: appsrvs remote_user: root tasks: - name: creat group group: name=apache system=yes gid=80 - name: creat user user: name=apache group=apache uid=80 shell=/sbin/nologin home=/usr/share/httpd system=yes password='$1$MrKn.0gj$CvMvkger.03UzBwQIrya.0' - name: install package yum: name=httpd - name: config file copy: src=/root/playbook/httpd.conf dest=/etc/httpd notify: restart service/conf/ backup=yes - name: service service: name=httpd state=started enabled=yes handlers: - name: restart service service: name=httpd state=restart[root@centos7 playbook]#ansible-playbook httod.yml如果我们httpd端口80 改成8080，再运行一遍`ansible-playbook`时，这时就只会触发重启httpd服务 Playbook中tags使用12345678910111213141516171819202122[root@centos7 playbook]#vim httpd.yml ---- hosts: appsrvs remote_user: root tasks: - name: creat group group: name=apache system=yes gid=80 - name: creat user user: name=apache group=apache uid=80 shell=/sbin/nologin home=/usr/share/httpd system=yes password='$1$MrKn.0gj$CvMvkger.03UzBwQIrya.0' - name: install package yum: name=httpd tags: install - name: config file copy: src=/root/playbook/httpd.conf dest=/etc/httpd tags: config notify: restart service/conf/ backup=yes - name: service service: name=httpd state=started enabled=yes handlers: - name: restart service service: name=httpd state=restart 给playbook打上tags我们就可以单独的执行tags的那部分tasks [root@centos7 playbook]#ansible-playbook -t install httpd.yml 仅仅执行了安装httpd Playbook中变量使用变量来源： ansible setup facts 远程主机的所有变量都可直接调用 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量公共（组）变量：针对主机组中所有主机定义统一变量 通过命令行指定变量，优先级最高 ansible-playbook –e varname=value 在playbook中定义 123vars:- var1: value1- var2: value2 在独立的变量YAML文件中定义 在role中定义 变量命名变量名仅能由字母、数字和下划线组成，且只能以字母开头 变量定义：key=value示例：http_port=80 变量调用方式通过 调用变量，且变量名前后必须有空格，有时用“”才生效 ansible-playbook –e 选项指定1ansible-playbook test.yml -e “hosts=www user=magedu” 示例使用setup变量示例：var.yml1234567- hosts: websrvs remote_user: root tasks: - name: create log file file: name=/var/log/ &#123;&#123; ansible_fqdn &#125;&#125; state=touchansible-playbook var.yml 变量示例：var.yml12345678910111213- hosts: websrvs remote_user: root vars: - username: user1 - groupname: group1 tasks: - name: create group group: name=&#123;&#123; groupname &#125;&#125; state=present - name: create user user: name=&#123;&#123; username &#125;&#125; state=presentansible-playbook var.ymlansible-playbook -e "username=user2 groupname=group2” var2.yml 主机变量 可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用示例：123[websrvs]www1.magedu.com http_port=80 maxRequestsPerChild=808www2.magedu.com http_port=8080 maxRequestsPerChild=909 组变量 组变量是指赋予给指定组内所有主机上的在playbook中可用的变量示例：123456[websrvs]www1.magedu.comwww2.magedu.com[websrvs:vars]ntp_server=ntp.magedu.comnfs_server=nfs.magedu.com 普通变量 123[websrvs]192.168.99.101 http_port=8080 hname=www1192.168.99.102 http_port=80 hname=www2 公共（组）变量 1234567[websvrs:vars]http_port=808mark=“_”[websrvs]192.168.99.101 http_port=8080 hname=www1192.168.99.102 http_port=80 hname=www2ansible websvrs –m hostname –a 'name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; http_port &#125;&#125;' 命令行指定变量： 1ansible websvrs –e http_port=8000 –m hostname –a 'name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; http_port &#125;&#125;' 模板templates 文本文件，嵌套有脚本（使用模板编程语言编写） Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, …]元组：(item1, item2, …)字典：{key1:value1, key2:value2, …}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When templates功能：根据模块文件动态生成对应的配置文件 templates文件必须存放于templates目录下，且命名为 .j2 结尾 yaml/yml 文件需和templates目录平级，目录结构如下： 1234./├── temnginx.yml└── templates └── nginx.conf.j2 Playbook中template变更替换 Playbook中template算术运算 Templates示例利用templates 同步nginx配置文件，并修改配置文件nginx.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[root@centos7 playbook]#mkdir templates[root@centos7 playbook]#mv nginx.conf templates/nginx.conf.j2[root@centos7 playbook]#tree.├── test_templ.yml├── templates └── nginx.conf.j2[root@centos7 playbook]#vim test_templ.yml--- - hosts: appsrvs remote_user: root tasks: - name: install yum: name=nginx - name: template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart - name: service service: name=nginx state=started enabled=yes handlers: - name: restart service: name=nginx state=restarted[root@centos7 playbook]#ansible-playbook test_templ.yml.........省略结果[root@centos7 playbook]#ansible appsrvs -a 'ss -ntlp' #查看80端口是否开启[root@centos7 playbook]#ansible appsrvs -m shell -a 'ps axu | grep nginx'192.168.183.137 | CHANGED | rc=0 &gt;&gt;root 16688 0.0 0.1 120812 2228 ? Ss 21:15 0:00 nginx: master process /usr/sbin/nginxnginx 16689 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processnginx 16690 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processroot 16755 0.0 0.0 113172 1196 pts/1 S+ 21:15 0:00 /bin/sh -c ps axu | grep nginxroot 16757 0.0 0.0 112704 940 pts/1 S+ 21:15 0:00 grep nginx192.168.183.136 | CHANGED | rc=0 &gt;&gt;root 18759 0.0 0.1 122924 2100 ? Ss 20:46 0:00 nginx: master process /usr/sbin/nginxnginx 18760 0.0 0.1 125472 3540 ? S 20:46 0:00 nginx: worker processroot 36053 0.0 0.0 113128 1196 pts/1 S+ 21:15 0:00 /bin/sh -c ps axu | grep nginxroot 36055 0.0 0.0 112664 948 pts/1 S+ 21:15 0:00 grep nginx[root@centos7 playbook]#ansible appsrvs -m shell -a 'ps axu | grep nginx' 192.168.183.137 | CHANGED | rc=0 &gt;&gt;root 16688 0.0 0.1 120812 2228 ? Ss 21:15 0:00 nginx: master process /usr/sbin/nginxnginx 16689 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processnginx 16690 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processroot 16755 0.0 0.0 113172 1196 pts/1 S+ 21:15 0:00 /bin/sh -c ps axu | grep nginxroot 16757 0.0 0.0 112704 940 pts/1 S+ 21:15 0:00 grep nginx192.168.183.136 | CHANGED | rc=0 &gt;&gt;root 18759 0.0 0.1 122924 2100 ? Ss 20:46 0:00 nginx: master process /usr/sbin/nginxnginx 18760 0.0 0.1 125472 3540 ? S 20:46 0:00 nginx: worker processroot 36053 0.0 0.0 113128 1196 pts/1 S+ 21:15 0:00 /bin/sh -c ps axu | grep nginxroot 36055 0.0 0.0 112664 948 pts/1 S+ 21:15 0:00 grep nginx[root@centos7 playbook]#ansible appsrvs -m setup -a 'filter=ansible_processor_count'192.168.183.136 | SUCCESS =&gt; &#123; "ansible_facts": &#123; "ansible_processor_count": 1 &#125;, "changed": false&#125;192.168.183.137 | SUCCESS =&gt; &#123; "ansible_facts": &#123; "ansible_processor_count": 2 &#125;, "changed": false&#125;worker process 与 CPU数量一致[root@centos7 playbook]#vim templates/nginx.conf.j2.....省略.....worker_processes &#123;&#123; ansible_processor_count*2 &#125;&#125;; #Playbook中template算术运算.....省略.....[root@centos7 playbook]#ansible appsrvs -m shell -a 'ps axu | grep nginx' 192.168.183.136 | CHANGED | rc=0 &gt;&gt;root 18759 0.0 0.1 122924 2100 ? Ss 20:46 0:00 nginx: master process /usr/sbin/nginxnginx 18760 0.0 0.1 125472 3540 ? S 20:46 0:00 nginx: worker processnginx 18761 0.0 0.1 125472 3540 ? S 20:46 0:00 nginx: worker processroot 36485 0.0 0.0 113128 1196 pts/1 S+ 21:36 0:00 /bin/sh -c ps axu | grep nginxroot 36487 0.0 0.0 112664 944 pts/1 S+ 21:36 0:00 grep nginx192.168.183.137 | CHANGED | rc=0 &gt;&gt;root 16688 0.0 0.1 120812 2228 ? Ss 21:15 0:00 nginx: master process /usr/sbin/nginxnginx 16689 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processnginx 16690 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processnginx 16691 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processnginx 16692 0.0 0.1 123360 3524 ? S 21:15 0:00 nginx: worker processroot 17220 0.0 0.0 113172 1200 pts/1 S+ 21:36 0:00 /bin/sh -c ps axu | grep nginxroot 17222 0.0 0.0 112704 940 pts/1 S+ 21:36 0:00 grep nginx when&ensp;&ensp;&ensp;&ensp;条件测试:如果需要根据变量、 facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法格式 when语句在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法示例：12345678910111213141516171819202122232425[root@centos7 playbook]#tree templates/templates/├── httpd6.conf.j2└── httpd7.conf.j2[root@centos7 playbook]#vim httpd.yml ---- hosts: appsrvs remote_user: root tasks: - name: install yum: name=httpd - name: template1 template: src=httpd6.conf.j2 dest=/etc/httpd/conf/httpd.conf when: ansible_distribution_major_version=="6" notify: restart - name: template2 template: src=httpd7.conf.j2 dest=/etc/httpd/conf/httpd.conf when: ansible_distribution_major_version=="7" notify: restart - name: service service: name=httpd state=started enabled=yes handlers: - name: restart service: name=httpd state=restart 迭代：with_items迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为”item”要在task中使用with_items给定要迭代的元素列表列表格式： 字符串字典 示例：12345- name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - testuser1 - testuser2 迭代嵌套子变量例:123456789101112131415- hosts：websrvs remote_user: root tasks: - name: add groups group: name=&#123;&#123; item &#125;&#125; with_items: - group1 - group2 - group3 - name: add users user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; with_items: - &#123; name: 'user1', group: 'group1' &#125; - &#123; name: 'user2', group: 'group2' &#125; - &#123; name: 'user3', group: 'group3' &#125; roles&ensp;&ensp;&ensp;&ensp;ansible自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲,roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中。 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过includes即可实现 角色(roles)：角色集合roles/ mysql/ httpd/ nginx/ memcached/ roles目录结构每个角色，以特定的层级目录结构进行组织roles目录结构： playbook.ymlroles/project/tasks/files/vars/templates/handlers/default/ 不常用meta/ 不常用 Roles各目录作用/roles/project/ :项目名称,有以下子目录files/ ：存放由copy或script模块等调用的文件templates/：template模块查找所需要模板文件的目录tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含default/：设定默认变量时使用此目录中的main.yml文件 创建role创建role的步骤 创建以roles命名的目录 在roles目录中分别创建以各角色名称命名的目录，如webservers等 在每个角色命名的目录中分别创建files、 handlers、 meta、 tasks、templates和vars目录；用不到的目录可以创建为空目录，也可以不创建 在playbook文件中，调用各角色 针对大型项目使用Roles进行编排123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223[root@centos7 playbook]#mkdir roles[root@centos7 playbook]#mkdir roles/httpd[root@centos7 playbook]#tree roles/roles/└── httpd1 directories, 0 files[root@centos7 playbook]#mkdir roles/httpd/&#123;files,tasks,templates,handlers,vars&#125;[root@centos7 playbook]#tree roles/roles/└── httpd ├── files ├── handlers ├── tasks ├── templates └── vars6 directories, 0 files[root@centos7 playbook]#cd roles/httpd/[root@centos7 httpd]#tree.├── files├── handlers├── tasks├── templates└── vars5 directories, 0 files[root@centos7 httpd]#cd tasks/[root@centos7 tasks]#touch user.yml group.yml config.yml install.yml service.yml[root@centos7 tasks]#vim group.yml - name: useradd group group: name=apache system=yes gid=80 [root@centos7 tasks]#vim user.yml - name: useradd user user: name=apache group=apache shell=/sbin/nologin home=/usr/share/httpd system=yes [root@centos7 tasks]#vim install.yml - name: install package yum: name=httpd [root@centos7 tasks]#vim config.yml - name: config file copy: src=httpd.conf dest=/etc/httpd/conf/ backup=yes notify: restart [root@centos7 tasks]#vim service.yml - name: service service: name=httpd state=started enabled=yes[root@centos7 tasks]#lltotal 20-rw-r--r-- 1 root root 76 Nov 24 00:41 config.yml-rw-r--r-- 1 root root 61 Nov 24 00:30 group.yml-rw-r--r-- 1 root root 42 Nov 24 00:39 install.yml-rw-r--r-- 1 root root 62 Nov 24 00:42 service.yml-rw-r--r-- 1 root root 107 Nov 24 00:34 user.yml[root@centos7 tasks]#vim main.yml- include: group.yml- include: user.yml- include: install.yml- include: config.yml- include: service.yml [root@centos7 tasks]#cd ..[root@centos7 httpd]#vim handlers/main.yml- name: restart service: name=httpd state=restarted[root@centos7 httpd]#cp /etc/httpd/conf/httpd.conf files/[root@centos7 httpd]#tree.├── files│ └── httpd.conf├── handlers│ └── main.yml├── tasks│ ├── config.yml│ ├── group.yml│ ├── install.yml│ ├── main.yml│ ├── service.yml│ └── user.yml├── templates└── vars5 directories, 8 files [root@centos7 httpd]#cd ../../[root@centos7 playbook]#vim httpd_roles.yml---- hosts: appsrvs remote_user: root roles: - role: httpd [root@centos7 playbook]#ansible-playbook httpd_roles.yml把httpd的文件复制一份到nginx里，然后改改[root@centos7 roles]#cp -r httpd/ nginx/[root@centos7 roles]#tree.├── httpd│ ├── files│ │ └── httpd.conf│ ├── handlers│ │ └── main.yml│ ├── tasks│ │ ├── config.yml│ │ ├── group.yml│ │ ├── install.yml│ │ ├── main.yml│ │ ├── service.yml│ │ └── user.yml│ ├── templates│ └── vars└── nginx ├── files │ └── httpd.conf ├── handlers │ └── main.yml ├── tasks │ ├── config.yml │ ├── group.yml │ ├── install.yml │ ├── main.yml │ ├── service.yml │ └── user.yml ├── templates └── vars12 directories, 16 files[root@centos7 roles]#cd nginx/[root@centos7 nginx]#tree.├── files│ └── httpd.conf├── handlers│ └── main.yml├── tasks│ ├── config.yml│ ├── group.yml│ ├── install.yml│ ├── main.yml│ ├── service.yml│ └── user.yml├── templates└── vars5 directories, 8 files[root@centos7 nginx]#rm -f tasks/&#123;group,user&#125;.yml[root@centos7 nginx]#tree.├── files│ └── httpd.conf├── handlers│ └── main.yml├── tasks│ ├── config.yml│ ├── install.yml│ ├── main.yml│ └── service.yml├── templates└── vars5 directories, 6 files[root@centos7 nginx]#cp /etc/nginx/nginx.conf templates/nginx.conf.j2[root@centos7 nginx]#tree.├── files│ └── httpd.conf├── handlers│ └── main.yml├── tasks│ ├── config.yml│ ├── install.yml│ ├── main.yml│ └── service.yml├── templates│ └── nginx.conf.j2└── vars5 directories, 7 files[root@centos7 nginx]#cd tasks/[root@centos7 tasks]#tree.├── config.yml├── install.yml├── main.yml└── service.yml0 directories, 4 files[root@centos7 tasks]#vim config.yml - name: config file template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart[root@centos7 tasks]#vim install.yml - name: install package yum: name=nginx [root@centos7 tasks]#vim main.yml- include: install.yml - include: config.yml- include: service.yml[root@centos7 tasks]#vim service.yml - name: service service: name=nginx state=started enabled=yes [root@centos7 tasks]#cd ../../../[root@centos7 playbook]#vim nginx_roles.yml- hosts: appsrvs remote_user: root roles: - role: nginx [root@centos7 playbook]#ansible-playbook nginx_roles.yml]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>playbook</tag>
        <tag>role</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible基础及常用模块]]></title>
    <url>%2F2018%2F12%2F01%2FAnsible%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[Ansible的概念&ensp;&ensp;&ensp;&ensp;概念：是一个配置管理工具，是一个自动化运维工具，通过ssh实现配置管理、应用部署、任务执行等功能。要实现ansible，必须基于key验证作用：可以完成一些批量任务或者完成一些需要经常重复的工作 同时在100台服务器上安装服务，并在安装后启动服务将某个文件一次性拷贝到100台服务器上每当有新服务器加入工作环境时都要部署新的服务，也就是需要经常重复完成相同的工作 此时都可以用到ansible在复制文件到受控主机时，受控主机目录下有此文件则ansible不做任何处理，若没有则复制，这些功能是shell所不具备的 控制其他主机的主机叫主控端被控制的主机叫被控端 ansible 中小型企业500台主机左右saltstack 大型企业puppet 超大型企业 Ansible的配置文件使用ansible前必须做到：1、在主控机上安装ansible基于epel源1yum install ansible -y 2、在ansible配置文件中将受控主机写入”管理清单（/etc/ansible/hosts）”。 方式有两种： 文件配置如果安装后没有配置文件直接使用ansible则会出现如下提示：1234567891011121314151617181920212223[root@CentOS7 ~]#ansible 192.168.183.158 -m ping[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicitlocalhost does not match 'all'[WARNING]: Could not match supplied host pattern, ignoring: 192.168.183.148将受控主机的IP写入配置文件/etc/ansible/hosts的最底部如下：# Here's another example of host ranges, this time there are no# leading 0s:## db-[99:101]-node.example.com192.168.183.158 192.168.183.132[root@CentOS7 ~]#ansible 192.168.183.158,192.168.183.132 -m ping192.168.183.132 | UNREACHABLE! =&gt; &#123; "changed": false, "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n", "unreachable": true&#125;192.168.183.158 | UNREACHABLE! =&gt; &#123; "changed": false, "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n", "unreachable": true&#125; 因为ansible是基于ssh的，所以要把受控主机的相关信息也要写全如下12345678910111213## db-[99:101]-node.example.com192.168.183.148 ansible_port=22 ansible_user=root ansible_ssh_pass=123456192.168.183.132 ansible_port=22 ansible_user=root ansible_ssh_pass=123456 "/etc/ansible/hosts" 47L, 1165C written [root@CentOS6 ~]#ansible 192.168.183.148,192.168.183.132 -m ping 192.168.183.148 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125;192.168.183.132 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 如果受控主机较多这样配置显然是不可取的，大多数情况下都使用第二种方法基于秘钥认证基于秘钥认证(由于前文写过，这里简单描述下)首先执行ssh-kengen生成秘钥对将生成的秘钥发送给受控机 ssh-copy-id 192.168.183.158123456789[root@centos7 data]#ansible all -m ping 192.168.183.132 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125;192.168.183.158 | SUCCESS =&gt; &#123; "changed": false, "ping": "pong"&#125; 小结：在使用ansible时首先要安装包，然后将受控主机的IP写入配置文件/etc/ansible/hosts中，使用秘钥验证方式则首先要生成秘钥对ssh-keygen将生成的秘钥发送至受控主机ssh-copy-id IP ansible命令执行ansible命令执行过程加载自己的配置文件 默认/etc/ansible/ansible.cfg加载自己对应的模块文件，如command通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件给文件+x执行执行并返回结果删除临时py文件，sleep 0退出 执行状态：绿色：执行成功并且不需要做改变的操作黄色：执行成功并且对目标主机做变更红色：执行失败 ansible的Host-patternansible [-m module_name] [-a args]–version 显示版本ansible –version-v 详细过程 –vv -vvv更详细–list-hosts 显示主机列表，可简写 –list ansible all –list-hosts-u, –user=REMOTE_USER 执行远程执行的用户-k, –ask-pass 提示输入ssh连接密码，默认Key验证-K, –ask-become-pass 提示输入sudo时的口令 1234[root@centos7 ~]#ansible 192.168.183.158 -m ping -u xie -kSSH password:[root@centos7 ~]#ansible 192.168.183.158 -m ping -u xie -KSUDO password: -C, –check 检查，并不执行-T, –timeout=TIMEOUT 执行命令的超时时间，默认10s-b, –become 代替旧版的sudo 切换–become-user=USERNAME 指定sudo的runas用户，默认为root ansible all -m ping -u wang -k -b –become-user=mage All ：表示所有Inventory中的所有主机 ansible all –m ping * : 通配符 ansible “*” -m ping 或关系 ansible websrvs:appsrvs -m ping 逻辑与 ansible ‘websrvs:&amp;dbsrvs’ –m ping 在websrvs组并且在dbsrvs组中的主机 逻辑非 ansible ‘websrvs:!dbsrvs’ –m ping 在websrvs组，但不在dbsrvs组中的主机注意：此处为单引号 综合逻辑 ansible ‘websrvs:dbsrvs:&amp;appsrvs:!ftpsrvs’ –m ping 正则表达式 ansible ‘~(web|db).*.magedu.com’ –m ping 注：列表清单中最好都使用单引号 Ansible相关文件配置文件/etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性/etc/ansible/hosts 主机清单/etc/ansible/roles/ 存放角色的目录 程序/usr/bin/ansible 主程序，临时命令执行工具/usr/bin/ansible-doc 查看配置文档，模块功能查看工具/usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台/usr/bin/ansible-playbook 定制自动化任务，编排剧本工具/usr/bin/ansiblepull 远程执行命令的工具/usr/bin/ansible-vault 文件加密工具/usr/bin/ansible-console 基于Console界面与用户交互的执行工具 Ansible 配置文件/etc/ansible/ansible.cfg （一般保持默认）12345678910111213[defaults]#inventory = /etc/ansible/hosts 主机列表配置文件 #library = /usr/share/my_modules/ # 库文件存放目录 #remote_tmp = $HOME/.ansible/tmp #临时py命令文件存放在远程主机目录 #local_tmp = $HOME/.ansible/tmp # 本机的临时命令执行目录 #forks = 5 # 默认并发数 #sudo_user = root # 默认sudo 用户 #ask_sudo_pass = True #每次执行ansible命令是否询问ssh密码 #ask_pass = True #remote_port = 22 #host_key_checking = False # 检查对应服务器的host_key，建议取消注释 #log_path=/var/log/ansible.log #日志文件 #module_name = command #默认模块 主机清单inventoryansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory file中将其分组命名默认的inventory file为/etc/ansible/hostsinventory file可以有多个，且也可以通过Dynamic Inventory来动态生成 etc/ansible/hosts文件格式 inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中；此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号来标明123456[webservers] www1.magedu.com:2222 www2.magedu.com [dbservers]db1.magedu.comdb2.magedu.com 如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机1234[websrvs]www[01:100].example.com[dbsrvs]db-[a:f].example.com ansible-doc: 显示模块帮助ansible-doc [options] [module…]-a 显示所有模块的文档-l, –list 列出可用模块-s, –snippet显示指定模块的playbook片段示例： ansible-doc –l 列出所有模块ansible-doc ping 查看指定模块帮助用法ansible-doc –s ping 查看指定模块帮助用法ansible-vault 功能：管理加密解密yml文件ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密ansible-vault decrypt hello.yml 解密ansible-vault view hello.yml 查看ansible-vault edit hello.yml 编辑加密文件?ansible-vault rekey hello.yml 修改口令?ansible-vault create new.yml 创建新文件 Ansible-console：2.0+新增，可交互执行命令，支持tab root@test (2)[f:10] $ 执行用户@当前操作的主机组 (当前组的主机数量)[f:并发数]$设置并发数： forks n 例如： forks 10切换组： cd 主机组 例如： cd web列出当前组主机列表： list列出所有的内置命令： ?或help 示例：123root@all (2)[f:5]listroot@all(2)[f:5] cd appsrvsroot@appsrvs (2)[f:5]listroot@appsrvs(2)[f:5] yum name=httpd state=presentroot@appsrvs (2)[f:5]$ service name=httpd state=started ansible-galaxy连接 https://galaxy.ansible.com 下载相应的roles 安装galaxy ansible-galaxy install geerlingguy.redis 列出所有已安装的galaxy ansible-galaxy list 删除galaxy ansible-galaxy remove geerlingguy.redis 推送命令至远程，效率无限提升，对运维要求较高 ansible-pull ansible-playbook执行playbook示例：ansible-playbook hello.yml1234567cat hello.yml #hello world yml file - hosts: websrvs remote_user: root tasks: - name: hello world command: /usr/bin/wall hello world ansible常用模块Command：在远程主机执行命令，默认模块，可忽略-m选项123[root@centos ~]#ansible all -m command -a 'service vsftpd start'[root@centos ~]#ansible all -m command -a 'echo magedu |passwd --stdin xie'此命令不支持 $VARNAME &lt; &gt; | ; &amp; 等，用shell模块实现 Shell：和command相似，用shell执行命令12[root@centos7 ~]#ansible all -m shell -a 'echo magedu | passwd –stdin xie'调用bash执行命令 类似 cat /tmp/stanley.md | awk -F‘|’ ‘&#123;print 1,2&#125;’ &amp;&gt; /tmp/example.txt 这些复杂命令，即使使用shell也可能会失败，解决办法：写到脚本时，copy到远程，执行，再把需要的结果拉回执行命令的机器 Script：在远程主机上运行ansible服务器上的脚本12-a "/PATH/TO/SCRIPT_FILE“ansible websrvs -m script -a /data/f1.sh Copy：从服务器复制文件到客户端1234[root@centos7 ~]#ansible all -m copy -a "src=/root/f1 dest=/tmp/f2 owner=xie mode=600 backup=yes"如目标存在，默认覆盖，此处指定先备份[root@centos7 ~]#ansible all -m copy -a "content='test content\n' dest=/tmp/f1.txt"指定内容，直接生成目标文件 Fetch：从客户端取文件至服务器端，copy相反，目录可先tar1[root@centos7 ~]#ansible all -m fetch -a 'src=/root/a.sh dest=/data/scripts' File：设置文件属性123[root@centos7 ~]#ansible all -m file -a "path=/data/f1.txt owner=wang mode=755“[root@centos7 ~]#ansible all -m filw -a "path=/data/f1.txt state=touch"[root@centos7 ~]#ansible all -m file -a 'src=/data/f1.txt dest=/data/f1.txt-link state=link' Hostname：管理主机名1[root@centos7 ~]#ansible websrvs -m hostname -a "name=websrv" Cron：计划任务支持时间：minute，hour，day，month，weekday 创建任务1[root@centos7 ~]#ansible all -m cron -a "minute=*/5 job='/usr/sbin/ntpdate 172.16.0.1 &amp;&gt;/dev/null' name=Synctime" 删除任务1[root@centos7 ~]#ansible all -m cron -a 'state=absent name=Synctime' Yum：管理包12[root@centos7 ~]#ansible all -m yum -a 'name=httpd,memcached,vsftpd state=present' 安装 state=present可以省略不写,系统默认[root@centos7 ~]#ansible all -m yum -a 'name=httpd,memcached,vsftpd state=absent' 删除 Service：管理服务1234[root@centos ~]#ansible all -m service -a 'name=httpd state=stopped'[root@centos ~]#ansible all -m service -a 'name=httpd state=started enabled=yes' 启动服务，并且开机启动[root@centos ~]#ansible all -m service -a 'name=httpd state=reloaded'[root@centos ~]#ansible all -m service -a 'name=httpd state=restarted' User：管理用户1234[root@centos ~]#ansible all -m user -a 'name=user1 comment="test user" uid=2048 home=/app/user1 group=root shell=/sbin/nologin'[root@centos ~]#ansible all -m user -a 'name=sysuser1 system=yes home=/app/sysuser1'[root@centos ~]#ansible all -m user -a 'name=user1 state=absent remove=yes' 删除账号并且删除家目录 Group：管理组12[root@centos ~]#ansible all -m group -a "name=testgroup system=yes"[root@centos ~]#ansible all -m group -a "name=testgroup state=absent"]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNCP服务]]></title>
    <url>%2F2018%2F11%2F19%2FDHCP%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[网络配置&ensp;&ensp;&ensp;&ensp;DHCP前身是BOOTP，在Linux的网卡配置中也能看到显示的BOOTP，DHCP引进一个bootp没有的概念：租约。bootp分配的地址是永久的，而dhcp分配的地址是可以有期限的。12[root@CentOS6 ~]#grep -i bootproto /etc/sysconfig/network-scripts/ifcfg-eth0 BOOTPROTO=dhcp DHCP可以自动分配IP、子网掩码、网关、DNS。 DHCP客户端使用的端口68，服务端使用端口67，使用的UDP应用层的协议。 &ensp;&ensp;&ensp;&ensp;DHCP一般不为服务器分配IP，因为他们要使用固定IP，所以DHCP一般只为办公环境的主机分配IP。服务器一旦开机则自动分配IP，并有一定的租期，租期到了则收回，IP可以续租，续租失败则收回并重新分配，如果服务器关闭则收回IP，先到先得的原则，哪台主机先申请就优先分配，并且基于广播机制(DHCP服务器和客户端需要在一个局域网).但DHCP也可以为其他网段内主机分配IP，只要连接两个网段中间的路由器能转发DHCP配置请求即可，但这要求路由器配置中继功能。 续租&ensp;&ensp;&ensp;&ensp;50%：租赁时间达到50%时来续租，刚向DHCP服务器发向新的DHCPREQUEST请求。如果dhcp服务没有拒绝的理由，则回应DHCPACK信息。当DHCP客户端收到该应答信息后，就重新开始新的租用周期&ensp;&ensp;&ensp;&ensp;87.5%：如果之前DHCP Server没有回应续租请求，等到租约期的7/8时，主机会再发送一次广播请求 主要用途用于内部网络和网络服务供应商自动分配IP地址给用户用于内部网络管理员作为对所有电脑作集中管理的手段 使用场景自动化安装系统解决IPV4资源不足问题DHCP服务 DHCP的工作原理(前四种经常用到) DHCP DISCOVER：客户端到服务器，客户端设置为自动获取后一开机就会向网络发广播 DHCP OFFER ：服务器到客户端，如果网络中有DHCP服务器就会分配一个IP并同时在网络中进行标记此IP已被占用 DHCP REQUEST：客户端到服务器，网络中有多个DHCP同时分配IP，客户端这时就会选择一个最快到达的ip DHCP ACK ：服务器到客户端，服务器最终确认 DHCP NAK：服务器到客户端,通知用户无法分配合适的IP地址 DHCP DECLINE ：客户端到服务器，指示地址已被使用 DHCP RELEASE：客户端到服务器，放弃网络地址和取消剩余的租约时间 DHCP INFORM：客户端到服务器, 客户端如果需要从DHCP服务器端获取更为详细的配置信息，则发送Inform报文向服务器进行请求，极少用到 模拟dhcp的实现过程 准备：两台虚拟机（centos7模拟DHCP服务器，centos6模拟客户端）centos7本身使用静态获取，centos6为动态获取 并且为仅主机模式关闭防火墙 iptables -vnL清空防火墙 iptables -F关闭SELinux 检查状态getenforcevim /etc/sysconfig/selinux 改为SELinux=disabled 重启后生效对centos7设置，使其成为dhcp服务器 打开虚拟机—&gt;编辑—-&gt;虚拟网络设置—&gt;选中仅主机—&gt;取消下面DHCP设置 取消DHCP服务就意味着网络中没有了DHCP服务器，那么客户端如果设置DHCP获取那么是不能获取到IP 在客户机将其获取方式改为DHCP vim /etc/sysconfig/network-scripts/ifcfg-eth0 设置完之后重启，客户机将不能获取IP，因为网络中没有DHCP服务器 开始配置DHCP服务器（centos7）配置前首先安装包 12[root@cetos7 ~]#yum install dhcp -yLoaded plugins: fastestmirror, langpacks 在其他的服务安装后就可以开启服务，但dhcp比较特殊，所以此时应先复制模板到配置文件进行相关设置，然后再开启服务 如果此时开启服务肯定是失败的12[root@cetos7 ~]#systemctl start httpdFailed to start httpd.service: Unit not found. 复制模板12[root@cetos7 ~]#cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcpd.confcp: overwrite '/etc/dhcp/dhcpd.conf'? y 配置文件123456789101112[root@cetos7 ~]#vim /etc/dhcp/dhcpd.conf# No service will be given on this subnet, but declaring it helps the # DHCP server to understand the network topology.subnet 192.168.183.0 netmask 255.255.255.0 &#123; #添加网断及子网掩码 range 192.168.183.10 192.168.183.100; #指定ip范围 &#125;# This is a very basic subnet declaration.subnet 10.254.239.0 netmask 255.255.255.224 &#123; range 10.254.239.10 10.254.239.20; 重启服务1[root@centos ~]#systemctl restart dhcpd 重启完之后再次重启客户端(centos6),然后通过ifcongfig就能看见客户端获取到你指定范围内的ip了。至此已经实现一个模拟的DHCP服务器。]]></content>
      <categories>
        <category>dhcp</category>
      </categories>
      <tags>
        <tag>dhcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化安装系统]]></title>
    <url>%2F2018%2F11%2F18%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[kickstart安装步骤 自动化安装之前我们首先要使用相应的工具去生成相应的文件（应答文件），在我们的系统装好之后，在管理员的家目录下都有这样一个文件anaconda-ks.cfg,此文件中的 kickstart就是我们实现自动化安装的重要文件，那么在配置此文件之前首先要安装kickstart所依赖的服务的包system-config-kickstart使用此工具需要在图形界面下进行具体步骤如下： 首先安装包文件system-config-kickstart 1[root@CentOS6 ~]#yum install system-config-kickstart 安装之后在图形界面下打开system-config-kickstart 1[root@CentOS6 ~]#system-config-kickstart 1centos7上包安装界面时是空白的，此时需要把yum源的[base]改为[development] 查看下是否生成了ks.cfg文件 123456789[root@CentOS6 ~]#ll ks.cfg -rw-r--r-- 1 root root 1345 Nov 18 14:34 ks.cfg[root@CentOS6 ~]#mkdir -pv /var/www/html/ksdir/&#123;6,7&#125;mkdir: created directory `/var/www/html/ksdir'mkdir: created directory `/var/www/html/ksdir/6'mkdir: created directory `/var/www/html/ksdir/7'[root@CentOS6 ~]#mv ks.cfg /var/www/html/ksdir/6/ks_mini.cfg [root@CentOS6 ~]#ll /var/www/html/ksdir/6/ks_mini.cfg-rw-r--r-- 1 root root 1345 Nov 18 14:34 /var/www/html/ksdir/6/ks_mini.cfg 如果对ks_mini.cfg文件进行修改，格式出现错误势必后面的安装也不能正常进行，那么此时我们可以用ksvalidator来进行检查 格式：ksvalidator ks_mini.cfg 如果访问的时候出现没有权限的提示，首先查看该应答文件是否为644权限如果权限不是此时应该修改权限chmod 644 ks6_mini.cfg如果权限是644权限，那么此时应该关闭selinux 关闭方法：vim /etc/selinux/config 将SELINUX=enabled 改为SELINUX=disabled,重启即可 此时已经可以通过刚才生成的文件通过网络来实现自动化安装，点击启动，把刚才的虚拟机重启（此时就需要光盘引导） 此时当你按下ENTER之后，就意味着你可以去休息了，剩下的事情完全自动化安装了。 kickstart文件的格式 命令段：指明各种安装前配置，如键盘类型等 程序包段：指明要安装的程序包组或程序包，不安装的程序包等 12345%packages @group_name package -package%end 脚本段： %pre: 安装前脚本运行环境：运行于安装介质上的微型Linux环境 %post: 安装后脚本运行环境：安装完成的系统 命令段中的命令： 必备命令 authconfig: 认证方式配置authconfig –useshadow –passalgo=sha512bootloader：bootloader的安装位置及相关配置bootloader –location=mbr –driveorder=sda –append=”crashkernel=auto rhgb quiet”keyboard: 设定键盘类型lang: 语言类型part: 创建分区rootpw: 指明root的密码timezone: 时区 可选命令 install OR upgradetext: 文本安装界面networkfirewallselinuxhaltpoweroffrebootrepouser：安装完成后为系统创建新用户url: 指明安装源key –skip 跳过安装号码,适用于rhel版本 制作引导光盘和U盘创建引导光盘： 123456mkdir –pv /app/myisocp -r /misc/cd/isolinux/ /app/myiso/vim /app/myiso/isolinux/isolinux.cfginitrd=initrd.img text ks=cdrom:/myks.cfgcp /root/myks.cfg /app/myiso/mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V "CentOS 6.9 x86_64 boot" -b isolinux/isolinux.bin -c isolinux/boot.cat -o /root/boot.iso /app/myiso/ 注意：以上相对路径都是相对于光盘的根，和工作目录无关 创建U盘启动盘 1dd if=/dev/sr0 of=/dev/sdb mkisofs选项​ -o 指定映像文件的名称。​ -b 指定在制作可开机光盘时所需的开机映像文件。​ -c 制作可开机光盘时，会将开机映像文件中的 no-eltorito-catalog 全部内容作成一个文件。​ -no-emul-boot 非模拟模式启动。​ -boot-load-size 4 设置载入部分的数量​ -boot-info-table 在启动的图像中现实信息​ -R 或 -rock 使用 Rock RidgeExtensions​ -J 或 -joliet 使用 Joliet 格式的目录与文件名称​ -v 或 -verbose 执行时显示详细的信息​ -T 或 -translation-table 建立文件名的转换表，适用于不支持 Rock Ridge Extensions 的系统上 1234567891011121314151617181920212223[root@CentOS6 ~]#mkdir /data/iso[root@CentOS6 ~]#cp -r /misc/cd/isolinux/ /data/iso[root@CentOS6 ~]#tree /data/iso/data/iso└── isolinux├── boot.cat├── boot.msg├── grub.conf├── initrd.img├── isolinux.bin├── isolinux.cfg├── memtest├── splash.jpg├── TRANS.TBL├── vesamenu.c32└── vmlinuz1 directory, 11 files[root@CentOS6 ~]#cp /var/www/html/ksdir/6/ks_mini.cfg /data/iso/[root@CentOS6 iso]#mkdir ksdir[root@CentOS6 iso]#mv ks_mini.cfg ksdir/[root@CentOS6 iso]#lsisolinux ksdir]]></content>
      <categories>
        <category>kickstart</category>
      </categories>
      <tags>
        <tag>kickstart</tag>
        <tag>mkisofs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加密和安全]]></title>
    <url>%2F2018%2F11%2F13%2F%E5%8A%A0%E5%AF%86%E5%92%8C%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[对称加密算法对称加密 加密和解密使用同一个密钥特性： 加密、解密使用同一个密钥，效率高将原始数据分割成固定大小的块，逐个进行加密 缺陷： 密钥过多密钥分发数据来源无法确认 非对称加密算法公钥加密:密钥是成对出现1234[root@cetos7 ~]#cd /etc/ssh[root@cetos7 ssh]#ll-rw-r-----. 1 root ssh_keys 1679 Sep 25 11:01 ssh_host_rsa_key-rw-r--r--. 1 root root 382 Sep 25 11:01 ssh_host_rsa_key.pub 公钥：公开给所有人；public key私钥：自己留存，必须保证其私密性；secret key 特点：用公钥加密数据，只能使用与之配对的私钥解密；反之亦然 功能： 数字签名：主要在于让接收方确认发送方身份对称密钥交换：发送方用对方的公钥加密一个对称密钥后发送给对方数据加密：适合加密较小数据 缺点：密钥长，加密解密效率低下 非对称加密:基于一对公钥/密钥对用密钥对中的一个加密，另一个解密 实现加密： 接收者生成公钥/密钥对：P和S ;公开公钥P，保密密钥S发送者使用接收者的公钥来加密消息M ;将P(M)发送给接收者接收者使用密钥S来解密：M=S(P(M)) 实现数字签名 发送者生成公钥/密钥对：P和S ;公开公钥P，保密密钥S ;使用密钥S来加密消息M ;发送给接收者S(M)接收者使用发送者的公钥来解密M=P(S(M)) 数字签名 结合签名和加密 分离签名 单向散列(数字指纹) 将任意数据缩小成固定大小的“指纹” 任意长度输入固定长度输出若修改数据，指纹也会改变（“不会产生冲突”）无法从指纹中重新生成数据（“单向”） 功能：数据完整性 常见算法 md5: 128bits、 sha1: 160bits、 sha224、sha256、 sha384、 sha512 常用工具 md5sum | sha1sum [ –check ] fileopenssl、 gpgrpm -V 加密类型对比 加密速度 密钥数 分发难度 密钥安全性 对称加密 中 多 难，方式很多，很混乱 安全机制很不健全 单向加密 快 无 最简单，官网公布 不需要安全性 非对称加密 慢 少 中，通过CA分发 有健全的安全机制 密钥交换密钥交换：IKE（ Internet Key Exchange ） 公钥加密DH (Deffie-Hellman)：生成会话密钥， DH A: g,p 协商生成公开的整数g, 大素数pB: g,pA:生成隐私数据 :a (a&lt;p )，计算得出 g^a%p，发送给BB:生成隐私数据 :b,计算得出 g^b%p，发送给AA:计算得出 [(g^b%p)^a] %p = g^ab%p，生成为密钥B:计算得出 [(g^a%p)^b] %p = g^ab%p，生成为密钥 使用gpg实现对称加密 对称加密file文件 12gpg -c filenamels filename.gpg 在另一台主机上解密filename 1gpg -o file -d filename.gpg 使用gpg工具实现公钥加密在hostB主机上用公钥加密，在hostA主机上解密 在hostA主机上生成公钥/私钥对 1gpg –gen-key 在hostA主机上查看公钥 1gpg –list-keys 在hostA主机上导出公钥到/data/magedupubkey 1gpg -a –export -o /data/magedupubkey 从hostA主机上复制公钥文件到需加密的B主机上 1scp magedupubkey hostB: 在需加密数据的hostB主机上生成公钥/私钥对 12gpg –list-keysgpg –gen-key 在hostB主机上导入公钥 12gpg –import magedupubkeygpg –list-keys 用从hostA主机导入的公钥，加密hostB主机的文件file,生成file.gpg 12gpg -e -r magedu f1.txtf1.txt.gpg 复制加密文件到hostA主机 1scp f1.txt.gpg hostA: 在hostA主机解密文件 1gpg -o f1.txt -d f1.txt.gpg 删除公钥和私钥(先删除私钥再删公钥) 12gpg –delete-secret-keys wangegpg –delete-keys wange 中间人攻击 CA和证书PKI: Public Key Infrastructure 签证机构：CA（Certificate Authority）注册机构：RA证书吊销列表：CRL证书存取库： 证书获取证书类型： 证书授权机构的证书服务器用户证书获取证书两种方法： 使用证书授权机构 生成证书请求（csr） 将证书请求csr发送给CA CA签名颁发证书 自签名的证书 自已签发自己的公钥 安全协议SSL功能：机密性，认证，完整性，重放保护两阶段协议，分为握手阶段和应用阶段 握手阶段(协商阶段):客户端和服务器端认证对方身份（依赖于PKI体系，利用数字证书进行身份认证），并协商通信中使用的安全参数、密码套件以及主密钥。 后续通信使用的所有密钥都是通过MasterSecret生成。 应用阶段:在握手阶段完成后进入，在应用阶段通信双方使用握手阶段协商好的密钥进行安全通信 SSL/TLS Handshake协议：包括协商安全参数和密码套件、服务器身份认证（客户端身份认证可选）、密钥交换 ChangeCipherSpec 协议：一条消息表明握手协议已经完成 Alert 协议：对握手协议中一些异常的错误提醒，分为fatal和warning两个级别，fatal类型错误会直接中断SSL链接，而warning级别的错误SSL链接仍可继续，只是会给出错误警告 Record 协议：包括对消息的分段、压缩、消息认证和完整性保护、加密等 HTTPS 协议：就是“HTTP 协议”和“SSL/TLS 协议”的组合。 HTTP overSSL” 或“HTTP over TLS” ，对http协议的文本数据进行加密处理后，成为二进制形式传输 openssl命令两种运行模式：交互模式和批处理模式openssl version：程序版本号 12[root@cetos7 ~]#openssl versionOpenSSL 1.0.2k-fips 26 Jan 2017 对称加密： 工具：openssl enc, gpg 算法：3des, aes, blowfish, twofish enc命令加密：openssl enc -e -des3 -a -salt -in filename -out filename.enc解密：openssl enc -d -des3 -a -salt –in filename.enc -out filename 单向加密： 工具：md5sum, sha1sum, sha224sum,sha256sum… dgst命令：openssl dgst -md5 [-hex默认] filenamemd5sum filename 生成用户密码 passwd命令: openssl passwd -1 openssl passwd -1 -salt “SALT(最多8位)” 生成随机数 openssl rand -base64|-hex NUM NUM: 表示字节数,使用-hex,每个字符为十六进制,相当于4位二进制,出现的字符数为NUM*2 1234[root@cetos7 ~]#openssl rand -base64 3n5c0[root@cetos7 ~]#openssl rand -hex 3a8e1d2 公钥加密 算法：RSA, ELGamal 工具：gpg, openssl rsautl（man rsautl） 数字签名 算法：RSA, DSA, ELGamal 密钥交换： 算法：dh 生成私钥openssl genrsa -out /PATH/TO/PRIVATEKEY.FILE NUM_BITS 1[root@centos~]#openssl genrsa -out test.key 1024 (umask 077; openssl genrsa –out test.key –des 2048) 加密 1[root@centos~]#(umask 077;openssl genrsa -out test.key -des 2048) openssl rsa -in test.key –out test.bak 将加密key解密 1[root@centos~]#openssl rsa -in test.key -out test.bak 从私钥中提取出公钥 openssl rsa –in test.key –pubout –out test.key.pub 12&gt; [root@centos~]#openssl rsa -in test.key -pubout -out test.key.pub&gt; 随机数生成器：伪随机数字 键盘和鼠标，块设备中断 /dev/random：仅从熵池返回随机数；随机数用尽，阻塞 /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机数,非阻塞OpenSSL 创建CA和申请证书1、创建所需要的文件 12touch /etc/pki/CA/index.txt 生成证书索引数据库文件echo 01 &gt; /etc/pki/CA/serial 指定第一个颁发证书的序列号 2、CA自签证书2.1、生成私钥 12cd /etc/pki/CA/(umask 066; openssl genrsa -out private/cakey.pem 2048) 2.2、生成自签名证书 1openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 3650 -out /etc/pki/CA/cacert.pem 选项说明： ​ -new：生成新证书签署请求 ​ -x509：专用于CA生成自签证书 ​ -key：生成请求时用到的私钥文件 ​ -days n：证书的有效期限 ​ -out /PATH/TO/SOMECERTFILE: 证书的保存路径 3、颁发证书 3.1、在需要使用证书的主机生成证书请求给web服务器生成私钥 1(umask 066; openssl genrsa –out /data/test.key 2048) 3.2、生成证书申请文件 1openssl req -new -key /data/test.key -out /data/test.csr 3.3、将证书请求文件传输给CA 3.4、CA签署证书，并将证书颁发给请求者 1openssl ca -in /tmp/test.csr –out /etc/pki/CA/certs/test.crt -days 100 注意：默认要求 国家，省，公司名称三项必须和CA一致创建CA和证书管理 3.5、查看证书中的信息： 12openssl x509 -in /PATH/FROM/CERT_FILE -noout -text|issuer|subject|serial|datesopenssl ca -status SERIAL 查看指定编号的证书状态 4、吊销证书 123openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem指定第一个吊销证书的编号,注意：第一次更新证书吊销列表前，才需要执行echo 01 &gt; /etc/pki/CA/crlnumber 更新证书吊销列表 1openssl ca -gencrl -out /etc/pki/CA/crl.pem 查看crl文件： 1openssl crl -in /etc/pki/CA/crl.pem -noout -text SSH(22/tcp) 具体的软件实现： OpenSSH: ssh协议的开源实现，CentOS默认安装dropbear：另一个开源实现 两种方式的用户登录认证： 基于password基于key Openssh软件组成 相关包： openssh openssh-clients openssh-server 工具： 基于C/S结构 Client: ssh, scp, sftp，sloginWindows客户端:xshell, putty, securecrt, sshsecureshellclientServer: sshd ssh客户端 允许实现对远程系统经验证地加密安全访问 当用户远程连接ssh服务器时，会复制ssh服务器/etc/ssh/ssh_host*key.pub（CentOS7默认是ssh_host_ecdsa_key.pub）文件中的公钥到客户机的~./ssh/know_hosts中。下次连接时，会自动匹配相应私钥，不能匹配，将拒绝连接 客户端组件： ​ ssh, 配置文件：/etc/ssh/ssh_config​ Host PATTERN​ StrictHostKeyChecking no 首次登录不显示检查提示格式： 12ssh [user@]host [COMMAND]ssh [-l user] host [COMMAND] 常见选项 ​ -p port：远程服务器监听的端口​ -b：指定连接的源IP​ -v：调试模式​ -C：压缩方式​ -X：支持x11转发​ -t：强制伪tty分配ssh -t remoteserver1 ssh -t remoteserver2 ssh remoteserver3 ssh服务登录验证方式：基于用户和口令登录验证 客户端发起ssh请求，服务器会把自己的公钥发送给用户用户会根据服务器发来的公钥对密码进行加密加密后的信息回传给服务器，服务器用自己的私钥解密，如果密码正确，则用户登录成功 基于密钥的登录方式 首先在客户端生成一对密钥（ssh-keygen）并将客户端的公钥ssh-copy-id 拷贝到服务端当客户端再次发送一个连接请求，包括ip、用户名服务端得到客户端的请求后，会到authorized_keys中查找，如果有响应的IP和用户，就会随机生成一个字符串，例如：magedu服务端将使用客户端拷贝过来的公钥进行加密，然后发送给客户端得到服务端发来的消息后，客户端会使用私钥进行解密，然后将解密后的字符串发送给服务端服务端接受到客户端发来的字符串后，跟之前的字符串进行对比，如果一致，就允许免密码登录 基于key认证 在客户端生成密钥对 1ssh-keygen -t rsa [-P ‘’][-f “~/.ssh/id_rsa”] 把公钥文件传输至远程服务器对应用户的家目录 1ssh-copy-id [-i [identity_file]][user@]host 重设私钥口令： 1ssh-keygen –p 验证代理（authentication agent）保密解密后的密钥 • 这样口令就只需要输入一次 • 在GNOME中，代理被自动提供给root用户 • 否则运行ssh-agent bash 钥匙通过命令添加给代理 1ssh-add rsync命令基于ssh和rsh服务实现高效率的远程系统之间复制文件使用安全的shell连接做为传输方式 1rsync -av /etc server1:/tmp 复制目录和目录下文件 例： 123456789101112131415[root@CentOS6 data]#ll ssltotal 12-rw-r--r--. 1 root root 3715 Nov 14 12:27 app.crt-rw-r--r--. 1 root root 655 Nov 14 08:52 app.csr-rw-------. 1 root root 887 Nov 14 08:48 app.key[root@CentOS6 data]#rsync -av /data/ssl 192.168.183.148:/dataroot@192.168.183.148's password: sending incremental file listssl/ssl/app.crtssl/app.csrssl/app.keysent 5472 bytes received 73 bytes 528.10 bytes/sectotal size is 5257 speedup is 0.95 1rsync -av /etc/ server1:/tmp 只复制目录下文件 例： 12345678910[root@CentOS6 data]#rsync -av /data/ssl/ 192.168.183.148:/dataroot@192.168.183.148's password: sending incremental file list./app.crtapp.csrapp.keysent 5460 bytes received 72 bytes 1229.33 bytes/sectotal size is 5257 speedup is 0.95 比scp更快，只复制不同的文件常用选项： ​ -n 模拟复制过程​ -v 显示详细过程​ -r 递归复制目录树​ -p 保留权限​ -t 保留时间戳​ -g 保留组信息​ -o 保留所有者信息​ -l 将软链接文件本身进行复制（默认）​ -L 将软链接文件指向的文件复制​ -a 存档，相当于–rlptgoD，但不保留ACL（-A）和SELinux属性（-X） pssh工具pssh是一个python编写可以在多台服务器上执行命令的工具，也可实现文件复制选项如下：​ –version：查看版本​ -h：主机文件列表，内容格式” [user@]host[:port]”​ -H：主机字符串，内容格式” [user@]host[:port]”​ -A：手动输入密码模式​ -i：每个服务器内部处理信息输出​ -l：登录使用的用户名​ -p：并发的线程数【可选】​ -o：输出的文件目录【可选】​ -e：错误输入文件【可选】​ -t：TIMEOUT 超时时间设置，0无限制【可选】​ -O：SSH的选项​ -P：打印出服务器返回信息​ -v：详细模式 pssh示例 通过pssh批量关闭seLinux pssh -H root@192.168.183.158 -i “sed-i “s/SELINUX=enforcing/SELINUX=disabled/“ /etc/selinux/config” 123&gt; [root@cetos7 ~]#pssh -H root@192.168.183.158 -i "sed -i "s/SELINUX=enforcing/SELINUX=disabled/" /etc/selinux/config"&gt; [1] 20:25:13 [SUCCESS] root@192.168.183.158&gt; 批量发送指令 pssh -H root@192.168.1.10 -i setenforce 0pssh -H wang@192.168.1.10 -i hostname 当不支持ssh的key认证时，通过 -A选项，使用密码认证批量执行指令 pssh -H wang@192.168.1.10 -A -i hostname 将标准错误和标准正确重定向都保存至/app目录下 pssh -H 192.168.1.10 -o /app -e /app -i “hostname” SSH端口转发 SSH会自动加密和解密所有SSH客户端与服务端之间的网络数据。但是SSH还能够将其他TCP端口的网络数据通过SSH链接来转发，并且自动提供了相应的加密及解密服务。这一过程也被叫做“隧道”（tunneling),这是因为 SSH 为其他TCP链接提供了一个安全的通道来进行传输而得名。例如Telnet，SMTP，LDAP这些TCP应用均能够从中得益，避免了用户名，密码以及隐私信息的明文传输。而与此同时，如果工作环境中的防火墙限制了一些网络端口的使用，但是允许SSH的连接，也能够通过将TCP端口转发来使用SSH进行通讯 SSH 端口转发能够提供两大功能： 加密 SSH Client 端至 SSH Server 端之间的通讯数据突破防火墙的限制完成一些之前无法建立的 TCP 连接SSH端口转发 本地转发： -L localport:remotehost:remotehostport sshserver 选项： ​ -f 后台启用 ​ -N 不打开远程shell，处于等待状态 ​ -g 启用网关功能 示例 1234567891011ssh –L 9527:telnetsrv:23 -Nfg sshsrvtelnet 127.0.0.1 9527 ​``` 当访问本机的9527的端口时，被加密后转发到sshsrv的ssh服务，再解密被转发到telnetsrv:23&gt;data &lt;--&gt; localhost:9527 &lt;--&gt; localhost:XXXXX &lt;--&gt; sshsrv:22 &lt;--&gt; sshsrv:YYYYY &lt;--&gt; telnetsrv:232. 远程转发:-R sshserverport:remotehost:remotehostport sshserver 示例：​```bashssh –R 9527:telnetsrv:23 –Nf sshsrv 让sshsrv侦听9527端口的访问，如有访问，就加密后通过ssh服务转发请求到本机ssh客户端，再由本机解密后转发到telnetsrv:23 Data sshsrv:9527 sshsrv:22 localhost:XXXXX localhost:YYYYY telnetsrv:23 动态端口转发： 当用firefox访问internet时，本机的1080端口做为代理服务器，firefox的访问请求被转发到sshserver上，由sshserver替之访问internet ssh -D 1080 root@sshserver -fNg在本机firefox设置代理socket proxy:127.0.0.1:1080curl –socks5 127.0.0.1:1080 http://www.qq.com X 协议转发 所有图形化应用程序都是X客户程序 能够通过tcp/ip连接远程X服务器数据没有加密机，但是它通过ssh连接隧道安全进行 ssh -X user@remotehost geditremotehost主机上的gedit工具，将会显示在本机的X服务器上传输的数据将通过ssh连接加密 ssh服务器服务器端：sshd 配置文件: /etc/ssh/sshd_config常用参数：PortListenAddress ipLoginGraceTime 2mPermitRootLogin yesStrictModes yes 检查.ssh/文件的所有者，权限等MaxAuthTries 6MaxSessions 10 同一个连接最大会话PubkeyAuthentication yesPermitEmptyPasswords noPasswordAuthentication yesGatewayPorts noClientAliveInterval 单位:秒ClientAliveCountMax 默认3UseDNS yesGSSAPIAuthentication yes 提高速度可改为noMaxStartups 未认证连接最大值，默认值10Banner /path/file 登录提示信息限制可登录用户的办法： AllowUsers user1 user2 user3DenyUsersAllowGroupsDenyGroup sssh服务的最佳实践建议使用非默认端口禁止使用protocol version 1限制可登录用户设定空闲会话超时时长利用防火墙设置ssh访问策略仅监听特定的IP地址基于口令认证时，使用强密码策略 tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c 12| xargs使用基于密钥的认证禁止使用空密码禁止root用户直接登录限制ssh的访问频度和并发在线数经常分析日志 编译安装dropbearssh协议的另一个实现：dropbear 源码编译安装：12345678910111. 安装开发包组:yum groupinstall "Development tools" 2. 下载dropbear-2017.75.tar.bz2 wget https://matt.ucc.asn.au/dropbear/dropbear-2017.75.tar.bz23. tar xf dropbear-2017.75.tar.bz2 4. cat INSTALL cat README 5. ./configure --prefix=/app/dropbear --sysconfdir=/etc/dropbear6. make PROGRAMS="dropbear dbclient dropbearkey dropbearconvert scp" 7. make PROGRAMS="dropbear dbclient dropbearkey dropbearconvert scp" install 启动ssh服务：12345678910111213141. ls /app/dropbear/sbin/ /app/dropbear/bin/ 2. /app/dropbear/sbin/dropbear -h 3. mkdir /etc/dropbear 4. cd /app/dropbear/binecho 'PATH=$PATH:/app/dropbear/bin:/app/dropbear/sbin' &gt; /etc/profile.d/dropbear.shdropbearkey -t rsa -f /etc/dropbear/dropbear_rsa_host_key 5. cd /app/dropbear/sbindropbear -p :2222 -F –E #前台运行 dropbear -p :2222 #后台运行6. 客户端访问：ssh -p 2222 root@127.0.0.1 或者cd /app/dropbear/bindbclient 127.0.0.1 AIDE 当一个入侵者进入了你的系统并且种植了木马，通常会想办法来隐蔽这个木马（除了木马自身的一些隐蔽特性外,他会尽量给你检查系统的过程设置障碍),通常入侵者会修改一些文件,比如管理员通常用ps -aux来查看系统进程，那么入侵者很可能用自己经过修改的ps程序来替换掉你系统上的ps程序，以使用ps命令查不到正在运行的木马程序。如果入侵者发现管理员正在运行crontab作业,也有可能替换掉crontab程序等等。所以由此可以看出对于系统文件或是关键文件的检查是很必要的.目前就系统完整性检查的工具用的比较多的有两款:Tripwire和AIDE，前者是一款商业软件,后者是一款免费的但功能也很强大的工具. AIDE:高级入侵检测环境)是一个入侵检测工具，主要用途是检查文件的完整性，审计计算机上的那些文件被更改过了. AIDE能够构造一个指定文件的数据库，它使用aide.conf作为其配置文件。 AIDE数据库能够保存文件的各种属性，包括：权限(permission)、索引节点序号(inode number)、所属用户(user)、所属用户组(group)、文件大小、最后修改时间(mtime)、创建时间(ctime)、最后访问时间(atime)、增加的大小以及连接数。 AIDE还能够使用下列算法：sha1、 md5、 rmd160、 tiger，以密文形式建立每个文件的校验码或散列号 这个数据库不应该保存那些经常变动的文件信息，例如：日志文件、邮件、 /proc文件系统、用户起始目录以及临时目录. 安装 yum install aide 修改配置文件 vim /etc/aide.conf (指定对哪些文件进行检测) /test/chameleon R/bin/ps R+a/usr/bin/crontab R+a/etc PERMS!/etc/mtab #“!” 表示忽略这个文件的检查R=p+i+n+u+g+s+m+c+md5权限+索引节点+链接数+用户+组+大小+最后一次修改时间+创建时间+md5校验值NORMAL = R+rmd60+sha256 初始化默认的AIDE的库： aide –init 生成检查数据库（建议初始数据库存放到安全的地方） cd /var/lib/aidemv aide.db.new.gz aide.db.gz 检测： aide –check/-C 更新数据库 aide –update sudo sudo能够授权指定用户在指定主机上运行某些命令。 如果未授权用户尝试使用 sudo，会提示联系管理员 sudo可以提供日志，记录每个用户使用sudo操作 sudo为系统管理员提供配置文件，允许系统管理员集中地管理用户的使用权限和使用的主机 sudo使用时间戳文件来完成类似“检票”的系统，默认存活期为5分钟的“入场券” 通过visudo命令编辑配置文件，具有语法检查功能 visudo –c 检查语法visudo -f /etc/sudoers.d/test 配置文件：/etc/sudoers, /etc/sudoers.d/ 时间戳文件：/var/db/sudo 日志文件：/var/log/secure 配置文件支持使用通配符glob 123456？:任意单一字符*：匹配任意长度字符[wxc]: 匹配其中一个字符[!wxc]: 除了这三个字符的其它字符\x : 转义[[alpha]] :字母 示例： /bin/ls [[alpha]]* 配置文件规则有两类 ​ 1、别名定义:不是必须的​ 2、授权规则:必须的授权规则格式 ： ​ 用户 登入主机=(代表用户) 命令示例： ​ root ALL=(ALL) ALL格式说明： ​ user: 运行命令者的身份​ host: 通过哪些主机​ (runas)：以哪个用户的身份​ command: 运行哪些命令 别名 Users和runas: username#uid%group_name%#giduser_alias|runas_alias host: ip或hostnamenetwork(/netmask)host_alias *command: command namedirectorysudoeditCmnd_Alias sudo别名和示例 别名有四种类型：User_Alias, Runas_Alias, Host_Alias ，Cmnd_Alias 别名格式：A-Z* 别名定义： Alias_Type NAME1 = item1, item2, item3 : NAME2 = item4, item5 示例1： Student ALL=(ALL) ALL%wheel ALL=(ALL) ALL 示例2： student ALL=(root) /sbin/pidof,/sbin/ifconfig%wheel ALL=(ALL) NOPASSWD: ALL 示例3 User_Alias NETADMIN= netuser1,netuser2Cmnd_Alias NETCMD = /usr/sbin/ipNETADMIN ALL=（root） NETCMD 示例4 User_Alias SYSADER=wang,mage,%adminsUser_Alias DISKADER=tomHost_Alias SERS=www.magedu.com,172.16.0.0/24Runas_Alias OP=rootCmnd_Alias SYDCMD=/bin/chown,/bin/chmodCmnd_Alias DSKCMD=/sbin/parted,/sbin/fdiskSYSADER SERS= SYDCMD,DSKCMDDISKADER ALL=(OP) DSKCMD 示例5 User_Alias ADMINUSER = adminuser1,adminuser2Cmnd_Alias ADMINCMD = /usr/sbin/useradd，/usr/sbin/usermod,/usr/bin/passwd [a-zA-Z]*, !/usr/bin/passwd rootADMINUSER ALL=(root) NOPASSWD:ADMINCMD，PASSWD:/usr/sbin/userdel 示例6 Defaults:wang runas_default=tomwang ALL=(tom,jerry) ALL 示例7 wang 192.168.1.6,192.168.1.8=(root) /usr/sbin/,!/usr/sbin/useradd 示例8 wang ALL=(ALL) /bin/cat /var/log/messages* sudo命令ls -l /usr/bin/sudosudo –i –u wang 切换身份sudo [-u user] COMMAND -V 显示版本信息等配置信息-u user 默认为root-l,ll 列出用户在主机上可用的和被禁止的命令-v 再延长密码有效期限5分钟,更新时间戳-k 清除时间戳（1970-01-01），下次需要重新输密码-K 与-k类似，还要删除时间戳文件-b 在后台执行指令-p 改变询问密码的提示符号示例：-p “password on %h for user %p:” TCP_Wrappers 工作在第四层（传输层）的TCP协议 对有状态连接的特定服务进行安全检测并实现访问控制 以库文件形式实现 某进程是否接受libwrap的控制取决于发起此进程的程序在编译时是否针对libwrap进行编译的 判断服务程序是否能够由tcp_wrapper进行访问控制的方法： ldd /PATH/TO/PROGRAM|grep libwrap.sostrings PATH/TO/PROGRAM|grep libwrap.so TCP_Wrappers的使用 配置文件：/etc/hosts.allow, /etc/hosts.deny 检查顺序：hosts.allow，hosts.deny 注意：一旦前面规则匹配，直接生效，将不再继续（默认允许） 基本语法: daemon_list@host: client_list [ :options :option… ] Daemon_list@host格式 单个应用程序的二进制文件名，而非服务名，例如vsftpd 以逗号或空格分隔的应用程序文件名列表，如:sshd,vsftpd ALL表示所有接受tcp_wrapper控制的服务程序 主机有多个IP，可用@hostIP来实现控制 如：in.telnetd@192.168.0.254 客户端Client_list格式 以逗号或空格分隔的客户端列表基于IP地址：192.168.10.1 192.168.1.基于主机名：www.magedu.com .magedu.com 较少用基于网络/掩码：192.168.0.0/255.255.255.0基于net/prefixlen: 192.168.1.0/24（CentOS7）基于网络组（NIS 域）：@mynetwork内置ACL：ALL，LOCAL，KNOWN，UNKNOWN，PARANOIDEXCEPT用法：示例：vsftpd: 172.16. EXCEPT 172.16.100.0/24 EXCEPT 172.16.100.1示例：只允许192.168.1.0/24的主机访问sshd 12345&gt; /etc/hosts.allow &gt; sshd: 192.168.1. &gt; /etc/hosts.deny &gt; sshd :ALL&gt; 示例：只允许192.168.1.0/24的主机访问telnet和vsftpd服务 1234/etc/hosts.allowvsftpd,in.telnetd: 192.168.1./etc/host.deny vsftpd,in.telnetd: ALL [:options]选项： deny 主要用在/etc/hosts.allow定义“拒绝”规则 如：vsftpd: 172.16. :deny allow 主要用在/etc/hosts.deny定义“允许” 规则 如：vsftpd:172.16. :allow spawn 启动一个外部程序完成执行的操作 示例 1sshd: ALL :spawn echo "$(date +%%F) login attempt from %c to %s,%d" &gt;&gt; /var/log/sshd.log 说明：在/etc/hosts.allow中添加，允许登录，并记录日志在/etc/hosts.deny中添加，拒绝登录，并记录日志 %c 客户端信息%s 服务器端信息%d 服务名%p 守护进程的PID%% 表示% twist 实际动作是拒绝访问,使用指定操作替换当前服务,标准输出和ERROR 发送到客户端,默认至/dev/null 12&gt; vsftpd: 172.16. :twist /bin/echo "connection prohibited"&gt; PAM模块 认证库：文本文件，MySQL，NIS，LDAP等 Sun公司于1995 年开发的一种与认证相关的通用框架机制 PAM 是关注如何为服务验证用户的 API，通过提供一些动态链接库和一套统一的API，将系统提供的服务和该服务的认证方式分开.使得系统管理员可以灵活地根据需要给不同的服务配置不同的认证方式而无需更改服务程序 一种认证框架，自身不做认证 它提供了对所有服务进行认证的中央机制，适用于本地登录，远程登录，如：telnet,rlogin,fsh,ftp,点对点协议PPP，su等应用程序中，系统管理员通过PAM配置文件来制定不同应用程序的不同认证策略；应用程序开发者通过在服务程序中使用PAM API(pam_xxxx( ))来实现对认证方法的调用；而PAM服务模块的开发者则利用PAM SPI来编写模块（主要调用函数pam_sm_xxxx( )供PAM接口库调用，将不同的认证机制加入到系统中；PAM接口库（libpam）则读取配置文件，将应用程序和相应的PAM服务模块联系起来 PAM架构 PAM相关文件 模块文件目录：/lib64/security/*.so 环境相关的设置：/etc/security/ 123456789101112131415161718[root@cetos7 bin]#cd /lib64/security/[root@cetos7 security]#lspam_access.so pam_gdm.so pam_permit.so pam_time.sopam_cap.so pam_gnome_keyring.so pam_postgresok.so pam_timestamp.sopam_chroot.so pam_group.so pam_pwhistory.so pam_tty_audit.sopam_console.so pam_issue.so pam_pwquality.so pam_umask.sopam_cracklib.so pam_keyinit.so pam_rhosts.so pam_unix_acct.sopam_debug.so pam_lastlog.so pam_rootok.so pam_unix_auth.sopam_deny.so pam_limits.so pam_securetty.so pam_unix_passwd.sopam_echo.so pam_listfile.so pam_selinux_permit.so pam_unix_session.sopam_env.so pam_localuser.so pam_selinux.so pam_unix.sopam_exec.so pam_loginuid.so pam_sepermit.so pam_userdb.sopam_faildelay.so pam_mail.so pam_shells.so pam_warn.sopam_faillock.so pam_mkhomedir.so pam_sss.so pam_wheel.sopam_filter pam_motd.so pam_stress.so pam_xauth.sopam_filter.so pam_namespace.so pam_succeed_if.sopam_fprintd.so pam_nologin.so pam_systemd.sopam_ftp.so pam_oddjob_mkhomedir.so pam_tally2.so 主配置文件:/etc/pam.conf，默认不存在 为每种应用模块提供一个专用的配置文件：/etc/pam.d/APP_NAME 注意：如/etc/pam.d存在，/etc/pam.conf将失效pam认证原理 123456789101112[root@cetos7 security]#cd /etc/pam.d/[root@cetos7 pam.d]#lsatd gdm-launch-environment pluto smartcard-auth system-auth-acchfn gdm-password polkit-1 smartcard-auth-ac systemd-userchsh gdm-pin postlogin smtp vlockconfig-util gdm-smartcard postlogin-ac smtp.postfix vmtoolsdcrond liveinst ppp sshd vsftpdcups login remote su xserverfingerprint-auth other runuser sudofingerprint-auth-ac passwd runuser-l sudo-igdm-autologin password-auth screen su-lgdm-fingerprint password-auth-ac setup system-auth PAM认证原理 PAM认证一般遵循这样的顺序：Service(服务)→PAM(配置文件)→pam_*.so PAM认证首先要确定那一项服务，然后加载相应的PAM的配置文件(位于/etc/pam.d下)，最后调用认证文件(位于/lib/security下)进行安全认证 PAM配置文件详解专用配置文件/etc/pam.d/* 格式type control module-path arguments说明： 模块类型（module-type） Auth 账号的认证和授权Account 与账号管理相关的非认证类的功能，如：用来限制/允许用户对某个服务的访问时间，当前有效的系统资源(最多可以有多少个用户)，限制用户的位置(例如：root用户只能从控制台登录)Password 用户修改密码时密码复杂度检查机制等功能Session 用户获取到服务之前或使用服务完成之后需要进行一些附加的操作，如：记录打开/关闭数据的信息，监视目录等-type 表示因为缺失而不能加载的模块将不记录到系统日志,对于那些不总是安装在系统上的模块有用 Control: PAM库如何处理与该服务相关的PAM模块成功或失败情况 两种方式实现：简单和复杂 简单方式实现：一个关健词实现 required ：一票否决，表示本模块必须返回成功才能通过认证，但是如果该模块返回失败，失败结果也不会立即通知用户，而是要等到同一type中的所有模块全部执行完毕再将失败结果返回给应用程序，即为必要条件requisite ：一票否决，该模块必须返回成功才能通过认证，但是一旦该模块返回失败，将不再执行同一type内的任何模块，而是直接将控制权返回给应用程序。是一个必要条件sufficient ：一票通过，表明本模块返回成功则通过身份认证的要求，不必再执行同一type内的其它模块，但如果本模块返回失败可忽略，即为充分条件optional ：表明本模块是可选的，它的成功与否不会对身份认证起关键作用，其返回值一般被忽略include： 调用其他的配置文件中定义的配置信息 复杂详细实现：使用一个或多个“status=action”[status1=action1 status2=action …]Status:检查结果的返回状态Action:采取行为 ok，done，die，bad，ignore，reset ok 模块通过，继续检查done 模块通过，返回最后结果给应用bad 结果失败，继续检查die 结果失败，返回失败结果给应用ignore 结果忽略，不影响最后结果reset 忽略已经得到的结果PAM认证机制 module-path: 模块路径 相对路径： /lib64/security目录下的模块可使用相对路径 如：pam_shells.so、 pam_limits.so 绝对路径： 模块通过读取配置文件完成用户对系统资源的使用控制 /etc/security/*.conf 1注意：修改PAM配置文件将马上生效 1编辑pam规则时，保持至少打开一个root会话，以防止root身份验证错误 Arguments 用来传递给该模块的参数 PAM模块示例模块：pam_shells功能：检查有效shellman pam_shells例：不允许使用/bin/csh的用户进行切换 1234567891011121314151617181920[root@cetos7 ~]#vim /etc/pam.d/su auth required pam_shells.so [root@cetos7 pam.d]#cat /etc/shells /bin/sh/bin/bash/sbin/nologin/usr/bin/sh/usr/bin/bash/usr/sbin/nologin/bin/tcsh#/bin/csh 用#把/bin/csh注释掉[root@cetos7 pam.d]#getent passwd magemage:x:1242:1244::/home/mage:/bin/bash[root@cetos7 pam.d]#usermod -s /bin/csh mage[root@cetos7 pam.d]#getent passwd mage mage:x:1242:1244::/home/mage:/bin/csh 把账号xie的shell类型改成 /bin/csh[root@cetos7 pam.d]#su - magePassword: su: Authentication failure mage账号将不可切换，其它不受影响 tail /var/log/secure 模块：pam_securetty.so功能：只允许root用户在/etc/securetty列出的安全终端上登陆示例：允许root在telnet登陆 1234[root@centos7 ~]vim /etc/pam.d/remote #auth required pam_securetty.so #将这一行加上注释 或者/etc/securetty文件中加入 pts/0,pts/1…pts/n 模块：pam_nologin.so功能： 如果/etc/nologin文件存在,将导致非root用户不能登陆 如果用户shell是/sbin/nologin 时，当该用户登陆时，会显示/etc/nologin文件内容，并拒绝登陆 模块：pam_limits.so功能：在用户级别实现对其可使用的资源的限制，例如：可打开的文件数量，可运行的进程数量，可用内存空间修改限制的实现方式： ulimit命令，立即生效，但无法保存 -n 每个进程最多的打开的文件描述符个数-u 最大用户进程数-S 使用 soft（软）资源限制-H 使用 hard（硬）资源限制 配置文件：/etc/security/limits.conf, /etc/security/limits.d/*.conf 配置文件：每行一个定义 1&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt; \ 应用于哪些对象 Username 单个用户@group 组内所有用户* 所有用户 \ 限制的类型 Soft 软限制,普通用户自己可以修改Hard 硬限制,由root用户设定，且通过kernel强制生效- 二者同时限定 \ 限制的资源 nofile 所能够同时打开的最大文件数量,默认为1024nproc 所能够同时运行的进程的最大数量,默认为1024 \ 指定具体值 限制用户最多打开的文件数和运行进程数 1234567&gt; &gt; /etc/pam.d/system-auth &gt; &gt; session required pam_limits.so &gt; &gt; &gt; &gt; vim /etc/security/limits.conf &gt; &gt; apache – nofile 10240 用户apache可打开10240个文件 &gt; &gt; student hard nproc 20 用户student不能运行超过20个进程&gt; &gt;]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>模块</tag>
        <tag>加密</tag>
        <tag>openssl</tag>
        <tag>ssh</tag>
        <tag>CA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6系统启动流程与grub]]></title>
    <url>%2F2018%2F11%2F06%2FCentos6%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%B8%8Egrub%2F</url>
    <content type="text"><![CDATA[Centos6启动流程 POST加电自检,即加载BIOS的硬件信息，获取第一个启动设备 读取第一个启动设备MBR的引导加载程序(grub)的启动信息 加载核心操作系统的核心信息，核心开始解压缩，并尝试驱动所有的硬件设备 核心执行init程序，并获取默认的运行信息 init程序执行/etc/rc.d/rc.sysinit文件 启动核心的外挂模块 init执行运行的各个批处理文件(scripts) 执行/bin/login程序，等待用户登录 登录之后开始以Shell控制主机启动流程 加电自检：power on system test(POST) 自检主要是检测一下硬件设备是否存在并能正常运行，如：CPU、内存、硬盘是否存在并能正常运行。这些自检的功能是有一个软件程序来实现的，这个软件程序叫做：BIOS。BIOS （Basic Input Output System）即基本输入输出系统。它是装载在一个硬件芯片CMOS之上，显然CMOS是一个硬件设备。加电过程就是给CMOS通电，然后启动其上的BIOS程序，BIOS程序会根据CMOS上面的一些配置信息去读取其他的硬件设备信息并检测其是否存在并能正常运行，之后进行硬件设备的初始化。 读取MBR 众所周知，硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，它的大小是512字节，别看地方不大，可里面却存放了预启动信息、分区表信息。前446字节存放grub的空间，中间64字节是分区表，最后2字节 55AA的标识。系统找到BIOS所指定的硬盘的MBR后，就会将其复制到0×7c00地址所在的物理内存中。其实被复制到物理内存的内容就是Boot Loader。Boot Loader 就是在操作系统内核运行之前运行的一段小程序。 Grub启动引导阶段 grub引导也分为三个阶段stage1阶段、stage1.5阶段和stage2阶段。 阶段 1 如上文 POST（上电自检）阶段提到的，在 POST 阶段结束时，BIOS 将查找在接入的磁盘中查找引导记录，其通常位于 MBR（主引导记录Master Boot Record），它加载它找到的第一个引导记录中到内存中，并开始执行此代码。引导代码（及阶段 1 代码）必须非常小，因为它必须连同分区表放到硬盘的第一个 512 字节的扇区中。 在传统的常规 MBR 中，引导代码实际所占用的空间大小为 446 字节。这个阶段 1 的 446 字节的文件通常被叫做引导镜像（boot.img），其中不包含设备的分区信息，分区是一般单独添加到引导记录中。 由于引导记录必须非常的小，它不可能非常智能，且不能理解文件系统结构。因此阶段 1 的唯一功能就是定位并加载阶段 1.5 的代码。为了完成此任务，阶段 1.5 的代码必须位于引导记录与设备第一个分区之间的位置。在加载阶段 1.5 代码进入内存后，控制权将由阶段 1 转移到阶段 1.5。 阶段 1.5 如上所述，阶段 1.5 的代码必须位于引导记录与设备第一个分区之间的位置。该空间由于历史上的技术原因而空闲。第一个分区的开始位置在扇区 63 和 MBR（扇区 0）之间遗留下 62 个 512 字节的扇区（共 31744 字节），该区域用于存储阶段 1.5 的代码镜像 core.img 文件。该文件大小为 25389 字节，故此区域有足够大小的空间用来存储 core.img。 因为有更大的存储空间用于阶段 1.5，且该空间足够容纳一些通用的文件系统驱动程序，如标准的 EXT 和其它的 Linux 文件系统，如 FAT 和 NTFS 等。故阶段 2 的文件可以存放于 /boot 文件系统中，一般在 /boot/grub 目录下。 注意 /boot 目录必须放在一个 GRUB 所支持的文件系统（并不是所有的文件系统均可）。阶段 1.5 的功能是开始执行存放阶段 2 文件的 /boot 文件系统的驱动程序，并加载相关的驱动程序。 阶段 2 GRUB 阶段 2 所有的文件都已存放于 /boot/grub 目录及其几个子目录之下。该阶段没有一个类似于阶段 1 与阶段 1.5 的镜像文件。相应地，该阶段主要需要从 /boot/grub2/i386-pc 目录下加载一些内核运行时模块。 GRUB 阶段 2 的主要功能是定位和加载 Linux 内核到内存中，并转移控制权到内核。内核的相关文件位于 /boot 目录下，这些内核文件可以通过其文件名进行识别，其文件名均带有前缀 vmlinuz。你可以列出 /boot 目录中的内容来查看操作系统中当前已经安装的内核。 Red Hat 包管理器（DNF）支持保留多个内核版本，以防最新版本内核发生问题而无法启动时，可以恢复老版本的内核。默认情况下，GRUB 提供了一个已安装内核的预引导菜单，其中包括问题诊断菜单（recuse）以及恢复菜单（如果配置已经设置恢复镜像）。 阶段 2 加载选定的内核到内存中，并转移控制权到内核代码。 加载内核 根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel”。系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。 用户层init依据inittab文件来设定运行等级 内核被加载后，第一个运行的程序便是/sbin/init，该文件会读取/etc/inittab文件，并依据此文件来进行初始化工作。 123456789101112131415161718192021222324252627[root@CentOS6 rc5.d]#cat /etc/inittab# inittab is only used by upstart for the default runlevel.# ADDING OTHER CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## System initialization is started by /etc/init/rcS.conf## Individual runlevels are started by /etc/init/rc.conf## Ctrl-Alt-Delete is handled by /etc/init/control-alt-delete.conf## Terminal gettys are handled by /etc/init/tty.conf and /etc/init/serial.conf,# with configuration in /etc/sysconfig/init.## For information on how to write upstart event handlers, or how# upstart works, see init(5), init(8), and initctl(8).## Default runlevel. The runlevels used are:# 0 - halt (Do NOT set initdefault to this)# 1 - Single user mode# 2 - Multiuser, without NFS (The same as 3, if you do not have networking)# 3 - Full multiuser mode# 4 - unused# 5 - X11# 6 - reboot (Do NOT set initdefault to this)# id:5:initdefault: 其实/etc/inittab文件最主要的作用就是设定Linux的运行等级， 运行级别：为系统运行或维护等目的而设定；0-6：7个级别 0：关机 1：单用户模式(root自动登录), single, 维护模式 2：多用户模式，启动网络功能，但不会启动NFS；维护模式 3：多用户模式，正常模式；文本界面 4：保留，未使用 5：多用户模式，正常模式；图形界面 6：重启 默认级别：3, 5 切换级别：init # 查看级别：runlevel ; who -r 每一行格式： 1id:runlevel:action:process id：是惟一标识该项的字符序列 runlevels： 定义了操作所使用的运行级别 action： 指定了要执行的特定操作 wait: 切换至此级别运行一次respawn：此process终止，就重新启动之initdefault：设定默认运行级别；process省略sysinit：设定系统初始化方式 process：定义了要执行的进程 故 id:5:initdefault: 这就表明Linux需要开机运行在5模式 破解CentOS5和6的root口令进入单用户模式即可 init进程执行rc.sysinit/etc/rc.d/rc.sysinit: 系统初始化脚本（一般情况下，我们不需要改） 设置主机名 设置欢迎信息 激活udev和selinux 挂载/etc/fstab文件中定义的文件系统 检测根文件系统，并以读写方式重新挂载根文件系统 设置系统时钟 激活swap设备 根据/etc/sysctl.conf文件设置内核参数 激活lvm及software raid设备 加载额外设备的驱动程序 清理操作启动流程 执行不同运行级别的脚本程序根据运行级别的不同，系统会运行rc0.d到rc6.d中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。说明：rc N –&gt; 意味着读取/etc/rc.d/rcN.d/12345678910111213[root@CentOS6 rc.d]#lltotal 60drwxr-xr-x. 2 root root 4096 Nov 6 09:32 init.d-rwxr-xr-x. 1 root root 2617 Jun 20 00:12 rcdrwxr-xr-x. 2 root root 4096 Oct 30 20:19 rc0.ddrwxr-xr-x. 2 root root 4096 Oct 30 20:19 rc1.ddrwxr-xr-x. 2 root root 4096 Oct 30 20:19 rc2.ddrwxr-xr-x. 2 root root 4096 Oct 30 20:19 rc3.ddrwxr-xr-x. 2 root root 4096 Oct 30 20:19 rc4.ddrwxr-xr-x. 2 root root 4096 Nov 7 11:26 rc5.ddrwxr-xr-x. 2 root root 4096 Oct 30 20:19 rc6.d-rwxr-xr-x. 1 root root 220 Jun 20 00:12 rc.local-rwxr-xr-x. 1 root root 20199 Jun 20 00:12 rc.sysinit K: K##：##运行次序；数字越小，越先运行；数字越小的服务，通常为依赖到别的服务S: S##：##运行次序；数字越小，越先运行；数字越小的服务，通常为被依赖到的服务 123456for srv in /etc/rc.d/rcN.d/K*; do$srv stopdonefor srv in /etc/rc.d/rcN.d/S*; do$srv startdone 执行/etc/rc.d/rc.local你如果打开了此文件，里面有一句话，读过之后，你就会对此命令的作用一目了然： 12345678[root@CentOS6 rc.d]#cat /etc/rc.d/rc.local #!/bin/sh## This script will be executed *after* all the other init scripts.# You can put your own initialization stuff in here if you don't# want to do the full Sys V style init stuff.touch /var/lock/subsys/local 注意：正常级别下，最后启动一个服务S99local没有链接至/etc/rc.d/init.d一个服务脚本，而是指向了/etc/rc.d/rc.local脚本不便或不需写为服务脚本放置于/etc/rc.d/init.d/目录，且又想开机时自动运行的命令，可直接放置于/etc/rc.d/rc.local文件中/etc/rc.d/rc.local在指定运行级别脚本后运行可以根据情况，进行自定义修改 执行/bin/login程序，进入登录状态此时，系统已经进入到了等待用户输入username和password的时候了，你已经可以用自己的帐号登入系统了。 GrubGrub: GRand Unified Bootloader如前面所述，grub分为三个阶段stage1: mbrstage1.5: mbr之后的扇区，让stage1中的bootloader能识别stage2所在的分区上的文件系统stage2：磁盘分区(/boot/grub/) Grub安装 grub-install 安装grub stage1和stage1_5到/dev/DISK磁盘上，并复制GRUB相关文件 到 DIR/boot目录下 grub-install –root-directory=DIR /dev/DISK grub grub&gt; root (hd#,#) grub&gt; setup (hd#)grub 识别硬盘设备 (hd#,#) hd#: 磁盘编号，用数字表示；从0开始编号 #: 分区编号，用数字表示; 从0开始编号 (hd0,0) 第一块硬盘，第一个分区 123456789101112131415161718192021222324252627282930313233343536[root@CentOS6 ~]#dd if=/dev/zero of=/dev/sda bs=1 count=446446+0 records in446+0 records out446 bytes (446 B) copied, 0.00308127 s, 145 kB/s[root@CentOS6 ~]#hexdump -C /dev/sda -n 51200000000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................|*000001b0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 80 20 |............... |000001c0 21 00 83 aa 28 82 00 08 00 00 00 00 20 00 00 aa |!...(....... ...|000001d0 29 82 83 fe ff ff 00 08 20 00 00 80 1a 06 00 fe |)....... .......|000001e0 ff ff 83 fe ff ff 00 88 3a 06 00 80 a9 03 00 fe |........:.......|000001f0 ff ff 05 fe ff ff 00 08 e4 09 00 f8 1b 0f 55 aa |..............U.|00000200[root@CentOS6 ~]#grubProbing devices to guess BIOS drives. This may take a long time. GNU GRUB version 0.97 (640K lower / 3072K upper memory) [ Minimal BASH-like line editing is supported. For the first word, TAB lists possible command completions. Anywhere else TAB lists the possible completions of a device/filename.]grub&gt; root (hd0,0) root (hd0,0) Filesystem type is ext2fs, partition type 0x83grub&gt; setup (hd0)setup (hd0) Checking if "/boot/grub/stage1" exists... no Checking if "/grub/stage1" exists... yes Checking if "/grub/stage2" exists... yes Checking if "/grub/e2fs_stage1_5" exists... yes Running "embed /grub/e2fs_stage1_5 (hd0)"... 27 sectors are embedded.succeeded Running "install /grub/stage1 (hd0) (hd0)1+27 p (hd0,0)/grub/stage2 /grub/grub.conf"... succeededDone.grub&gt; 如果我们把/boot/grub/* 的文件移走 123456789101112131415161718192021222324252627282930313233343536373839404142[root@CentOS6 ~]#mv /boot/grub/* /data[root@CentOS6 ~]#dd if=/dev/zero of=/dev/sda bs=1 count=446446+0 records in446+0 records out446 bytes (446 B) copied, 0.00398936 s, 112 kB/s[root@CentOS6 ~]#hexdump -C /dev/sda -n 51200000000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................|*000001b0 00 00 00 00 00 00 00 00 00 00 00 00 00 00 80 20 |............... |000001c0 21 00 83 aa 28 82 00 08 00 00 00 00 20 00 00 aa |!...(....... ...|000001d0 29 82 83 fe ff ff 00 08 20 00 00 80 1a 06 00 fe |)....... .......|000001e0 ff ff 83 fe ff ff 00 88 3a 06 00 80 a9 03 00 fe |........:.......|000001f0 ff ff 05 fe ff ff 00 08 e4 09 00 f8 1b 0f 55 aa |..............U.|00000200[root@CentOS6 ~]#grubProbing devices to guess BIOS drives. This may take a long time. GNU GRUB version 0.97 (640K lower / 3072K upper memory) [ Minimal BASH-like line editing is supported. For the first word, TAB lists possible command completions. Anywhere else TAB lists the possible completions of a device/filename.]grub&gt; root (hd0,0)root (hd0,0) Filesystem type is ext2fs, partition type 0x83grub&gt; setup (hd0)setup (hd0) Checking if "/boot/grub/stage1" exists... no Checking if "/grub/stage1" exists... noError 15t: File not foundgrub&gt; [root@CentOS6 ~]#grub-install /dev/sdaProbing devices to guess BIOS drives. This may take a long time.Installation finished. No error reported.This is the contents of the device map /boot/grub/device.map.Check if this is correct or not. If any of the lines is incorrect,fix it and re-run the script `grub-install'.(fd0) /dev/fd0(hd0) /dev/sda 由此实验我们可以看出grub&gt; root (hd#,#)；grub&gt; setup (hd#)这种修复方法依赖于/boot/grub/ 文件而grub-install这种修复方法不依赖/boot/grub/ 文件，感觉更通用一些。 grubstage2及内核等通常放置于一个基本磁盘分区功用： 提供启动菜单、并提供交互式接口 a：内核参数e: 编辑模式，用于编辑菜单c: 命令模式，交互式接口 加载用户选择的内核或操作系统 允许传递参数给内核可隐藏启动菜单 为菜单提供了保护机制 为编辑启动菜单进行认证为启用内核或操作系统进行认证grub legacy grub的命令行接口 help: 获取帮助列表 help KEYWORD: 详细帮助信息 find (hd#,#)/PATH/TO/SOMEFILE： root (hd#,#) kernel /PATH/TO/KERNEL_FILE: 设定本次启动时用到的内核文件；额外还可添加许多内核支持使用的cmdline参数 例如：max_loop=100 selinux=0 init=/path/to/init initrd /PATH/TO/INITRAMFS_FILE: 设定为选定的内核提供额外文件的ramdisk boot: 引导启动选定的内核 cat /proc/cmdline 内核参数 12[root@CentOS6 ~]#cat /proc/cmdline ro root=UUID=d3df2aba-5cd3-47fe-8128-3445b87dba11 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet 手动在grub命令行接口启动系统 1234grub&gt; root (hd#,#)grub&gt; kernel /vmlinuz-VERSION-RELEASE ro root=/dev/DEVICEgrub&gt; initrd /initramfs-VERSION-RELEASE.imggrub&gt; bootgrub legacy配置文件 配置文件: /boot/grub/grub.conf &lt;- /etc/grub.conf1234567891011121314151617181920[root@CentOS6 ~]#vim /boot/grub/grub.conf# grub.conf generated by anaconda ## Note that you do not have to rerun grub after making changes to this file# NOTICE: You have a /boot partition. This means that# all kernel and initrd paths are relative to /boot/, eg.# root (hd0,0)# kernel /vmlinuz-version ro root=/dev/sda2# initrd /initrd-[generic-]version.img#boot=/dev/sdadefault=0timeout=5splashimage=(hd0,0)/grub/splash.xpm.gzhiddenmenutitle CentOS 6 (2.6.32-754.el6.x86_64) root (hd0,0) kernel /vmlinuz-2.6.32-754.el6.x86_64 ro root=UUID=d3df2aba-5cd3-47fe-8128-3445b87dba11 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet initrd /initramfs-2.6.32-754.el6.x86_64.img 参数：default=#: 设定默认启动的菜单项；落单项(title)编号从0开始timeout=#：指定菜单项等待选项选择的时长splashimage=(hd#,#)/PATH/XPM_FILE：菜单背景图片文件路径password [–md5] STRING: 启动菜单编辑认证hiddenmenu：隐藏菜单title TITLE：定义菜单项“标题” , 可出现多次root (hd#,#)：查找stage2及kernel文件所在设备分区；为grub的根kernel /PATH/TO/VMLINUZ_FILE [PARAMETERS]：启动的内核initrd /PATH/TO/INITRAMFS_FILE: 内核匹配的ramfs文件 grub加密因为linux只要进入单用户模式下就很轻易的破解root口令，所以我们在/boot/grub/grub.conf文件里加上一行passwd.password [–md5|–encrypted ] STRING: 启动选定的内核或操作系统时进行认证 生成grub口令 12grub-md5-cryptgrub-crypt 破解root口令 启动系统时，设置其运行级别1，进入单用户模式： 编辑grub菜单(选定要编辑的title，而后使用a 或 e 命令)在选定的kernel后附加1, s, S，single 都可以在kernel所在行，键入“b” 命令]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>启动流程</tag>
        <tag>grub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务]]></title>
    <url>%2F2018%2F10%2F13%2FDNS%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[&ensp;&ensp;&ensp;&ensp;DNS(DomainName Server)是域名解析服务器，提供域名和IP地址之间一种转换机制，IP地址是平面结构不容易记住，DNS是层次化的结构，便于记忆 DNS域名 根域：根域位于层次结构的最顶部并用“.”来表示，全球有十三个根服务器，一个主根服务器，十二个辅助根服务器。 顶级域:顶级域是按照组织或地理位置来划分的 .gov：表示政府组织.com：表示商业组织.net：网络中心.org：非营利性组织.edu：教育部门 .cn .uk .us：国家国别的代码，cn表示中国，uk表示英国，us表示美国 二级域：由国际域名组织为互联网中的个人或部门指定和登记的二级域，如51cto.com,baidu.com DNS服务器类型 主DNS服务器(Master DNS）:管理和维护所负责解析的域内解析库的服务器 辅助DNS服务器 (SlaveDNS)：从主服务器或从服务器“复制”（区域传输）解析库副本 序列号：解析库版本号，主服务器解析库变化时，其序列递增刷新时间间隔：从服务器从主服务器请求同步解析的时间间隔重试时间间隔：从服务器请求同步失败时，再次尝试时间间隔过期时长：从服务器联系不到主服务器时，多久后停止服务 缓存DNS服务器:没有自己的区域数据文件，只是帮助客户端向外部DNS请求查询，然后将查询的结果保存到它的缓存中。 “通知”机制：主服务器解析库发生变化时，会主动通知从服务器 一个域可以有拥有多个从服务器，但只能有一台主服务器一台从服务器也可以从另一台从服务器那里获取数据客户端检索本地数据文件的相关记录，客户端将无法自行解释的需求，通过53端口送给指定的DNS服务器 DNS解析DNS查询类型递归查询迭代查询 名称服务器：域内负责解析本域内的名称的主机根服务器：13组服务器 解析类型FQDN(Fully Qualified Domain Name)完全合格域名，由主机名+域名组成，如www.51cto.com 正向解析：FQDN–&gt;IP,把完全合格域名解析为IP地址反向解析：IP–&gt;FQDN，把IP解析为完全合格域名。 注意：正反向解析是两个不同的名称空间，是两棵不同的解析树 解析答案肯定答案：否定答案：请求的条目不存在等原因导致无法返回结果权威答案：非权威答案 BIND&ensp;&ensp;&ensp;&ensp;BIND是BerkeleyInternet Name Daemon的缩写,BIND是在Internet上应用最为广泛的DNS服务器，提供稳定与可信赖的下层结构以提供域名与IP地址的转换 Bind的相关软件包bind-9.8.2-0.17.rc1.el6.x86_64提供域名服务的主程序和相关文件bind-libs-9.8.2-0.17.rc1.el6.x86_64提供域名域名服务器所依赖的库文件bind-utils-9.8.2-0.17.rc1.el6.x86_64提供了对DNS 服务的测试工具程序 注：bind-chroot：安装上这个包之后让named进程有限的活动在/var/named/chroot/中防止黑客攻击导致服务器的崩溃。这里就不安装了，因为安装之后除了路径改变之后其他均不变。所以为了更好的熟悉过程就暂时不装了 直接用yum安装yum install bind -y bind服务器服务脚本和名称：/etc/rc.d/init.d/named /usr/lib/systemd/system/named.service主配置文件：/etc/named.conf, /etc/named.rfc1912.zones, /etc/rndc.key解析库文件：/var/named/ZONE_NAME.ZONE注意： 一台物理服务器可同时为多个区域提供解析 必须要有根区域文件；named.ca 应该有两个（如果包括ipv6的，应该更多）实现localhost和本地回环地址的解析库 资源记录资源记录定义的格式语法：name [TTL] IN rr_type value注意： TTL可从全局继承 @可用于引用当前区域的名字 同一个名字可以通过多条记录定义多个不同的值；此时DNS服务器会以轮询方式响应 同一个值也可能有多个不同的定义名字；通过多个不同的名字指向同一个值进行 定义；此仅表示通过多个不同的名字可以找到同一个主机 区域解析库：由众多RR组成 资源记录：Resource Record, RR记录类型：A, AAAA, PTR, SOA, NS, CNAME, MX A：internet Address，作用，FQDN –&gt; IPAAAA：FQDN –&gt; IPv6PTR：PoinTeR，IP –&gt; FQDNSOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于解析库的第一条记录NS：Name Server，专用于标明当前区域的DNS服务器CNAME ： Canonical Name，别名记录MX：Mail eXchanger，邮件交换器 SQA name: 当前区域的名字，例如”magedu.com.”value: 有多部分组成 当前区域的主DNS服务器的FQDN，也可以使用当前区域的名字；当前区域管理员的邮箱地址；但地址中不能使用@符号，一般用.替换例：admin.magedu.com.主从服务区域传输相关定义以及否定的答案的统一的TTL 1234567$TTL 1D@ IN SOA @ rname.invalid. ( 0 ; serial 序列号 1D ; refresh 刷新时间 1H ; retry 重试时间 1W ; expire 过期时间 3H ) ; minimum 否定答案的TTL值 NS记录 name: 当前区域的名字 value: 当前区域的某DNS服务器的名字，例如ns.magedu.com. 注意：一个区域可以有多个NS记录例如： 12magedu.com. IN NS ns1.magedu.com. magedu.com. IN NS ns2.magedu.com. 注意:(1) 相邻的两个资源记录的name相同时，后续的可省略(2) 对NS记录而言，任何一个ns记录后面的服务器名字，都应该在后续有一个A记录 MX记录name: 当前区域的名字value: 当前区域的某邮件服务器(smtp服务器)的主机名一个区域内，MX记录可有多个；但每个记录的value之前应该有一个数字(0-99)，表示此服务器的优先级；数字越小优先级越高12magedu.com. IN MX 10 mx1.magedu.com. IN MX 20 mx2.magedu.com. 注意：对MX记录而言，任何一个MX记录后面的服务器名字，都应该在后续有一个A记录 A记录1name: 某主机的FQDNvalue: 主机名对应主机的IP地址例如：1234567www.magedu.com. IN A 1.1.1.1 www.magedu.com. IN A 2.2.2.2 mx1.magedu.com. IN A 3.3.3.3 mx2.magedu.com. IN A 4.4.4.4 $GENERATE 1-254 HOST$ A 1.2.3.$ *.magedu.com. IN A 5.5.5.5 magedu.com. IN A 6.6.6.6 避免用户写错名称时给错误答案，可通过泛域名解析进行解析至某特定地址 其它记录 AAAA:name: FQDNvalue: IPv6 PTR:name: IP，有特定格式，把IP地址反过来写，1.2.3.4，要写作4.3.2.1；而有特定后缀: in-addr.arpa.，所以完整写法为：124.3.2.1.in-addr.arpa.value: FQDN 14.3.2.1.in-addr.arpa. IN PTR www.magedu.com. 别名记录CNAME：name: 别名的FQDNvalue: 真正名字的FQDN例如：1www.magedu.com. IN CNAME websrv.magedu.com. 子域授权：每个域的名称服务器，都是通过其上级名称服务器在解析库进行授权 类似根域授权tld： 1234.com. IN NS ns1.com..com. IN NS ns2.com.ns1.com. IN A 2.2.2.1ns2.com. IN A 2.2.2.2 magedu.com. 在.com的名称服务器上，解析库中添加资源记录 123456magedu.com. IN NS ns1.magedu.com.magedu.com. IN NS ns2.magedu.com.magedu.com. IN NS ns3.magedu.com.ns1.magedu.com. IN A 3.3.3.1ns2.magedu.com. IN A 3.3.3.2ns3.magedu.com. IN A 3.3.3.3 glue record：粘合记录，父域授权子域的记录 DNS实验 正向的主DNS服务器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115[root@CentOS6 ~]#vim /etc/sysconfig/network-scripts/ifcfg-eth0 BOOTPROTO=staticIPADDR=192.168.183.158PREFIX=24DNS1=192.168.183.148 [root@CentOS6 ~]#service network restartShutting down interface eth0: Device state: 3 (disconnected) [ OK ]Shutting down loopback interface: [ OK ]Bringing up loopback interface: [ OK ]Bringing up interface eth0: Active connection state: activatedActive connection path: /org/freedesktop/NetworkManager/ActiveConnection/2 [ OK ][root@CentOS6 ~]#cat /etc/resolv.conf# Generated by NetworkManagerdomain localdomainsearch localdomainnameserver 192.168.183.148[root@CentOS6 ~]#ping 114.114.114.114 PING 114.114.114.114 (114.114.114.114) 56(84) bytes of data.64 bytes from 114.114.114.114: icmp_seq=1 ttl=128 time=14.7 ms64 bytes from 114.114.114.114: icmp_seq=2 ttl=128 time=13.8 ms[root@CentOS6 ~]#ping www.baidu.com ping: unknown host www.baidu.com我们需要把192.168.183.148这个DNS服务器配置文件修改下[root@centos7 ~]#vim /etc/named.conf// listen-on port 53 &#123; localhost; &#125;;......省略.......// allow-query &#123; localhost; &#125;; allow-transfer &#123;192.169.183.136;&#125;; 为后面搭建主备服务器准备的把这两行注释掉[root@centos7 ~]#named-checkconf 检查语法是否有错误[root@centos7 ~]#rndc reload 修改文件生效server reload successful[root@CentOS6 ~]#dig www.magedu.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6 &lt;&lt;&gt;&gt; www.magedu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 55470;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 16;; QUESTION SECTION:;www.magedu.com. IN A;; ANSWER SECTION:www.magedu.com. 600 IN A 101.200.188.230......省略.......[root@centos7 ~]#vim /etc/named.rfc1912.zones ......省略.......zone "localhost.localdomain" IN &#123; type master; file "named.localhost"; allow-update &#123; none; &#125;;&#125;;zone "mmagedu.com" IN &#123; type master; file "magedu.com.zone"; &#125;;......省略.......[root@centos7 ~]#cd /var/named/[root@centos7 named]#cp -a named.localhost magedu.com.zone cp时要注意文件的属性[root@centos7 named]#lltotal 20drwxrwx--- 2 named named 23 Nov 24 14:19 datadrwxrwx--- 2 named named 60 Nov 24 14:20 dynamic-rw-r----- 1 root named 152 Jun 21 2007 magedu.com.zone-rw-r----- 1 root named 2281 May 22 2017 named.ca-rw-r----- 1 root named 152 Dec 15 2009 named.empty-rw-r----- 1 root named 152 Jun 21 2007 named.localhost-rw-r----- 1 root named 168 Dec 15 2009 named.loopbackdrwxrwx--- 2 named named 6 Apr 13 2018 slaves[root@centos7 named]#vim magedu.com.zone $TTL 1D@ IN SOA dns1 admin.magedu.com. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS dns1dns1 A 192.168.183.148 www CNAME websrvwebsrv A 6.6.6.6websrv A 7.7.7.7websrv A 8.8.8.8@ A 6.6.6.6 泛域名解析* A 6.6.6.6[root@centos7 named]#rndc reloadserver reload successful[root@CentOS6 ~]#dig www.magedu.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6 &lt;&lt;&gt;&gt; www.magedu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 20887;; flags: qr aa rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;www.magedu.com. IN A;; ANSWER SECTION:www.magedu.com. 86400 IN CNAME websrv.magedu.com.websrv.magedu.com. 86400 IN A 6.6.6.6websrv.magedu.com. 86400 IN A 7.7.7.7websrv.magedu.com. 86400 IN A 8.8.8.8 反向的主DNS服务器 123456789101112131415161718192021222324252627282930313233343536373839404142[root@centos7 ~]#vim /etc/named.rfc1912.zoneszone "183.168.192.in-addr.arpa" &#123; type master; file "192.168.183.158.zone";&#125;;[root@centos7 ~]#cd /var/named/[root@centos7 named]#vim 192.168.183.zone$TTL 86400@ IN SOA dnsserver admin.magedu.com. ( 20181124; 3H; 10M; 1D; 1H); NS dnsserverdnsserver A 192.168.183.148148 PTR dnsserver.magedu.com.100 PTR www.magedu.com.120 PTR blog.magedu.com&lt;92.168.183.zone" 12L, 227C written[root@centos7 named]#named-checkconf[root@centos7 named]#named-checkzone 183.168.192.in-addr.arpa 192.168.183.zonezone 183.168.192.in-addr.arpa/IN: loaded serial 20181124OK[root@centos7 named]#rndc reloadserver reload successful[root@CentOS6 ~]#dig -x 192.168.183.148; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6 &lt;&lt;&gt;&gt; -x 192.168.183.148;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 53616;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;148.183.168.192.in-addr.arpa. IN PTR;; ANSWER SECTION:148.183.168.192.in-addr.arpa. 86400 IN PTR dnsserver.magedu.com.......省略....... DNS冗错(DNS主备服务器的搭建)再找一台主机(192.168.183.137)搭建DNS服务器安装bind yum install bind -y修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[root@centos7 ~]#vim /etc/named.conf......省略.......// listen-on port 53 &#123; 127.0.0.1; &#125;; //注释掉 listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt";// allow-query &#123; localhost; &#125;; //注释掉 allow-transfer &#123; none;&#125;;......省略.......[root@centos7 ~]# vim /etc/named.rfc1912.zoneszone "magedu.com" &#123; type slave; master &#123;192.168.183.148;&#125;; file "slaves/magedu.com.zone.slave";&#125;;[root@centos7 ~]#vim /var/named/magedu.com.zone //主服务器 NS dns1 NS dns2dns1 A 192.168.183.148dns2 A 192.168.183.137 [root@centos7 ~]#rndc reloadserver reload successful[root@centos7 ~]# systemctl start named[root@centos7 ~]# cd /var/named/slaves/[root@centos7 slaves]# lltotal 4-rw-r--r--. 1 named named 524 Nov 24 21:20 magedu.com.zone.slave[root@CentOS6 ~]#dig www.magedu.com ; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6 &lt;&lt;&gt;&gt; www.magedu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 33539;; flags: qr aa rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 3, ADDITIONAL: 3;; QUESTION SECTION:;www.magedu.com. IN A;; ANSWER SECTION:www.magedu.com. 86400 IN CNAME websrv.magedu.com.websrv.magedu.com. 86400 IN A 6.6.6.6websrv.magedu.com. 86400 IN A 7.7.7.7websrv.magedu.com. 86400 IN A 8.8.8.8;; AUTHORITY SECTION:magedu.com. 86400 IN NS dns1.magedu.com.magedu.com. 86400 IN NS dns2.magedu.com.;; ADDITIONAL SECTION:dns1.magedu.com. 86400 IN A 192.168.183.148dns2.magedu.com. 86400 IN A 192.168.183.137;; Query time: 6 msec;; SERVER: 192.168.183.148#53(192.168.183.148) 主服务器;; WHEN: Sat Nov 24 20:43:12 2018;; MSG SIZE rcvd: 206把主服务器网线掐断[root@CentOS6 ~]#dig www.magedu.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6 &lt;&lt;&gt;&gt; www.magedu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 55691;; flags: qr aa rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 3, ADDITIONAL: 3;; QUESTION SECTION:;www.magedu.com. IN A;; ANSWER SECTION:www.magedu.com. 86400 IN CNAME websrv.magedu.com.websrv.magedu.com. 86400 IN A 7.7.7.7websrv.magedu.com. 86400 IN A 8.8.8.8websrv.magedu.com. 86400 IN A 6.6.6.6;; AUTHORITY SECTION:magedu.com. 86400 IN NS dns2.magedu.com.magedu.com. 86400 IN NS dns1.magedu.com.;; ADDITIONAL SECTION:dns1.magedu.com. 86400 IN A 192.168.183.148dns2.magedu.com. 86400 IN A 192.168.183.137;; Query time: 5 msec;; SERVER: 192.168.183.136#53(192.168.183.137) 备用服务器;; WHEN: Sat Nov 24 20:48:16 2018;; MSG SIZE rcvd: 206]]></content>
      <categories>
        <category>dns</category>
      </categories>
      <tags>
        <tag>dns</tag>
        <tag>解析</tag>
        <tag>资源记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux kernel]]></title>
    <url>%2F2018%2F10%2F06%2Flinux%20kernel%2F</url>
    <content type="text"><![CDATA[kernel introduce 内核是操作系统的核心，掌控着所有硬件设备的控制权。也就是说，你所希望计算机帮你完成的各项工作，都需要通过内核的帮助才能完成。内核可以分为以下几种设计流派： 单内核(monolithic kernel)： Linux把所有功能集成于同一个程序微内核(micro kernel)：Windows, Solaris每种功能使用一个单独子系统实现内核 Linux内核特点： 支持模块化：.ko（内核对象) 如：文件系统，硬件驱动，网络协议等 支持内核模块的动态装载和卸载 组成部分： 核心文件：/boot/vmlinuz-VERSION-releaseramdisk：辅助的伪根系统 CentOS 5: /boot/initrd-VERSION-release.imgCentOS 6,7: /boot/initramfs-VERSION-release.img 模块文件：/lib/modules/VERSION-release kernel 自身初始化检测可识别到的所有硬件设备加载硬件驱动程序（借助于ramdisk加载驱动）以只读方式挂载根文件系统运行用户空间的第一个应用程序：/sbin/init启动流程 ramdisk：内核中的特性之一：使用缓冲和缓存来加速对磁盘上的文件访问，并加载相应的硬件驱动 CentOS 5: initrd 工具程序：mkinitrdCentOS 6，7: initramfs工具程序：mkinitrd, dracut ramdisk文件的制作 mkinitrd命令 为当前正在使用的内核重新制作ramdisk文件 1mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) dracut命令 为当前正在使用的内核重新制作ramdisk文件 1dracut /boot/initramfs-$(uname -r).img $(uname -r) 内核版本uname命令uname - print system informationuname [OPTION]…-r: 显示VERSION-RELEASE-n: 显示主机名-a:显示所有信息 123456[root@CentOS6 ~]#uname -r2.6.32-754.el6.x86_64[root@CentOS6 ~]#uname -nCentOS6.localdomain[root@CentOS6 ~]#uname -aLinux CentOS6.localdomain 2.6.32-754.el6.x86_64 #1 SMP Tue Jun 19 21:26:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux uname -a 现实的内容依次为： Linux 操作系统类型 CentOS6.localdomain 操作系统的主机名 2.6.32-754.el6.x86_64 内核版本信息 #1 SMP Tue Jun 19 21:26:04 UTC 2018 内核的编译日期 x86_64 x86_64 x86_64 这三组分别是：操作系统版本、处理器类型、硬件平台 GNU/Linux 操作系统名称 /proc目录该目录是系统与内核交互的一个伪文件系统接口，内核把自己内部状态信息及统计信息，以及可配置参数通过proc伪文件系统加以输出。 参数 只读：输出信息 1234567[root@CentOS6 ~]#cat /proc/sys/net/ipv4/icmp_echo_ignore_all 0[root@CentOS6 ~]#ping 192.168.183.157PING 192.168.183.157 (192.168.183.157) 56(84) bytes of data.64 bytes from 192.168.183.157: icmp_seq=1 ttl=64 time=0.074 ms64 bytes from 192.168.183.157: icmp_seq=2 ttl=64 time=0.068 ms64 bytes from 192.168.183.157: icmp_seq=3 ttl=64 time=0.069 ms 可写：可接受用户指定“新值”来实现对内核某功能或特性的配置,不支持编辑器编辑 12345678[root@CentOS6 ~]#echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all[root@CentOS6 ~]#cat /proc/sys/net/ipv4/icmp_echo_ignore_all1[root@CentOS6 ~]#ping -wl -c1 192.168.183.157PING 192.168.183.157 (192.168.183.157) 56(84) bytes of data. --- 192.168.183.157 ping statistics ---1 packets transmitted, 0 received, 100% packet loss, time 10001ms 1/proc/sys echo命令通过重定向方式也可以修改大多数参数的值 12echo “VALUE” &gt; /proc/sys/path/to/parameterecho “websrv” &gt; /proc/sys/kernel/hostname sysctl命令用于查看或设定此目录中诸多参数 12sysctl -w path.to.parameter=VALUEsysctl -w kernel.hostname=mail.magedu.com sysctl命令默认配置文件：/etc/sysctl.conf 设置某参数 1sysctl -w parameter=VALUE 通过读取配置文件设置参数 1sysctl -p [/path/to/conf_file] 查看所有生效参数 1sysctl -a 例： 123456[root@CentOS6 ~]#sysctl -a |lesskernel.sched_child_runs_first = 0kernel.sched_min_granularity_ns = 2000000kernel.sched_latency_ns = 10000000kernel.sched_wakeup_granularity_ns = 2000000kernel.sched_tunable_scaling = 1 常用的几个参数： 123net.ipv4.ip_forwardnet.ipv4.icmp_echo_ignore_allvm.drop_caches /sys目录&ensp;&ensp;&ensp;&ensp;sysfs：为用户使用的伪文件系统，输出内核识别出的各硬件设备的相关属性信息，也有内核对硬件特性的设定信息；有些参数是可以修改的，用于调整硬件工作特性udev通过此路径下输出的信息动态为各设备创建所需要设备文件，udev是运行用户空间程序专用工具：udevadmin, hotplugudev为设备创建设备文件时，会读取其事先定义好的规则文件，一般在/etc/udev/rules.d及/usr/lib/udev/rules.d目录下 12345678910111213网卡[root@CentOS6 ~]#cat /etc/udev/rules.d/70-persistent-net.rules# This file was automatically generated by the /lib/udev/write_net_rules# program, run by the persistent-net-generator.rules rules file.## You can modify it, as long as you keep each rule on a single# line, and change only the value of the NAME= key.# PCI device 0x8086:0x100f (e1000)SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:0c:29:bf:4b:56", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth0"# PCI device 0x8086:0x100f (e1000)SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:0c:29:bf:4b:60", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth1" 内核模块管理查看当前内核已经装载的模块 lsmod123456789101112131415[root@CentOS6 ~]#lsmodModule Size Used byrfcomm 71207 4 sco 17589 2 bridge 85770 0 bnep 16370 2 l2cap 54498 16 rfcomm,bnepautofs4 27000 3 8021q 20507 0 garp 7184 1 8021qstp 2218 2 bridge,garpllc 5450 3 bridge,garp,stpipt_REJECT 2383 2 nf_conntrack_ipv4 9218 2 ...省略... 查看内核模块的文件/proc/modules123456789101112131415[root@CentOS6 ~]#cat /proc/modules rfcomm 71207 4 - Live 0xffffffffa05fd000sco 17589 2 - Live 0xffffffffa05f3000bridge 85770 0 - Live 0xffffffffa05d5000bnep 16370 2 - Live 0xffffffffa05cd000l2cap 54498 16 rfcomm,bnep, Live 0xffffffffa05b9000autofs4 27000 3 - Live 0xffffffffa05ad0008021q 20507 0 - Live 0xffffffffa05a2000garp 7184 1 8021q, Live 0xffffffffa059c000stp 2218 2 bridge,garp, Live 0xffffffffa0598000llc 5450 3 bridge,garp,stp, Live 0xffffffffa0592000ipt_REJECT 2383 2 - Live 0xffffffffa0567000nf_conntrack_ipv4 9218 2 - Live 0xffffffffa0560000nf_defrag_ipv4 1483 1 nf_conntrack_ipv4, Live 0xffffffffa055c000...省略... 查看模块的详细描述信息 modinfo1modinfo [ -k kernel ][ modulename|filename… ] ​ -n：只显示模块文件路径​ -p：显示模块参数​ -a：作者​ -d：描述 例： 123456789[root@CentOS6 ~]#modinfo xfsfilename: /lib/modules/2.6.32-754.el6.x86_64/kernel/fs/xfs/xfs.kolicense: GPLdescription: SGI XFS with ACLs, security attributes, large block/inode numbers, no debug enabledauthor: Silicon Graphics, Inc.retpoline: Ysrcversion: 032C69ECC93FCBD7B47F691depends: exportfsvermagic: 2.6.32-754.el6.x86_64 SMP mod_unload modversions 内核模块装载或卸载 modprobe装载模块：modprobe MOD_NAME (注意这里会自动解决模块间的依赖关系)卸载模块：modprobe -r modulename 手动实现模块文件的装载和卸载insmod命令：insmod /path/to/module_file(注意这里不会自动解决模块间的依赖关系)rmmod命令:rmmod MOD_NAME 编译内核前提： 准备好开发环境 获取目标主机上硬件设备的相关信息 获取目标主机系统功能的相关信息 例如:需要启用相应的文件系统 获取内核源代码包 www.kernel.org 开发环境准备 包组 1234Development Toolsncurses-develelfutils-libelf-developenssl-devel 目标主机硬件设备相关信息 CPU： cat /proc/cpuinfox86info -alscpu PCI设备： lspci -v-vv lsusb -v-vv lsblk 块设备 3.了解全部硬件设备信息hal-device：CentOS 6 内核编译安装系统 安装开发包组 下载源码文件 .config：准备文本配置文件 make menuconfig：配置内核选项 make [-j #] make modules_install：安装模块 make install: 安装内核相关文件 ​安装bzImage为/boot/vmlinuz-VERSION-RELEASE ​生成initramfs文件 ​编辑grub的配置文件 12345678910编译安装内核示例tar xf linux-3.10.67.tar.xz -C /usr/srccd /usr/src/linux-3.10.67 cp /boot/config-$(uname -r) ./.configmake help make menuconfig make -j 2 make modules_installmake install reboot 卸载内核 make clean：清理大多数编译生成的文件，但会保留config文件等 make mrproper: 清理所有编译生成的文件、 config及某些备份文件 make distclean：mrproper、清理patches以及编辑器备份文件卸载内核 删除/lib/modules/目录下不需要的内核库文件 删除/usr/src/linux/目录下不需要的内核源码 删除/boot目录下启动的内核和内核映像文件 更改grub的配置文件，删除不需要的内核启动列表]]></content>
      <categories>
        <category>内核</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>编译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程和计划任务]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%BF%9B%E7%A8%8B%E5%92%8C%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[一、进程的相关概念1.1、相关定义 内核的功用：进程管理、文件系统、网络功能、内存管理、驱动程序、 安全功能等 通俗的来说进程是运行起来的程序。唯一标识进程的是进程描述符（PID）,在linux内核中是通过task_struck和task_list来定义和管理进程的 ； 进程Process: 运行中的程序的一个副本，是被载入内存的一个指令集合 ​ 进程ID（Process ID，PID）号码被用来标记各个进程 ​ UID、 GID、和SELinux语境决定对文件系统的存取和访问权限 ​ 通常从执行进程的用户来继承 ​ 存在生命周期 task struct：Linux内核存储进程信息的数据结构格式 task list：多个任务的的task struct组成的链表 1.2、进程创建 init：第一个进程 进程：都由其父进程创建，父子关系，CoW（写实复制） ​ fork(), clone() 创建过程 1.系统首先以fock的方式复制（cow）一个与父进程相同的进程，这个进程与父进程唯一的差别就是PID不同，但是这个进程还会多一个PPID的参数，PPID就是父进程的程序识别码PID； 2.然后新产生的进程开始加载实际要运行的程序进行执行。 1.3、进程的基本状态 创建状态：进程在创建时需要申请一个空白PCB(process control block进程控制块)，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 就绪状态：进程已准备好，已分配到所需资源，只要分配到CPU就能够立即运行 执行状态：进程处于就绪状态被调度后，进程进入执行状态 阻塞状态：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 1.3.1、状态之间转换六种情况运行——&gt;就绪：1、主要是进程占用CPU的时间过长，而系统分配给该进程占用CPU的时间是有限的； ​ 2、在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行时，该进程就被迫让出CPU，该进程便由执行状态转变为就绪状态 就绪——&gt;运行：运行的进程的时间片用完，调度就转到就绪队列中选择合适的进程分配CPU 运行——&gt;阻塞：正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为阻塞状态，如发生了I/O请求 阻塞——&gt;就绪:进程所等待的事件已经发生，就进入就绪队列 以下两种状态是不可能发生的： 阻塞——&gt;运行：即使给阻塞进程分配CPU，也无法执行，操作系统在进行调度时不会从阻塞队列进行挑选，而是从就绪队列中选取 就绪——&gt;阻塞：就绪态根本就没有执行，谈不上进入阻塞态 1.4、进程优先级 进程优先级： ​ 系统优先级：数字越小，优先级越高 ​ 0-139（CentOS4,5） ​ 各有140个运行队列和过期队列 ​ 0-98，99（CentOS6） ​ 实时优先级: 99-0 值最大优先级最高 nice值：-20到19，对应系统优先级100-139或99 Big O：时间复杂度，用时和规模的关系 ​ O(1), O(logn), O(n)线性, O(n^2)抛物线, O(2^n) 1.5、进程内存 Page Frame: 页框，用存储页面数据，存储Page 4k LRU：Least Recently Used 近期最少使用算法,释放内存 物理地址空间和线性地址空间 ​ MMU：Memory Management Unit负责转换线性和物理地址 ​ TLB：Translation Lookaside Buffer ​ 翻译后备缓冲器,用于保存虚拟地址和物理地址映射关系的缓存 1.6、IPC：进程间通信（Inter Process Communication）&ensp;&ensp;&ensp;&ensp;在计算机网络体系中，主机与主机之间的通信，实质上是主机进程与主机进程之间的通信，也就是进程间的通信； 同一主机：signal:信号 ​ shm: shared memory ​ semaphore:信号量，一种计数器 ​不同主机：socket: IP和端口号 ​ RPC: remote procedure call ​ MQ：消息队列，Kafka，ActiveMQ ## 1.7、Linux内核：抢占式多任务1.8、进程类型 守护进程: daemon,在系统引导过程中启动的进程，和终端无关进程 ​前台进程：跟终端相关，通过终端启动的进程 ​注意：两者可相互转化 1.9、进程状态 ​ 运行态：running ​ 就绪态：ready ​ 睡眠态： ​ 可中断：interruptable ​ 不可中断：uninterruptable ​ 停止态：stopped,暂停于内存，但不会被调度，除非手动启动 ​ 僵死态：zombie，结束进程，父进程结束前，子进程不关闭 1.10、进程的分类 CPU-Bound：CPU密集型，非交互 IO-Bound：IO密集型，交互 二、进程和线程的关系&ensp;&ensp;&ensp;&ensp;进程和线程都是由操作系统所体会的程序运行的基本单元，系统利用该基本单元实现系统对应用的并发性。进程和线程的区别在于： 1、一个程序至少有一个进程,一个进程至少有一个线程. 线程的划分尺度小于进程，使得多线程程序的并发性高。另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。2、线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。3、从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。4、进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.​ 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源. 一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行. 三、系统管理工具Linux系统状态的查看及管理工具 pstree, ps, pidof, pgrep, top, htop,glance, pmap, vmstat, dstat, kill, pkill, job, bg, fg, nohup 3.1、pstree命令display a tree of processes（显示查看进程树） 以下为CentOS 6 和 CentOS 7 的区别 123456789root@CentOS6 ~]# pstreeinit─┬─abrtd #可以看到都是有init生成的 ├─acpid ├─atd ├─auditd───&#123;auditd&#125; ├─automount───4*[&#123;automount&#125;] ├─bonobo-activati───&#123;bonobo-activat&#125; ├─clock-applet、、、、 123456789101112[root@centos7 ~]#pstreesystemd─┬─ModemManager───2*[&#123;ModemManager&#125;] #可以看到都是有systemd生成的 ├─NetworkManager─┬─dhclient │ └─3*[&#123;NetworkManager&#125;] ├─VGAuthService ├─abrt-dbus───3*[&#123;abrt-dbus&#125;] ├─2*[abrt-watch-log] ├─abrtd ├─alsactl ├─atd ├─auditd─┬─audispd─┬─sedispatch、、、、、、 四、进程查看命令4.1、ps：查看进程信息ps [OPTION]… 支持三种选项： ​ UNIX选项 如-A -e ​ BSD选项 如a ​ GNU选项 如–help 4.1.1、选项：默认显示当前终端中的进程 ​ a 选项包括所有终端中的进程 ​ x 选项包括不链接终端的进程 ​ u 选项显示进程所有者的信息 ​ f 选项显示进程树,相当于–forest ​ k|–sort 属性 对属性排序,属性前加-表示倒序 ​ o 属性…选项显示定制的信息pid、cmd、%cpu、%mem ​ L 显示支持的属性列表 4.1.2、常见选项： -C cmdlist 指定命令，多个命令用，分隔 -L 显示线程 -e: 显示所有进程，相当于-A -f: 显示完整格式程序信息 -F: 显示更完整格式的进程信息 -H: 以进程层级格式显示进程相关信息 -u userlist 指定有效的用户ID或名称 -U userlist 指定真正的用户ID或名称 -g gid或groupname 指定有效的gid或组名称 -G gid或groupname 指定真正的gid或组名称 -p pid 显示指pid的进程 –ppid pid 显示属于pid的子进程 -M 显示SELinux信息，相当于Z 4.1.3、ps输出属性VSZ: Virtual memory SiZe，虚拟内存集，线性内存 RSS: ReSident Size, 常驻内存集 STAT：进程状态​ R：running​ S: interruptable sleeping​ D: uninterruptable sleeping​ T: stopped​ Z: zombie​ +: 前台进程​ l: 多线程进程​ L：内存分页并带锁​ N：低优先级进程​ &lt;: 高优先级进程​ s: session leader，会话（子进程）发起者 4.1.4、常用组合123ps aux：观察系统所有的程序数据ps -lA：也是能够观察所有系统的数据ps axjf：连同部分程序树状态 ni: nice值 pri: priority 优先级 psr: processor CPU编号 rtprio: 实时优先级 12ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,commps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm 4.1.5、示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576771.查询你拥有的所有进程ps -x2.显示指定用户名(RUID)或用户ID的进程ps -fU apacheps -fU 483.显示指定用户名(EUID)或用户ID的进程ps -fu wangps -fu 10004.查看以root用户权限（实际和有效ID）运行的每个进程ps -U root -u root5.列出某个组拥有的所有进程（实际组ID：RGID或名称）ps -fG nginx6.列出有效组名称（或会话）所拥有的所有进程ps -fg mysqlps -fg 277.显示指定的进程ID对应的进程ps -fp 12348.以父进程ID来显示其下所有的进程，如显示父进程为1234的所有进程ps -f --ppid 12349.显示指定PID的多个进程ps -fp 1204,1239,126310.要按tty显示所属进程ps -ft pts/011.以进程树显示系统中的进程如何相互链接ps -e --forest12.以进程树显示指定的进程ps -f --forest -C sshdps -ef --forest | grep -v grep | grep sshd13.要显示一个进程的所有线程,将显示LWP（轻量级进程）以及NLWP（轻量级进程数）列ps -fL -C nginx14.要列出所有格式说明符ps L15.查看进程的PID，PPID，用户名和命令ps -eo pid,ppid,user,cmd16.自定义格式显示文件系统组,ni值开始时间和进程的时间ps -p 1234 -o pid,ppid,fgroup,ni,lstart,etime17.使用其PID查找进程名称：ps -p 1244 -o comm=18.要以其名称选择特定进程，显示其所有子进程ps -C sshd,bash19.查找指定进程名所有的所属PID，在编写需要从std输出或文件读取PID的脚本时这个参数很有用ps -C httpd,sshd -o pid=20.检查一个进程的执行时间ps -eo comm,etime,user | grep nginx21.查找占用最多内存和CPU的进程ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | headps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head22.显示安全信息ps -eMps --context23.使用以下命令以用户定义的格式显示安全信息ps -eo euser,ruser,suser,fuser,f,comm,label24.使用watch实用程序执行重复的输出以实现对就程进行实时的监视，如下面的命令显示每秒钟的监视watch -n 1 'ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head' 五、进程管理工具5.1、top：持续观察进程运行状态5.1.1、常用参数​ -d # 指定刷新时间间隔，默认为3秒​ -b 全部显示所有进程​ -n # 刷新多少次后退出​ -H 线程模式，示例：top -H -p pidof mysqld 5.1.2、内置命令​ 排序：​ P：以占据的CPU百分比,%CPU​ M：占据内存百分比,%MEM​ T：累积占据CPU时长,TIME+​ 首部信息显示：​ uptime信息：l命令​ tasks及cpu信息：t命令​ cpu分别显示：1 (数字)​ memory信息：m命令​ 退出命令：q​ 修改刷新时间间隔：s​ 终止指定进程：k​ 保存文件：W 5.2、htop命令选项：​ -d #: 指定延迟时间；​ -u UserName: 仅显示指定用户的进程​ -s COLUME: 以指定字段进行排序子命令：​ s：跟踪选定进程的系统调用​ l：显示选定进程打开的文件列表​ a：将选定的进程绑定至某指定CPU核心​ t：显示进程树 5.3、kill命令&ensp;&ensp;&ensp;&ensp;&ensp;向进程发送控制信号，以实现对进程管理,每个信号对应一个数字，信号名称以SIG开头（可省略），不区分大小写显示当前系统可用信号： kill –l 或者 trap -l 1234567891011121314[root@centos7 ~]#kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX 常用信号：man 7 signal​ 1) SIGHUP 无须关闭进程而让其重读配置文件​ 2) SIGINT 中止正在运行的进程；相当于Ctrl+c​ 3) SIGQUIT 相当于ctrl+\​ 9) SIGKILL 强制杀死正在运行的进程​ 15) SIGTERM 终止正在运行的进程​ 18) SIGCONT 继续运行​ 19) SIGSTOP 后台休眠指定信号的方法 : (1) 信号的数字标识：1, 2, 9​ (2) 信号完整名称：SIGHUP​ (3) 信号的简写名称：HUP 按PID：kill [-SIGNAL] pid … 12kill –n SIGNAL pidkill –s SIGNAL pid 按名称：killall [-SIGNAL] comm… 按模式：pkill [options] pattern​ -SIGNAL​ -u uid: effective user，生效者​ -U uid: real user，真正发起运行命令者​ -t terminal: 与指定终端相关的进程​ -l: 显示进程名（pgrep可用）​ -a: 显示完整格式的进程名（pgrep可用）​ -P pid: 显示指定进程的子进程 六、系统、内存工具6.1、系统工具1、uptime： &ensp;&ensp;&ensp;&ensp;显示当前时间，系统已启动的时间、当前上线人数，系统平均负载（1、 5、 10分钟的平均负载，一般不会超过1） 2、系统平均负载:&ensp;&ensp;&ensp;&ensp;指在特定时间间隔内运行队列中的平均进程数 3、通常每个CPU内核的当前活动进程数不大于3，那么系统的性能良好。 如果每个CPU内核的任务数大于5，那么此主机的性能有严重问题 4、如果linux主机是1个双核CPU，当Load Average 为6的时候说明机器已经被充分使用 6.2、内存空间内存空间使用状态：​ free [OPTION]​ -b 以字节为单位​ -m 以MB为单位​ -g 以GB为单位​ -h 易读格式​ -o 不显示-/+buffers/cache行​ -t 显示RAM + swap的总和​ -s n 刷新间隔为n秒​ -c n 刷新n次后即退出 6.3、内存工具6.3.1、vmstat命令：虚拟内存信息1vmstat [options][delay [count]] 选项：​ -s: 显示内存的统计数据 例： 123456789101112131415161718192021222324252627[root@centos7 ~]#vmstat -s 1865308 K total memory 189440 K used memory 274412 K active memory 145448 K inactive memory 1225172 K free memory 2200 K buffer memory 448496 K swap cache 2097148 K total swap 0 K used swap 2097148 K free swap 8210 non-nice user cpu ticks 70 nice user cpu ticks 36498 system cpu ticks 24164865 idle cpu ticks 3536 IO-wait cpu ticks 0 IRQ cpu ticks 1236 softirq cpu ticks 0 stolen cpu ticks 387226 pages paged in 174244 pages paged out 0 pages swapped in 0 pages swapped out 8310928 interrupts 7174983 CPU context switches 1548195503 boot time 29025 forks 1234[root@centos7 ~]#vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 1225240 2200 448572 0 0 2 1 34 30 0 0 100 0 0 6.3.1.1、procs: ​ r：可运行（正运行或等待运行）进程的个数，和核心数有关​ b：处于不可中断睡眠态的进程个数(被阻塞的队列的长度) 6.3.1.2、memory： ​ swpd: 交换内存的使用总量​ free：空闲物理内存总量​ buffer：用于buffer的内存总量​ cache：用于cache的内存总量 6.3.1.3、swap: ​ si：从磁盘交换进内存的数据速率(kb/s)​ so：从内存交换至磁盘的数据速率(kb/s) 6.3.1.4、io：​ bi：从块设备读入数据到系统的速率(kb/s)​ bo: 保存数据至块设备的速率 6.3.1.5、system：​ in: interrupts 中断速率，包括时钟​ cs: context switch 进程切换速率 6.3.1.6、cpu：​ us:Time spent running non-kernel code​ sy: Time spent running kernel code​ id: Time spent idle. Linux 2.5.41前,包括IO-wait time.​ wa: Time spent waiting for IO. 2.5.41前，包括in idle.​ st: Time stolen from a virtual machine. 2.6.11前, unknown. 6.3.2、iostat:统计CPU和设备IO信息123456789101112131415[root@centos7 ~]#iostatLinux 3.10.0-862.el7.x86_64 (centos7.5.localdomain) 01/24/2019 _x86_64_ (2 CPU)avg-cpu: %user %nice %system %iowait %steal %idle 0.03 0.00 0.16 0.01 0.00 99.80Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsdb 0.00 0.04 0.00 4272 0sdc 0.00 0.01 0.00 884 0sdd 0.00 0.02 0.00 2200 0sda 0.18 3.06 1.43 372232 174335sde 0.00 0.02 0.00 2200 0sdf 0.00 0.02 0.00 2204 0scd0 0.00 0.03 0.00 3298 0dm-0 0.00 0.01 0.00 1036 0 6.3.3、pmap命令：进程对应的内存映射pmap [options] pid […]​ -x: 显示详细格式的信息​ 例：pmap 1 另外一种实现 1cat /proc/PID/maps 七、系统监控工具7.1、glances命令：(EPEL源)1glances [-bdehmnrsvyz1] [-B bind] [-c server] [-C conffile] [-p port] [-P password] [--password] [-t refresh] [-f file] [-o output] 7.1.1、常用选项：​ -b: 以Byte为单位显示网卡数据速率​ -d: 关闭磁盘I/O模块​ -f /path/to/somefile: 设定输入文件位置​ -o {HTML|CSV}：输出格式​ -m: 禁用mount模块​ -n: 禁用网络模块​ -t #: 延迟时间间隔​ -1：每个CPU的相关数据单独显示 7.1.2、C/S模式下运行glances命令1、服务器模式：​ glances -s -B IPADDR​ IPADDR: 指明监听的本机哪个地址 2、客户端模式：​ glances -c IPADDR​ IPADDR：要连入的服务器端地址 7.2、dstat命令：系统资源统计,代替vmstat,iostatdstat [-afv][options..] [delay [count]] ​ -c 显示cpu相关信息 ​ -C #,#,…,total ​ -d 显示disk相关信息 ​ -D total,sda,sdb,… ​ -g 显示page相关统计数据 ​ -m 显示memory相关统计数据 ​ -n 显示network相关统计数据 ​ -p 显示process相关统计数据 ​ -r 显示io请求相关的统计数据 ​ -s 显示swapped相关的统计数据 ​ –top-cpu：显示最占用CPU的进程 ​ –top-io: 显示最占用io的进程 ​ –top-mem: 显示最占用内存的进程 ​ –top-latency: 显示延迟最大的进程 7.3、iotop&ensp;&ensp;&ensp;&ensp;iotop命令是一个用来监视磁盘I/O使用状况的top类工具iotop具有与top相似的UI，其中包括PID、用户、 I/O、进程等相关信息，可查看每个进程是如何使用IO 7.3.1、iotop常用参数​ -o, –only只显示正在产生I/O的进程或线程，除了传参，可以在运行过程中按o生效 ​ -b, –batch非交互模式，一般用来记录日志 ​ -n NUM, –iter=NUM设置监测的次数，默认无限。在非交互模式下很有用 ​ -d SEC, –delay=SEC设置每次监测的间隔，默认1秒，接受非整形数据例如1.1 ​ -p PID, –pid=PID指定监测的进程/线程 ​ -u USER, –user=USER指定监测某个用户产生的I/O ​ -P, –processes仅显示进程，默认iotop显示所有线程 ​ -a, –accumulated显示累积的I/O，而不是带宽 ​ -k, –kilobytes使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用 ​ -t, –time 加上时间戳，非交互非模式 ​ -q, –quiet 禁止头几行，非交互模式，有三种指定方式 ​ -q 只在第一次监测时显示列名 ​ -qq 永远不显示列名 ​ -qqq 永远不显示I/O汇总 7.3.2、交互按键​ left和right方向键：改变排序​ r：反向排序​ o：切换至选项–only​ p：切换至–processes选项​ a：切换至–accumulated选项​ q：退出​ i：改变线程的优先级 7.4、lsof&ensp;&ensp;&ensp;&ensp;lsof：list open files查看当前系统文件的工具。在linux环境下，一切皆文件，用户通过文件不仅可以访问常规数据，还可以访问网络连接和硬件如传输控制协议 (TCP) 和用户数据报协议 (UDP)套接字等，系统在后台都为该应用程序分配了一个文件描述符 7.4.1、命令参数​ -a：列出打开文件存在的进程 ​ -c&lt;进程名&gt;：列出指定进程所打开的文件 ​ -g：列出GID号进程详情 ​ -d&lt;文件号&gt;：列出占用该文件号的进程 ​ +d&lt;目录&gt;：列出目录下被打开的文件 ​ +D&lt;目录&gt;：递归列出目录下被打开的文件 ​ -n&lt;目录&gt;：列出使用NFS的文件 ​ -i&lt;条件&gt;：列出符合条件的进程(4、 6、协议、 :端口、 @ip ) ​ -p&lt;进程号&gt;：列出指定进程号所打开的文件 ​ -u：列出UID号进程详情 ​ -h：显示帮助信息 ​ -v：显示版本信息。 ​ -n: 不反向解析网络名字 7.4.2、lsof示例7.4.2.1、进程管理1、查看由登陆用户启动而非系统启动的进程 1lsof /dev/pts1 2、指定进程号，可以查看该进程打开的文件 1lsof -p 9527 7.4.2.2、文件管理1、查看指定程序打开的文件 1lsof -c httpd 2、查看指定用户打开的文件 1lsof -u root | more 3、查看指定目录下被打开的文件 123lsof +D /var/log/lsof +d /var/log/#参数+D为递归列出目录下被打开的文件，参数+d为列出目录下被打开的文件 7.4.2.3、网络管理1、查看所有网络连接 123lsof -i –nlsof -i@127.0.0.1#通过参数-i查看网络连接的情况，包括连接的ip、端口等以及一些服务的连接情况，例如：sshd等。也可以通过指定ip查看该ip的网络连接情况 2、查看端口连接情况 12lsof -i :80 -n#通过参数-i:端口可以查看端口的占用情况，-i参数还有查看协议，ip的连接情况等 3、查看指定进程打开的网络连接 12lsof -i –n -a -p 9527#参数-i、 -a、 -p等，-i查看网络连接情况，-a查看存在的进程，-p指定进程 4、查看指定状态的网络连接 12lsof -n -P -i TCP -s TCP:ESTABLISHED#-n:no host names, -P:no port names,-i TCP指定协议，-s指定协议状态通过多个参数可以清晰的查看网络连接情况、协议连接情况等 7.4.2.4、恢复删除文件12345lsof |grep /var/log/messagesrm -f /var/log/messageslsof |grep /var/log/messagescat /proc/653/fd/6cat /proc/653/fd/6 &gt; /var/log/messages 八、作业管理Linux的作业控制​ 前台作业：通过终端启动，且启动后一直占据终端​ 后台作业：可通过终端启动，但启动后即转入后台运行（释放终端） 让作业运行于后台​ (1) 运行中的作业： Ctrl+z​ (2) 尚未启动的作业： COMMAND &amp; 后台作业虽然被送往后台运行，但其依然与终端相关；退出终端，将关闭后台作业。如果希望送往后台后，剥离与终端的关系​ nohup COMMAND &amp;&gt;/dev/null &amp;​ screen；COMMAND 查看当前终端所有作业：jobs 作业控制：​ fg [[%]JOB_NUM]：把指定的后台作业调回前台​ bg [[%]JOB_NUM]：让送往后台的作业在后台继续运行​ kill [%JOB_NUM]： 终止指定的作业 并行运行 同时运行多个进程，提高效率 方法1​ vi all.sh​ f1.sh&amp;​ f2.sh&amp;​ f3.sh&amp; 方法2​ (f1.sh&amp;);(f2.sh&amp;);(f3.sh&amp;) 方法3​ { f1.sh&amp; f2.sh&amp; f3.sh&amp; } 九、任务计划Linux任务计划、周期性任务执行 未来的某时间点执行一次任务 ​ at 指定时间点，执行一次性任务 ​ batch 系统自行选择空闲时间去执行此处指定的任务 周期性运行某任务​ cron 9.1、at任务1、包：at 2、at命令：at [option] TIME 3、常用选项：​ -V 显示版本信息 ​ -t time 时间格式 [[CC]YY]MMDDhhmm[.ss] ​ -l 列出指定队列中等待运行的作业；相当于atq ​ -d 删除指定的作业；相当于atrm ​ -c 查看具体作业任务 ​ -f /path/file 指定的文件中读取任务​ -m 当任务被完成之后，将给用户发送邮件，即使没有标准输出 注意：作业执行命令的结果中的标准输出和错误以邮件通知给相关用户 4、TIME：定义出什么时候进行 at 这项任务的时间​ HH:MM [YYYY-mm-dd] ​ noon, midnight, teatime（4pm）​ tomorrow​ now+#{minutes,hours,days, OR weeks} 5、at时间格式 ​ HH:MM 02:00在今日的 HH:MM 进行，若该时刻已过，则明天此时执行任务 ​ HH:MM YYYY-MM-DD 02:00 2016-09-20规定在某年某月的某一天的特殊时刻进行该项任务 ​ HH:MM[am|pm] + number [minutes|hours|days|weeks]在某个时间点再加几个时间后才进行该项任务 12now + 5 min02pm + 3 days 6、执行方式：​ 1）交互式 ​ 2）输入重定向 ​ 3）at –f 文件 7、依赖与atd服务,需要启动才能实现at任务 8、at队列存放在/var/spool/at目录中 9、/etc/at.{allow,deny}控制用户是否能执行at任务​ 白名单：/etc/at.allow 默认不存在，只有该文件中的用户才能执行at命令​ 黑名单：/etc/at.deny 默认存在，拒绝该文件中用户执行at命令，而没有在at.deny 文件中的使用者则可执行​ 如果两个文件都不存在，只有 root 可以执行 at 命令 9.2、周期性任务计划cron9.2.1、相关的程序包​ cronie：主程序包，提供crond守护进程及相关辅助工具​ cronie-anacron：cronie的补充程序，用于监控cronie任务执行状况，如cronie中的任务在过去该运行的时间点未能正常运行，则anacron会随后启动一次此任务​ crontabs：包含CentOS提供系统维护任务 9.2.2、计划任务确保crond守护处于运行状态：​ CentOS 7:​ systemctl status crond​ CentOS 6:​ service crond status 9.2.3、计划周期性执行的任务提交给crond，到指定时间会自动运行系统cron任务：系统维护作业​ /etc/crontab用户cron任务：​ crontab命令 日志：/var/log/cron 9.2.3.1、系统cron任务注释行以 # 开头 123456789101112131415~]#cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 例：晚上9点10分运行echo命令 110 21 * * * wang /bin/echo "Howdy!" 9.2.3.1.1、时间表示法(1) 特定值​ 给定时间点有效取值范围内的值 (2) * ​ 给定时间点上有效取值范围内的所有值​ 表示“每…” (3) 离散取值 ​ #,#,# (4) 连续取值 ​ #-# (5) 在指定时间范围上，定义步长 /#: #即为步长 例：每3小时echo和wall命令 10 */3 * * * centos /bin/echo “howdy”; wall "welcome to Magedu!” 9.2.3.1.2、系统的计划任务​ /etc/crontab 配置文件​ /etc/cron.d/ 配置文件​ /etc/cron.hourly/ 脚本​ /etc/cron.daily/ 脚本​ /etc/cron.weekly/ 脚本​ /etc/cron.monthly/ 脚本 9.2.3.1.3、anacron系统1、运行计算机关机时cron不运行的任务，CentOS6以后版本取消anacron服务，由crond服务管理 2、对笔记本电脑、台式机、工作站、偶尔要关机的服务器及其它不一直开机的系统很重要对很有用 3、配置文件：/etc/anacrontab，负责执行/etc/ cron.daily /etc/cron.weekly/etc/cron.monthly中系统任务 ​ 字段1：如果在这些日子里没有运行这些任务…… ​ 字段2：在重新引导后等待这么多分钟后运行它 ​ 字段3：任务识别器，在日志文件中标识 ​ 字段4：要执行的任务 4、由/etc/cron.hourly/0anacron执行 5、当执行任务时，更新/var/spool/anacron/cron.daily 文件的时间戳 9.2.3.1.4、管理临时文件1、CentOS6使用/etc/cron.daily/tmpwatch定时清除临时文件 2、CentOS7使用systemd-tmpfiles-setup服务实现 3、配置文件： ​ /etc/tmpfiles.d/*.conf ​ /run/tmpfiles.d/*.conf ​ /usr/lib/tmpfiles/*.conf 4、/usr/lib/tmpfiles.d/tmp.conf ​ d /tmp 1777 root root 10d ​ d /var/tmp 1777 root root 30d 5、命令： ​ systemd-tmpfiles –clean|remove|create configfile 9.2.3.2、crontab命令定义​ 每个用户都有专用的cron任务文件：/var/spool/cron/USERNAME crontab命令： 1crontab [-u user][-l | -r | -e][-i] ​ -l 列出所有任务 ​ -e 编辑任务 ​ -r 移除所有任务 ​ -i 同-r一同使用，以交互式模式移除指定任务 ​ -u user 仅root可运行，指定用户管理cron任务 控制用户执行计划任务：​ /etc/cron.{allow,deny} 9.2.3.4、at和crontab1、一次性作业使用 at ​ 重复性作业使用crontab 2、没有被重定向的输出会被邮寄给用户 3、root能够修改其它用户的作业 4、注意：运行结果的标准输出和错误以邮件通知给相关用户​ (1) COMMAND &gt; /dev/null​ (2) COMMAND &amp;&gt; /dev/null 5、对于cron任务来讲，%有特殊用途；如果在命令中要使用%，则需要转义，将%放置于单引号中，则可不用转义]]></content>
      <categories>
        <category>进程和计划任务</category>
      </categories>
      <tags>
        <tag>进程</tag>
        <tag>计划任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux用户、组和权限管理]]></title>
    <url>%2F2018%2F09%2F21%2FLinux%E7%94%A8%E6%88%B7%E3%80%81%E7%BB%84%E5%92%8C%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[基础概念&ensp;&ensp;&ensp;&ensp; Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户、用户组的类别： 用户user Linux用户： Username/UID 管理员： root, 0普通用户： 1-60000 自动分配 系统用户： 1-499, 1-999 （CentOS7） 对守护进程获取资源进行权限分配登录用户： 500+, 1000+（CentOS7）通过交互式方式登录 组group Linux组： Groupname/GID 管理员组： root, 0普通组： 系统组： 1-499, 1-999（centos7）普通组： 500+, 1000+（centos7） 对于一个用户而言可以有不同的组，分别称为用户的基本组（主组）和附加组；基本组组名与用户名相同，且仅包含一个用户，也叫私有组。基本组以外的的组属于用户的附加组。 判断用户和组是不是管理员，不是根据名字叫root来判断的，而是根据UID和GID是不是等于0来判断的。等于0则为管理员，否则则不是。 用户配置文件 用户及其属性信息(名称、 UID、主组ID等）：/etc/passwd 组及其属性信息：/etc/group 用户密码及相关属性：/etc/shadow 组密码及相关属性：/etc/gshadow /etc/passwd123456[root@localhost ~]#cat /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin /etc/passwd中一行记录对应着一个用户，每行记录又被冒号(:)分隔为7个字段： 用户名:口令:UID:GID:注释性描述:主目录:登录Shell类型 系统中有一类用户称为系统用户，这些用户在/etc/passwd文件中也占有一条记录，但是不能登录，因为它们的登录Shell为空。它们的存在主要是方便系统管理，满足相应的系统进程对文件属主的要求.系统用户含义: ​ bin 拥有可执行的用户命令文件​ sys 拥有系统文件​ adm 拥有帐户文件​ uucp UUCP使用​ lp lp或lpd子系统使用​ nobody NFS使用 /etc/group&ensp;&ensp;&ensp;&ensp;当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 用户要访问属于附加组的文件时，必须首先使用newgrp命令使自己成为所要访问的组中的成员。123456789[root@localhost ~]#cat /etc/grouproot:x:0:bin:x:1:daemon:x:2:sys:x:3:adm:x:4:tty:x:5:disk:x:6:lp:x:7: 此文件的格式也类似于/etc/passwd文件，由冒号(:)隔开若干个字段，这些字段有： 组名:口令:组标识号:组内用户列表 组名:是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。 口令:字段存放的是用户组加密后的口令字。 组标识号:与用户标识号类似，也是一个整数，被系统内部用来标识组。 组内用户列表:是属于这个组的所有用户的列表，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组,也可能是附加组 /etc/shadow/etc/shadow文件用于单独存放加密后的口令字，只有超级用户才拥有该文件读权限注意：/etc/shadow中的记录行与/etc/passwd中的一一对应，它由pwconv命令根据/etc/passwd中的数据自动产生123456[root@localhost ~]#cat /etc/shadowroot:$6$9T5n/VcnCXrseL/f$Nqs3zA.hfJPXIrNtuiyUD9Ps6s.aGC.XYPrABjgPPABgvRIyMntuEkw2All7VhDQd5XM3AiN2RqAdwuoUfJ0K1::0:99999:7:::bin:*:17632:0:99999:7:::daemon:*:17632:0:99999:7:::adm:*:17632:0:99999:7:::lp:*:17632:0:99999:7::: 它的文件格式与/etc/passwd类似，由若干个字段组成，字段之间用”:”隔开。这些字段是： 登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志 ​ 登录名:/etc/passwd文件中的登录名相一致的用户账号 ​ 加密口令:字段存放的是加密后的用户口令字，长度为13个字符。如果为空，则对应用户没有口令，登录时不需要口令； ​ 最后一次修改时间:表示的是从某个时刻起，到用户最后一次修改口令时的天数 ​ 最小时间间隔:指的是两次修改口令之间所需的最小天数 ​ 最大时间间隔:指的是口令保持有效的最大天数 ​ 警告时间:字段表示的是从系统开始警告用户到用户密码正式失效之间的天数 ​ 不活动时间:表示的是用户没有登录活动但账号仍能保持有效的最大天数 ​ 失效时间:字段给出的是一个绝对的天数，如果使用了这个字段，那么就给出相应账号的生存期。期满后，该账号就不再是一个合法的账号，也就不能再用来登录了。 /etc/gshadow123456789[root@localhost ~]#cat /etc/gshadowroot:::bin:::daemon:::sys:::adm:::tty:::disk:::lp::: 它的文件格式与/etc/group类似，由若干个字段组成，字段之间用”:”隔开。这些字段是：群组名称：就是群组名称群组密码：组管理员列表：组管理员的列表，更改组密码和成员以当前组为附加组的用户列表： (分隔符为逗号) 用户和组的管理命令用户管理命令 useradd(创建用户)usermod(修改用户)userdel(删除用户) 组管理命令 groupadd(创建组)groupmod(修改组)groupdel(删除组) 密码配置命令 passwd(设置用户密码)gpasswd（设置组密码） 用户创建:useradd1useradd [options] LOGIN ​ -u UID:用户ID的数字值。此值必须为唯一的，除非使用了-o选项。此值必须非负，默认使用大于等于UID_MIN，且大于任何其他用户ID最小值​ -o 配合-u 选项，不检查UID的唯一性​ -g GID：指明用户所属基本组，可为组名，也可以GID​ -c “COMMENT”：用户的注释信息​ -d HOME_DIR: 以指定的路径(不存在)为家目录​ -s SHELL: 指明用户的默认shell程序，可用列表在/etc/shells文件中​ -G GROUP1[,GROUP2,…]：为用户指明附加组，组须事先存在​ -N 不创建私用组做主组，使用users组做主组​ -r 创建系统用户 CentOS 6: ID&lt;500， CentOS 7: ID&lt;1000​ -m 创建家目录，用于系统用户​ -M 不创建家目录，用于非系统用户 useradd -D：显示创建用户时的默认设置；useradd -D 选项：设置某默认选项； 例1：创建一个用户sam，为sam指定主目录为/usr/sam1useradd -d /usr/sam sam 例2：创建用户gentoo，附加组为bin和root，默认shell为/bin/csh，注释信息为“Gentoo Distribution”1useradd -c "Gentoo Distribution" -G bin,root -s /bin/csh gentoo 例3:新建用户gem，指定该用户的登录Shell是 /bin/sh，指定它属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。123groupadd groupgroupadd admuseradd -s /bin/sh -g group –G "adm,root" gem 例4:创建下面的用户、组和组成员关系名字为webs 的组用户nginx 使用webs 作为附属组用户varnish，也使用webs 作为附属组用户mysql，不可交互登录系统，且不是webs 的成员， nginx， varnish，mysql密码都是magedu1234567groupadd websuseradd nginx -G websuseradd varnish -G websuseradd mysql -s /sbin/nologinecho magedu | passwd --stdin nginxecho magedu | passwd --stdin varnishecho magedu | passwd --stdin mysql 用户属性修改:usermod注意：usermod不允许改变正在线上的使用者帐号名称。当usermod改变userID,必须确认这名user没在电脑上执行任何程序 1usermod [OPTION] login ​ -u UID: 新UID​ -g GID: 新主组​ -G GROUP1[,GROUP2,…[,GROUPN]]]：新附加组，原来的附加组将会被覆盖；若保留原有，则要同时使用-a选项​ -s SHELL：新的默认SHELL​ -c ‘COMMENT’：新的注释信息​ -d HOME: 新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用-m选项​ -l login_name: 新的名字​ -L: lock指定用户,在/etc/shadow 密码栏的增加 !​ -U: unlock指定用户,将 /etc/shadow 密码栏的 ! 拿掉​ -e YYYY-MM-DD: 指明用户账号过期日期​ -f INACTIVE: 设定非活动期限 删除用户:userdel userdel [OPTION]… login-r：用户主目录中的文件将随用户主目录和用户邮箱一起删除 创建组:groupadd groupadd [OPTION]… group_name-g GID :指明GID,默认是上一个组的GID+1-r:创建系统组，默认为1-999数字 修改和删除组 组属性修改:groupmod groupmod [OPTION]… group-n group_name: 新名字-g GID: 新的GID 组删除：groupdelgroupdel GROUP passwd：密码设置常用命令以下命令只有root才有权限操作passwd：修改自己的密码passwd username：修改其它用户的密码-d：删除指定用户密码-l： 锁定指定用户-e：强制用户下次登录修改密码-f：强制操作-n mindays：指定最短使用期限-x maxdays： 最大使用期限-w warndays：提前多少天开始警告-i inactivedays：非活动期限–stdin：从标准输入接收用户密码echo “PASSWORD” | passwd –stdin USERNAME​ 更改组密码:gpasswd gpasswd [OPTION] GROUP-a UserName：把用户添加至组中-d UserName：从此组中移除此用户； newgrp命令：登录到一个新组 chage命令：修改用户账号的各种期限；修改账户或口令的期限设定1234561. 口令最短使用期限7天，最长使用期限30天，警告期3天，非活动期3天。 [root@localhost ~]# chage -m7 -M30 -W3 -I3 mageedu 2. 修改口令最近一次修改时间，需转换为设定时间到1970年1月1日的天数 [root@localhost ~]# chage -d16860 mageedu 3. 设置账户过期时间，需转换为设定时间到1970年1月1日的天数。 [root@localhost ~]# chage -E16920 mageedu chsh：更换登入系统时使用的shell, chfn：提供使用者更改个人资讯, finger：使用者查询一些其他使用者的资料, pwck : 检查密码文件的完整性, grpck：检查组文件的完整性 su：切换用户 不读取目标用户的配置文件,不改变当前工作目录（非登录式切换，半切换)su UserName 读取目标用户的配置文件,切换至家目录（登录式切换，完全切换)su - UserName 仅以指定的用户的身份运行此处指定的命令，而不执行真正的身份切换操作su [-] UserName -c ‘COMMAND’注意：root切换至任何其它用户无须认证密码；普通用户切换至其它用户，都需要密码 用户和用户组权限管理12[root@localhost ~]#ll -d /etc # 显示文件名与相关属性命令drwxr-xr-x. 137 root root 12288 Oct 21 09:57 /etc 类型和权限(permission)： 显示格式： 类型和权限 连接数 所有者 用户组 文件大小 修改日期 文件名 权限组合机制：(8bites 二进制) 第二道十个字符：每三个为一组，均为’rwx’三个参数组合rwxrwxrwx每个位置固定不定，若无则为空，用’-‘符号表示 r：readable, 读；w：writable, 写；x：excutable，执行 r=4 w=2 x=1 -=0 文件权限系统主要分为3类用户： 属主：owner,u 属组：group,g 其他：other,o 其与之对应的权限:​ rwx rwx rwx 文件和目录的权限管理： 对于文件的含义: r：可获取文件的数据；可以使用类似于cat命令查看文件内容 w: 可修改文件的数据；可以编或者删除此文件 x：可将此文件运行为进程；可以在命令提示符下当做命令提交给内核运行 对于目录的含义: r：可使用ls命令获取其下的所有文件列表； w: 可修改此目录下的文件列表；即创建或删除文件； x: 可cd至此目录中，且可使用ls -l来获取所有文件的详细属性信息； X: 只针对目录添加x权限，不对目录下的文件添加x权限； 权限管理命令chmod:更改文件目录权限用户类型：u：属主 g：属组 o：其它 a: 所有 chmod [OPTION]… MODE[,MODE]… FILE… 赋权表示法：直接操作一类用户的所有权限位rwx用等号表示：[u|g|o|a]=rwx中的一位或者多位 授权表示法：直接操作一类用户的一个权限位r,w,x用加减号表示：[u|g|o|a][+|-]rwx chmod [OPTION]… OCTAL-MODE FILE…直接使用三位数字的方式给文件目录增加权限，分别表示所有者、所属组、其他人的权限数字的表示方法同上：8bites 二进制表示权限的组合机制r=4 w=2 x=1 三位相加12345[root@CentOS6 data]#ll--w-------. 1 root root 0 Oct 21 20:29 f1[root@CentOS6 data]#chmod 666 f1 #对 (u g o)添加读写权限[root@CentOS6 data]#ll-rw-rw-rw-. 1 root root 0 Oct 21 20:29 f1 chmod [OPTION]… –reference=RFILE FILE… 参照某个文件的权限来进行授权操作123456789[root@CentOS6 data]#ll--w-------. 1 root root 0 Oct 21 20:29 f1-rw-r--r--. 1 root root 0 Oct 21 21:20 f2-rw-r--r--. 1 root root 0 Oct 21 21:20 f3[root@CentOS6 data]#chmod --reference=f1 f2 f3[root@CentOS6 data]#ll--w-------. 1 root root 0 Oct 21 20:29 f1--w-------. 1 root root 0 Oct 21 21:20 f2--w-------. 1 root root 0 Oct 21 21:20 f3 注意：普通用户仅能修改属主为自己的那些文件的权限；root可以更改所有用户 chown:更改文件目录的所有者，也可以更改所属组12345[root@CentOS6 data]#ll f1-rw-rw-rw-. 1 root root 0 Oct 21 20:29 f1[root@CentOS6 data]#chown xie f1[root@CentOS6 data]#ll f1-rw-rw-rw-. 1 xie root 0 Oct 21 20:29 f1 chgrp [OPTION]… GROUPFILE… 更改所属组1234[root@CentOS6 data]#ll f1-rw-rw-rw-. 1 xie root 0 Oct 21 20:29 f1[root@CentOS6 data]#ll f1-rw-rw-rw-. 1 xie rpc 0 Oct 21 20:29 f1 注意： 普通用户是不能更改文件的所有者的 作为普通用户，要想更改文件的所属组： 文件是普通用户它自己的如果要更改的组，普通用户必须在这个组里 umask:文件的权限反向掩码，遮罩码 umask：查看当前umask12[root@localhost ~]#umask0022 系统默认为：0022 表示特殊权限、所有者权限、所有组权限、其他人权限更改默认设置位置：/etc/bashrc 对文件目录的umask操作 文件：666-umask 文件默认不能拥有执行权限;如果减得的结果中有执行权限，则需要将其加1文件夹：777-umask Linux文件系统上的特殊权限SUID功能：继承二进制程序所有者的权限权限设定：chmod u+s file…chmod u-s file…chmod 4### file…1234567891011[root@localhost data]#ll f1-rw-r--r--. 1 root root 595 Oct 14 14:16 f1[root@localhost data]#chmod u+s f1[root@localhost data]#ll f1-rwSr--r--. 1 root root 595 Oct 14 14:16 f1[root@localhost data]#chmod u-s f1[root@localhost data]#ll f1-rw-r--r--. 1 root root 595 Oct 14 14:16 f1[root@localhost data]#chmod 4644 f1[root@localhost data]#ll f1 -rwSr--r--. 1 root root 595 Oct 14 14:16 f1 SUID只对二进制可执行程序有效SUID设置在目录上无意义 SGID 可执行文件上SGID权限功能：继承二进制程序所有组的权限权限设定：chmod g+s file…chmod g-s file…chmod 2### file… 目录上的SGID权限功能：此目录新建的文件继承目录的所属组权限设定：chmod g+s dir…chmod g-s dir…chmod 2### dir… Sticky位功能：作用于目录，此目录的文件只能被所有者或root删除权限设定:chmod o+t dir…chmod o-t dir…chmod 1### dir…12[root@localhost ~]#ll -d /tmpdrwxrwxrwt. 15 root root 4096 Oct 23 18:33 /tmp 权限位映射SUID: user,占据属主的执行权限位s： 属主拥有x权限S：属主没有x权限SGID: group,占据属组的执行权限位s： group拥有x权限S： group没有x权限Sticky: other,占据other的执行权限位t： other拥有x权限T： other没有x权限 访问控制列表ACL： Access Control List，实现灵活的权限管理除了文件的所有者，所属组和其它人，可以对更多的用户设置权限CentOS7 默认创建的xfs和ext4文件系统具有ACL功能CentOS7 之前版本，默认手工创建的ext4文件系统无ACL功能,需手动增加tune2fs –o acl /dev/sdb1mount –o acl /dev/sdb1 /mnt/testACL生效顺序：所有者，自定义用户，自定义组，其他人 1、常见的一些命令​ setfacl -m u:username:rwx file 为用户的文件赋予访问权限rwx​ setfacl -m g:groupname:rw file 为组的文件赋予访问权限rwx​ getfacl filename 查看设置的acl权限​ setfacl -b filename 清空acl权限​ setfacl -k dir 删除默认ACL权限 123456789101112131415161718192021222324[root@localhost data]#ll f1-rw-r--r--. 1 root root 595 Oct 14 14:16 f1[root@localhost data]#setfacl -m u:xie:rw f1[root@localhost data]#ll f1-rw-rw-r--+ 1 root root 595 Oct 14 14:16 f1 # +代表有acl权限[root@localhost data]#getfacl f1# file: f1# owner: root# group: rootuser::rw-user:xie:rw-group::r--mask::rw-other::r--[root@localhost data]#setfacl -b f1[root@localhost data]#ll f1-rw-r--r--. 1 root root 595 Oct 14 14:16 f1[root@localhost data]#getfacl f1# file: f1# owner: root# group: rootuser::rw-group::r--other::r-- 练习 当用户docker对/testdir 目录无执行权限时，意味着无法做哪些操作？答:无法cd至此目录中；无法查看目录的详细属性；无法查看文件的内容； 当用户mongodb对/testdir 目录无读权限时，意味着无法做哪些操作？答:可使用ls命令获取其下的所有文件列表 当用户redis 对/testdir 目录无写权限时，该目录下的只读文件file1是否可修改和删除？答:不行，文件能不能删除由目录的权限决定的。（rw） 当用户zabbix对/testdir 目录有写和执行权限时，该目录下的只读文件file1是否可修改和删除？答:可以 复制/etc/fstab文件到/var/tmp下，设置文件所有者为tomcat读写权限，所属组为apps组有读写权限，其他人无权限 123456useradd tomcatgroupadd appscp /etc/fstab /var/tmpchown tomcat /var/tmp/fstabchgrp apps /var/tmp/fstabchmod 660 /var/tmp/fstab 误删除了用户git的家目录，请重建并恢复该用户家目录及相应的权限属性 123456useradd gitrm -rf /home/gitmkdir /home/gitcp -a /etc/skel/.[^.]* /home/gitchown -R git.git /home/gitchmod 700 /home/git 在/testdir/dir里创建的新文件自动属于webs组，组apps的成员如：tomcat能对这些新文件有读写权限，组dbs的成员如： mysql只能对新文件有读权限，其它用户（不属于webs,apps,dbs）不能访问这个文件夹 1234567891011mkdir -p /testdir/dirgroupadd webschgrp webs /testdir/dirchmod g+s /testdir/dir groupadd apps groupadd dbsuseradd -G apps tomcatuseradd -G dbs mysqlsetfacl -m g:apps:rw /testdir/dir/setfacl -m g:dbs:r /testdir/dir/chmod o= /testdir/dir 备份/testdir/dir里所有文件的ACL权限到/root/acl.txt中，清除/testdir/dir中所有ACL权限，最后还原ACL权限 123getfacl -R /testdir/dir &gt; /root/acl.txt setfacl -b /testdir/dirsetfacl -R –set-file=acl.txt /testdir/dir]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>user</tag>
        <tag>group</tag>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见文本或文件处理命令]]></title>
    <url>%2F2018%2F08%2F11%2F%E5%B8%B8%E8%A7%81%E6%96%87%E6%9C%AC%E6%88%96%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[文件查看命令cat1cat [OPTION]... [FILE]... -E： 显示行结束符 $ 12345678910[root@cetos7 ~]#cat /etc/fstab -E$#$# /etc/fstab$# Created by anaconda on Sat Aug 11 10:51:01 2018$#$# Accessible filesystems, by reference, are maintained under '/dev/disk'$# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info$#$UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0$ -n： 对显示出的每一行进行编号 12345678910[root@cetos7 ~]#cat /etc/fstab -n 1 2 # 3 # /etc/fstab 4 # Created by anaconda on Sat Aug 11 10:51:01 2018 5 # 6 # Accessible filesystems, by reference, are maintained under '/dev/disk' 7 # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info 8 # 9 UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0 -A：显示所有控制符 12345678910[root@cetos7 ~]#cat /etc/fstab -A$#$# /etc/fstab$# Created by anaconda on Sat Aug 11 10:51:01 2018$#$# Accessible filesystems, by reference, are maintained under '/dev/disk'$# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info$#$UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0$ -b： 非空行编号 12345678910[root@cetos7 ~]#cat /etc/fstab -b 1 # 2 # /etc/fstab 3 # Created by anaconda on Sat Aug 11 10:51:01 2018 4 # 5 # Accessible filesystems, by reference, are maintained under '/dev/disk' 6 # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info 7 # 8 UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0 -s：压缩连续的空行成一行 1234567891011121314151617181920[root@cetos7 ~]#cat &gt; f1112312121122121221334[root@cetos7 ~]#cat f1 -s112312121122121221334 tac与cat查看文件的内容相反，倒过来显示文件内容 123456789101112131415161718192021222324252627[root@cetos7 ~]#cat /etc/fstab ## /etc/fstab# Created by anaconda on Sat Aug 11 10:51:01 2018## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0UUID=7d1b5c8d-8054-4496-befe-267963e07605 /boot xfs defaults 0 0UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 /data xfs defaults 0 0UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201 swap swap defaults 0 0[root@cetos7 ~]#tac /etc/fstab UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201 swap swap defaults 0 0UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 /data xfs defaults 0 0UUID=7d1b5c8d-8054-4496-befe-267963e07605 /boot xfs defaults 0 0UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0## See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info# Accessible filesystems, by reference, are maintained under '/dev/disk'## Created by anaconda on Sat Aug 11 10:51:01 2018# /etc/fstab#[root@cetos7 ~]# rev123456789101112131415161718192021222324252627[root@cetos7 ~]#cat /etc/fstab ## /etc/fstab# Created by anaconda on Sat Aug 11 10:51:01 2018## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0UUID=7d1b5c8d-8054-4496-befe-267963e07605 /boot xfs defaults 0 0UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 /data xfs defaults 0 0UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201 swap swap defaults 0 0[root@cetos7 ~]#rev /etc/fstab #batsf/cte/ #8102 10:15:01 11 guA taS no adnocana yb detaerC ##'ksid/ved/' rednu deniatniam era ,ecnerefer yb ,smetsyselif elbisseccA #ofni erom rof )8(diklb ro/dna )8(tnuom ,)8(sfdnif ,)5(batsf segap nam eeS ##0 0 stluafed sfx / 0292c2e9b04c-00ca-d4c4-a400-15bff33d=DIUU0 0 stluafed sfx toob/ 50670e369762-efeb-6944-4508-d8c5b1d7=DIUU0 0 stluafed sfx atad/ 259715fcc1f3-7f99-f754-e821-8a4e6557=DIUU0 0 stluafed paws paws 1025bf76ef56-d7c8-9f44-a39e-5109e251=DIUU[root@cetos7 ~]# 如果显示的内容过多，我们可以分页查看文件内容: more: 分页查看文件 less: 与more正好相反 作用：查看文件，以较少的内容进行输出，按下辅助功能键（数字+回车、空格键+上下方向键）查看更多 语法：#less 需要查看的文件路径 在退出的只需要按下q键即可 head:显示文本前或后行内容 用法：head [OPTION]… [FILE]… -c #: 指定获取前#字节 -n #: 指定获取前#行 -#： 指定行数 tail 显示文本后几行的内容用法：tail [OPTION]… [FILE]… ​ -c #: 指定获取后#字节 ​ -n #: 指定获取后#行​ -#：同上 ​ -f: 跟踪显示文件fd新追加的内容,常用日志监控 ​ 相当于 –follow=descriptor ​ -F: 跟踪文件名，相当于–follow=name –retry ​ tailf 类似tail –f，当文件不增长时并不访问文件 文本处理工具wc： 收集文本统计数据计数单词总数、行总数、字节总数和字符总数 可以对文件或STDIN中的数据运行 用法：wc [OPTION]…[FILE]…常用选项： -l 只计数行数 -w 只计数单词总数 -c 只计数字节总数 -m 只计数字符总数 -L 显示文件中最长行的长度文本排序sort 把整理过的文本显示在STDOUT，不改变原始文件 sort:排序用法：sort [options] file(s)常用选项: -r 执行反方向（由上至下）整理 -R 随机排序 -n 执行按数字大小整理 -f 选项忽略（fold）字符串中的字符大小写 -u 选项（独特， unique）删除输出中的重复行 -t c 选项使用c做为字段界定符 -k X 选项按照使用c字符分隔的X列来整理能够使用多次uniq uniq命令：从输入中删除前后相接的重复的行用法：uniq [OPTION]… [FILE]…常用选项: -c: 显示每行重复出现的次数 -d: 仅显示重复过的行 -u: 仅显示不曾重复的行 注：连续且完全相同方为重复常和sort 命令一起配合使用：sort userlist.txt | uniq -c比较文件 cut: 文本内容切割用法：cut [OPTION]… [FILE]…常用选项: -d DELIMITER: 指明分隔符，默认tab -f FILEDS: #: 第#个字段 #,#[,#]：离散的多个字段，例如1,3,6 #-#：连续的多个字段, 例如1-6 混合使用： 1-3,7 -c 按字符切割 例： 123cut -d: -f1 /etc/passwd cat /etc/passwd | cut -d: -f7 cut -c2-5 /usr/share/dict/words paste: 合并两个文件同行号的列到一行用法：paste [OPTION]… [FILE]…常用选项: -d 分隔符：指定分隔符，默认用TAB -s : 所有行合成一行显示 例： 12paste f1 f2paste -s f1 f2 文件查找locate1、查询系统上预建的文件索引数据库​ /var/lib/mlocate/mlocate.db2、依赖于事先构建的索引​ 索引的构建是在系统较为空闲时自动进行(周期性任务)，管理员手动更新数据库(updatedb)3、索引构建过程需要遍历整个根文件系统，极消耗资源4、工作特点: 查找速度快 模糊查找 非实时查找 搜索的是文件的全路径，不仅仅是文件名 可能只搜索用户具备读取和执行权限的目录 4、有用的选项 ​ -i 不区分大小写的搜索 ​ -n N 只列举前N个匹配项目 ​ -r 使用正则表达式 例 1234搜索以”.conf”结尾的文件locate -r “\.conf$”搜索/etc下以.conf结尾的文件locate -r “^/etc/.\.conf$” find1、实时查找工具，通过遍历指定路径完成文件查找2、工作特点： 查找速度略慢 精确查找 实时查找 可能只搜索用户具备读取和执行权限的目录 语法：find [OPTION]… [查找路径][查找条件] [处理动作] ​ 查找路径：指定具体目标路径；默认为当前目录 ​ 查找条件：指定的查找标准，可以文件名、大小、类型、权限等标准进行； 默认为找出指定路径下的所有文件 ​ 处理动作：对符合条件的文件做操作，默认输出至屏幕 查找条件1、指搜索层级 ​ -maxdepth level 最大搜索目录深度,指定目录为第1级 ​ -mindepth level 最小搜索目录深度 2、先处理目录内的文件，再处理目录 ​ -depth 3、根据文件名和inode查找： ​ -name “文件名称”：支持使用glob ​ *, ?, [], [^] ​ -iname “文件名称”：不区分字母大小写 ​ -inum n： 按inode号查找 ​ -samefile name：相同inode号的文件 ​ -links n：链接数为n的文件 ​ -regex “PATTERN”：以PATTERN匹配整个文件路径字符串，而不仅仅是文件名称 例： 1234find /etc/ -maxdepth2 -mindepth2 -name passwd 显示/etc/下包含passwd的两级目录find /data -name "*f1"查找data目录下包含f1的文件，此处的*表示通配符，引号必须加find /home -user wang -ls 长格式显示所有者为wang的文件useradd xixi -u 1004 将无主文件重新赋予新的所有者 4、根据属主、属组查找： ​ -user USERNAME：查找属主为指定用户(UID)的文件 ​ -group GRPNAME: 查找属组为指定组(GID)的文件 ​ -uid UserID：查找属主为指定的UID号的文件 ​ -gid GroupID：查找属组为指定的GID号的文件 ​ -nouser：查找没有属主的文件 ​ -nogroup：查找没有属组的文件 例： 1find /home -nouser -o -nogroup 查找无主或无组的文件 5、根据文件类型查找：-type TYPE: ​ f: 普通文件 ​ d: 目录文件 ​ l: 符号链接文件 ​ s：套接字文件 ​ b: 块设备文件 ​ c: 字符设备文件 ​ p: 管道文件 6、空文件或目录 -empty 例： 1find /app -type d -empty 7、组合条件 与：-a 或：-o 非：-not, ! 7.1、德·摩根定律： (非 A) 或 (非 B) = 非(A 且 B) (非 A) 且 (非 B) = 非(A 或 B) 例： 12!A -a !B = !(A -o B)!A -o !B = !(A -a B) 例： 找出/tmp目录下，属主不是root，且文件名不以f开头的文件 12find /tmp \(-not -user root -a -not -name 'f*'\) -lsfind /tmp -not \( -user root -o -name 'f*' \) -ls 查找/etc/下，除/etc/sane.d目录的其它所有.conf后缀的文件 1find /etc -path '/etc/sane.d' -a -prune -o -name "*.conf" 查找/etc/下，除/etc/sane.d和/etc/fonts两个目录的所有.conf后缀的文件 1find /etc \( -path "/etc/sane.d" -o -path "/etc/fonts"\) -a -prune -o -name "*.conf" 查找data 目录下非空非普通的文件 1find /data/ ! -empty -o -type f 8、根据文件大小来查找：​ -size [+|-]#UNIT​ 常用单位：k, M, G，c（byte）​ #UNIT: (#-1, #]​ 如：6k 表示(5k,6k]​ -#UNIT：[0,#-1]​ 如：-6k 表示[0,5k]​ +#UNIT：(#,∞)​ 如：+6k 表示(6k,∞) 9、根据时间戳：9.1、以“天”为单位； ​ -atime [+|-]#,​ #: [#,#+1)​ +#: [#+1,∞]​ -#: [0,#)​ -mtime​ -ctime9.2、以“分钟”为单位：​ -amin​ -mmin​ -cmin例： 1find /etc/ -mmin -1 查找一分钟以内被修改的文件 10、根据权限查找：-perm [/|-]MODE​ MODE: 精确权限匹配​ /MODE：任何一类(u,g,o)对象的权限中只要能一位匹配即可，或关系，+ 从centos7开始淘汰​ -MODE：每一类对象都必须同时拥有指定权限，与关系​ 0 表示不关注 例： 12345678find -perm 755 会匹配权限模式恰好是755的文件只要当任意人有写权限时，find -perm +222就会匹配只有当每个人都有写权限时，find -perm -222才会匹配只有当其它人（other）有写权限时，find -perm -002才会匹配find -perm 666 查找当前文件夹下权限位666的文件find -perm /666 只要有一个权限符合就行find -perm -666 表示都要有读写权限-表示交集（都有） /表示并集 处理动作&ensp;&ensp;&ensp;&ensp;简单理解为当我们把要查找的内容搜索出来以后要做的事情 -print：默认的处理动作，显示至屏幕 -ls：类似于对查找到的文件执行“ls -l”命令 -delete：删除查找到的文件 -fls file：查找到的所有文件的长格式信息保存至指定文件中 -ok COMMAND {} \; 对查找到的每个文件执行由COMMAND指定的命令，对于每个文件执行命令之前，都会交互式要求用户确认 -exec COMMAND {} \; 对查找到的每个文件执行由COMMAND指定的命令 {}: 用于引用查找到的文件名称自身 find传递查找到的文件至后面指定的命令时，查找到所有符合条件的文件一次性传递给后面的命令 参数替换xargs1、由于很多命令不支持管道|来传递参数，而日常工作中有这个必要，所以就有了xargs命令2、xargs用于产生某个命令的参数，xargs 可以读入 stdin 的数据，并且以空格符或回车符将 stdin 的数据分隔成为arguments注意：文件名或者是其他意义的名词内含有空格符的情况3、有些命令不能接受过多参数，命令执行可能会失败，xargs可以解决示例： 123456xargs将前面的输入用空格分开然后传给后面的命令echo f&#123;1..100&#125; | xargs -n1 touch n1 n1表示每次只创建一个文件 数字可以修改ls f* |xargs rmfind /sbin -perm +700 |ls -l 这个命令是错误的find /sbin -perm +700 | xargs ls –l 4、find和xargs格式：find | xargs COMMAND find 示例 备份配置文件，添加.orig这个扩展名 1find -name "*.conf" -exec cp &#123;&#125; &#123;&#125;.orig \; 提示删除存在时间超过３天以上的joe的临时文件 1find /tmp -ctime +3 -user joe -ok rm &#123;&#125; \; 在主目录中寻找可被其它用户写入的文件 1find ~ -perm -002 -exec chmod o-w &#123;&#125; \; 查找/data下的权限为644，后缀为sh的普通文件，增加执行权限 1find /data –type f -perm 644 -name "*.sh" –exec chmod 755 &#123;&#125; \; 查看/home的目录 1find /home –type d -ls 压缩、解压缩及归档工具compress/uncompress1、compress [-dfvcVr][-b maxbits] [file …] ​ -d: 解压缩，相当于uncompress ​ -c: 结果输出至标准输出,不删除原文件 ​ -v: 显示详情 2、uncompress 解压缩 3、zcat file.Z &gt;filecompress file 压缩时会删除原文件 gzip/gunzip1、gzip [OPTION]… FILE … ​ -d: 解压缩，相当于gunzip ​ -c: 将压缩或解压缩的结果输出至标准输出 ​ -#：1-9，指定压缩比，值越大压缩比越大 2、zcat：不显式解压缩的前提下查看文本文件内容 例： 1234gzip -9 mmgzip -c messages &gt;messages.gzgzip -c -d messages.gz &gt; messageszcat messages.gz &gt; messages 3、gunzip mm.gz 解压缩4、zcat mm.gz 查看压缩文件 bzip2/bunzip2/bzcat1、bzip2 [OPTION]… FILE … ​ -k: keep, 保留原文件 ​ -d：解压缩 ​ -#：1-9，压缩比，默认为9 2、bzcat：不显式解压缩的前提下查看文本文件内容 xz/unxz/xzcat1、xz [OPTION]… FILE … ​ -k: keep, 保留原文件 ​ -d：解压缩 ​ -#：1-9，压缩比，默认为6 2、xzcat: 不显式解压缩的前提下查看文本文件内容gz bz2 常用的两种压缩文件 zip/unzip1、打包压缩 1zip -r /testdir/sysconfig /etc/sysconfig/ #把后面的文件压缩为sysconfig.zip 解包解压缩 1234unzip sysconfig.zipcat /var/log/messages | zip messages – #此处的-表示把前面的作为标准输入传给zipunzip -p message &gt; message tar工具tar [OPTION]…(1) 创建归档 1tar -cpvf /PATH/TO/SOMEFILE.tar FILE… ​ c：表示创建 ​ f：表示需要打包的文件名(2) 追加文件至归档： 注：不支持对压缩文件追加 1tar -r -f /PATH/TO/SOMEFILE.tar FILE… (3) 查看归档文件中的文件列表 1tar -t -f /PATH/TO/SOMEFILE.tar (4) 展开归档 12tar -x -f /PATH/TO/SOMEFILE.tartar -x -f /PATH/TO/SOMEFILE.tar -C /PATH/ (5) 结合压缩工具实现：归档并压缩-j: bzip2, -z: gzip, -J: xz -T：选项指定输入文件 -X：选项指定包含要排除的文件列表 1234tar zcvf mybackup.tgz -T /root/includefilelist -X /root/excludefilelisttar -cpvf data.tar /data p表示保留属性 f表示文件 /data表示要打包的目录无论什么样的后缀都可以解开tar xvf data.tar.bz2 -C /mnt (6)分割大的 tar 文件为多份小文件： 12345split -b Size -d tar-file-name prefix-name prefix前缀split -b 1M -d mybackup.tgz mybackup-partssplit -b 1M mybackup.tgz mybackup-parts合并：cat mybackup-parts* &gt; mybackup.tar.gz cpio功能：复制文件从或到归档&ensp;&ensp;&ensp;&ensp;cpio命令是通过重定向的方式将文件进行打包备份，还原恢复的工具，它可以解压以“.cpio”或者“.tar”结尾的文件 ​ cpio [选项] &gt; 文件名或者设备名 ​ cpio [选项] &lt; 文件名或者设备名 选项 ​ -o 将文件拷贝打包成文件或者将文件输出到设备上 ​ -A 向已存在的归档文件中追加文件 ​ -i 解包，将打包文件解压或将设备上的备份还原到系统 ​ -t 预览，查看文件内容或者输出到设备上的文件内容 ​ -v 显示打包过程中的文件名称。 ​ -d 解包生成目录，在cpio还原时，自动的建立目录 例: 123456781.将etc目录备份： find ./etc -print |cpio -ov &gt;bak.cpio2.将/data内容追加bak.cpio find /data | cpio -oA -F bak.cpio3.内容预览 cpio -tv &lt; etc.cpio4.解包文件 cpio -idv &lt; etc.cpio]]></content>
      <categories>
        <category>文本命令</category>
      </categories>
      <tags>
        <tag>命令</tag>
        <tag>查找</tag>
        <tag>压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本处理三剑客之awk]]></title>
    <url>%2F2018%2F07%2F07%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F</url>
    <content type="text"><![CDATA[Linux文本处理工具三剑客：grep、sed、awk.其中grep是一种文本过滤工具,sed是文本行编辑器,而awk是一种报表生成器，就是对文件进行格式化处理。这里的格式化就是对文件内容进行各种“排版”，进而格式化显示。 在Linux之上我们使用的是GNU awk，简称gawk.我们通过man gawk得知gawk–模式扫描和处理语言，gawk是一种过程式编程语言。gawk还支持条件判断、数组、循环等各种编程语言中所有可以使用的功能，因此我们还可以把gwak称为一种脚本语言解释器。 基本用法： awk [options] ‘program’ var=value file… awk [options] -f programfile var=value file… awk [options] ‘BEGIN{action;… }pattern{action;… }END{action;… }’ file … awk程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块，共3部分组成 program 通常是被放在单引号中 选项： -F “分隔符” 指明输入时用到的字段分隔符 -v var=value 变量赋值 awk语言 基本格式：awk [options] ‘program’ file…Program：pattern{action statements;..} pattern和action pattern部分决定动作语句何时触发及触发事件 BEGIN,END action statements对数据进行处理，放在{}内指明 print, printf 分割符、域和记录 awk执行时，由分隔符分隔的字段（域）标记1,1,2…n称为域标识。n称为域标识。0为所有域，注意：此时和shell中变量符含义不同文件的每一行称为记录省略action，则默认执行print符含义不同文件的每一行称为记录省略action，则默认执行print0 的操作 awk工作原理 第一步：执行BEGIN{action;… }语句块中的语句 第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ action;… }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕。 第三步：当读至输入流末尾时，执行END{action;…}语句块 BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中 END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块 pattern语句块中的通用命令是最重要的部分，也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块 awk的输出命令之一：printprint格式：print item1, item2, … item:字符串，用引号引用; print “hello”,”world” 变量：显示变量的值，也可以直接使用变量的名进行引用; print name 要点： 各item之间需要逗号分隔：而输出的分隔符为默认空白字符; 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式:数值会被隐士转换为字符串进行输出； 如省略item，相当于”print $0”,用于输出整行; 输出空白字符：print “ “ 示例： awk -F: ‘{print}’ /etc/passwd 等同于 awk -F: ‘{print $0}’ /etc/passwd 1234567&gt; [root@cetos7 ~]#cat /etc/passwd&gt; root:x:0:0:root:/root:/bin/bash&gt; bin:x:1:1:bin:/bin:/sbin/nologin&gt; [root@cetos7 ~]#awk -F: '&#123;print&#125;' /etc/passwd&gt; root:x:0:0:root:/root:/bin/bash&gt; bin:x:1:1:bin:/bin:/sbin/nologin&gt; awk -F: ‘{print “wang”}’ /etc/passwd 12345&gt; [root@cetos7 ~]#awk -F: '&#123;print "wang"&#125;' /etc/passwd &gt; # 以：为分隔符，打印wang&gt; wang&gt; wang&gt; awk -F: ‘{print $1}’ /etc/passwd 12345&gt; [root@cetos7 ~]#awk -F: '&#123;print $1&#125;' /etc/passwd &gt; # 以：为分隔符，打印第一列&gt; root&gt; bin&gt; awk -F: ‘{print 1”\t”1”\t”3}’ /etc/passwd 12345&gt; [root@cetos7 ~]#awk -F: '&#123;print $1" \t"$3&#125;' /etc/passwd&gt; # 以：为分隔符，打印第一列、第三列加上空格和制表符&gt; root 0&gt; bin 1&gt; grep “^UUID” /etc/fstab | awk ‘{print 2,2,4}’ 123456&gt; [root@cetos7 ~]#grep "^UUID" /etc/fstab | awk '&#123;print $2,$4&#125;'&gt; / defaults&gt; /boot defaults&gt; /data defaults&gt; swap defaults&gt; awk变量变量：内置和自定义变量 内置变量 FS：输入字段分隔符，默认为空白字符 awk -v FS=’:’ ‘{print 1,FS,1,FS,3}’ /etc/passwd等同于awk -F: ‘{print 1,”:”,1,”:”,3}’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk -v FS=':' '&#123;print $1,FS,$3&#125;' /etc/passwd&gt; root : 0&gt; bin : 1&gt; OFS：输出字段分隔符，默认为空白字符 awk -v FS=’:’ -v OFS=’:’ ‘{print 1,1,3,$7}’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk -v FS=':' -v OFS=':' '&#123;print $1,$3,$7&#125;' /etc/passwd&gt; root:0:/bin/bash&gt; bin:1:/sbin/nologin&gt; RS：输入记录分隔符，指定输入时的换行符 awk -v RS=’:’ ‘{print }’ /etc/passwd 12345678910111213141516&gt; [root@cetos7 ~]#awk -v RS=':' '&#123;print &#125;' /etc/passwd&gt; root&gt; x&gt; 0&gt; 0&gt; root&gt; /root&gt; /bin/bash&gt; bin&gt; x&gt; 1&gt; 1&gt; bin&gt; /bin&gt; /sbin/nologin&gt; ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=’:’ -v ORS=’\t’ ‘{print }’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk -v RS=':' -v ORS='\t' '&#123;print &#125;' /etc/passwd &gt; root x 0 0 root /root /bin/bash&gt; bin x 1 1 bin /bin /sbin/nologin&gt; NF：字段数量 awk -F: ‘{print NF}’ /etc/passwd 引用变量时，变量前不需加$ 1234&gt; [root@cetos7 ~]#awk -F: '&#123;print NF&#125;' /etc/passwd&gt; 7&gt; 7&gt; awk -F: ‘{print $(NF-1)}’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk -F: '&#123;print $(NF-1)&#125;' /etc/passwd&gt; /root&gt; /bin&gt; NR：记录号(如果是多个文件，它会一起计数的) awk ‘{print NR}’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk '&#123;print NR&#125;' /etc/passwd&gt; 1&gt; 2&gt; awk END’{print NR}’ /etc/passwd 123&gt; [root@cetos7 ~]#awk END'&#123;print NR&#125;' /etc/passwd &gt; 58&gt; FNR：各文件分别计数,记录号 awk ‘{print FNR}’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk '&#123;print FNR&#125;' /etc/passwd&gt; 1&gt; 2&gt; FILENAME：当前文件名 awk ‘{print FILENAME}’ /etc/fstab 1234&gt; [root@cetos7 ~]#awk '&#123;print FILENAME&#125;' /etc/fstab &gt; /etc/fstab&gt; /etc/fstab&gt; ARGC：命令行参数的个数 awk ‘{print ARGC}’ /etc/fstab /etc/inittab 1234567891011121314&gt; [root@cetos7 ~]#awk '&#123;print ARGC&#125;' /etc/passwd&gt; 2&gt; 2&gt; ``` &gt; 10. ARGV：数组，保存的是命令行所给定的各参数 &gt; &gt;awk '&#123;print ARGV[0]&#125;' /etc/passwd &gt; ```bash&gt; [root@cetos7 ~]#awk '&#123;print ARGV[0]&#125;' /etc/passwd &gt; awk&gt; awk&gt; [root@cetos7 ~]#awk '&#123;print ARGV[1]&#125;' /etc/passwd &gt; /etc/passwd&gt; /etc/passwd&gt; 自定义变量(区分字符大小写) -v var=value 在program中直接定义 示例： awk -v name=”test” ‘{print $1,name}’ /etc/fstab 1234567891011121314&gt; [root@cetos7 ~]#awk -v name="test" '&#123;print $1,name&#125;' /etc/fstab &gt; test&gt; # test&gt; # test&gt; # test&gt; # test&gt; # test&gt; # test&gt; # test&gt; UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 test&gt; UUID=7d1b5c8d-8054-4496-befe-267963e07605 test&gt; UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 test&gt; UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201 test&gt; awk ‘{sex=”male”;print $1,sex,age;age=”18”}’ /etc/fstab 1234567891011121314&gt; [root@cetos7 ~]#awk '&#123;sex="male";print $1,sex,age;age="18"&#125;' /etc/fstab &gt; male #第一次age变量没有值，为空。所以变量应该先赋值，后使用&gt; # male 18&gt; # male 18&gt; # male 18&gt; # male 18&gt; # male 18&gt; # male 18&gt; # male 18&gt; UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 male 18&gt; UUID=7d1b5c8d-8054-4496-befe-267963e07605 male 18&gt; UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 male 18&gt; UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201 male 18&gt; 1234567[root@cetos7 ~]#cat awkscript&#123;print script,$1,$2&#125; #print的内容可以写在一个脚本，可以用 -f 调用。[root@cetos7 ~]#awk -F: -f awkscript script="awk" /etc/passwdawk root xawk bin xawk daemon xawk adm x awk的输出命令之二:printf命令格式化输出：printf “FORMAT” , item1, item2, … 必须指定FORMAT 不会自动换行，需要显式给出换行控制符，\n FORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 %c：显示字符的ASCII码 %d, %i：显示十进制整数 %e, %E：显示科学计数法数值 %f：显示为浮点数 %g, %G：以科学计数法或浮点形式显示数值 %s：显示字符串 %u：无符号整数 %%：显示%自身 修饰符 #[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f 左对齐（默认右对齐） %-15s 显示数值的正负符号 %+dprintf示例 示例： awk -F: ‘{printf “%s”,$1}’ /etc/passwd 123456789101112131415161718&gt; [root@cetos7 ~]#awk -F: '&#123;printf "%s",$1&#125;' /etc/passwd &gt; rootbindaemonadmlpsyncshutdownhaltmailoperatorgamesftpnobodysystemd-networkdbuspolkitdlibstoragemgmtrpccolordsaslauthabrtsetroubleshootrtkitchronyrpcusernfsnobodyqemuunboundglustertssusbmuxdgeoclueradvdpulsegdmgnome-initial-setupsshdavahipostfixntptcpdumpxiealiceyanglizhaohuappapp2webuserapp3zhanggentoomagetomcatapachememcachedhttpd&gt; ``` &gt; &gt;awk -F: '&#123;printf "%-20s %10d\n",$1,$3&#125;' /etc/passwd &gt; &gt; &gt;awk -F: '&#123;printf "Username: %s,UID:%d\n",$1,$3&#125;' /etc/passwd &gt; ```bash&gt; [root@cetos7 ~]#awk -F: '&#123;printf "Username: %s,UID:%d\n",$1,$3&#125;' /etc/passwd &gt; Username: root,UID:0&gt; Username: bin,UID:1&gt; ``` &gt; &gt;awk -F: '&#123;printf "Username: %15s,UID:%d\n",$1,$3&#125;' /etc/passwd &gt; ```bash&gt; [root@cetos7 ~]#awk -F: '&#123;printf "Username: %15s,UID:%d\n",$1,$3&#125;' /etc/passwd&gt; Username: root,UID:0&gt; Username: bin,UID:1&gt; Username: daemon,UID:2&gt; awk -F: ‘{printf “Username: %-15s,UID:%d\n”,1,1,3}’ /etc/passwd 12345&gt; [root@cetos7 ~]#awk -F: '&#123;printf "Username: %-15s,UID:%d\n",$1,$3&#125;' /etc/passwd&gt; Username: root ,UID:0&gt; Username: bin ,UID:1&gt; Username: daemon ,UID:2&gt; 操作符 算术操作符： x+y, x-y, x*y, x/y, x^y, x%y -x：转换为负数 +x：将字符串转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符： =, +=, -=, *=, /=, %=, ^=，++, – 下面两语句有何不同 12awk ‘BEGIN&#123;i=0;print ++i,i&#125;’ #先自加再打印awk ‘BEGIN&#123;i=0;print i++,i&#125;’ #先打印再自加 比较操作符： ==, !=, &gt;, &gt;=, &lt;, &lt;= 模式匹配符： ~：左边是否和右边匹配，包含 !~：是否不匹配 示例： awk -F: ‘0 ~ /root/{print0 ~ /root/{print1}’ /etc/passwd 1234&gt; [root@cetos7 ~]#awk -F: '$0 ~ /root/&#123;print $1&#125;' /etc/passwd &gt; root&gt; operator&gt; awk ‘$0~”^root”‘ /etc/passwd 123&gt; [root@cetos7 ~]#awk '$0~"^root"' /etc/passwd &gt; root:x:0:0:root:/root:/bin/bash&gt; awk -F: ‘$3==0’ /etc/passwd 123&gt; [root@cetos7 ~]#awk -F: '$3==0' /etc/passwd &gt; root:x:0:0:root:/root:/bin/bash&gt; 逻辑操作符：与&amp;&amp;，或||，非! 示例： awk -F: ‘3&gt;1000{print3&gt;1000{print1,$3}’ /etc/passwd 123456&gt; [root@cetos7 ~]#awk -F: '$3&gt;1000&#123;print $1,$3&#125;' /etc/passwd&gt; nfsnobody 65534&gt; alice 1003&gt; yang 1004&gt; ·········&gt; awk -F: ‘3&lt;1000{print3&lt;1000{print1,$3}’ /etc/passwd 123456&gt; [root@cetos7 ~]#awk -F: '$3&lt;1000&#123;print $1,$3&#125;' /etc/passwd &gt; root 0&gt; bin 1&gt; daemon 2&gt; ·········&gt; 条件表达式（三目表达式） selector?if-true-expression:if-false-expression 示例： 1[root@cetos7 ~]#awk -F: '&#123;$3&gt;=1000 ? usertype="Common User":usertype="SysUser";printf "%15s:%-s\n",$1,usertype&#125;' /etc/passwd awk PATTERNPATTERN:根据pattern条件，过滤匹配的行，再做处理 如果未指定：空模式，匹配每一行 /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来 awk ‘/^UUID/{print $1}’ /etc/fstab 123456&gt; [root@cetos7 ~]#awk '/^UUID/&#123;print $1&#125;' /etc/fstab &gt; UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920&gt; UUID=7d1b5c8d-8054-4496-befe-267963e07605&gt; UUID=7556e4a8-128e-457f-99f7-3f1ccf517952&gt; UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201&gt; awk ‘!/^UUID/{print $1}’ /etc/fstab 12345678910&gt; [root@cetos7 ~]#awk '!/^UUID/&#123;print $1&#125;' /etc/fstab &gt; &gt; #&gt; #&gt; #&gt; #&gt; #&gt; #&gt; #&gt; relational expression: 关系表达式，结果为“真”才会被处理 真：结果为非0值，非空字符串 假：结果为空字符串或0值 示例： awk -F: ‘i=1;j=1{print i,j}’ /etc/passwd 123456&gt; [root@cetos7 ~]#awk -F: 'i=1;j=1&#123;print i,j&#125;' /etc/passwd&gt; root:x:0:0:root:/root:/bin/bash&gt; 1 1&gt; bin:x:1:1:bin:/bin:/sbin/nologin&gt; 1 1&gt; awk ‘!0’ /etc/passwd ; awk ‘!1’ /etc/passwd 1234567&gt; [root@cetos7 ~]#awk '!0' /etc/passwd&gt; root:x:0:0:root:/root:/bin/bash&gt; bin:x:1:1:bin:/bin:/sbin/nologin&gt; [root@cetos7 ~]#awk '!1' /etc/passwd&gt; root:x:0:0:root:/root:/bin/bash&gt; bin:x:1:1:bin:/bin:/sbin/nologin&gt; awk -F: ‘NF==”/bin/bash” {printNF==”/bin/bash” {print1,$NF}’ /etc/passwd 1234567891011121314&gt; [root@cetos7 ~]#awk -F: '$NF=="/bin/bash" &#123;print $1,$NF&#125;' /etc/passwd &gt; root /bin/bash&gt; xie /bin/bash&gt; alice /bin/bash&gt; yang /bin/bash&gt; li /bin/bash&gt; zhao /bin/bash&gt; hu /bin/bash&gt; app /bin/bash&gt; app3 /bin/bash&gt; zhang /bin/bash&gt; mage /bin/bash&gt; tomcat /bin/bash&gt; awk -F: ‘NF /bashNF /bash/{print 1,1,NF}’ /etc/passwd 1234567891011121314&gt; [root@cetos7 ~]#awk -F: '$NF ~ /bash$/&#123;print $1,$NF&#125;' /etc/passwd&gt; root /bin/bash&gt; xie /bin/bash&gt; alice /bin/bash&gt; yang /bin/bash&gt; li /bin/bash&gt; zhao /bin/bash&gt; hu /bin/bash&gt; app /bin/bash&gt; app3 /bin/bash&gt; zhang /bin/bash&gt; mage /bin/bash&gt; tomcat /bin/bash&gt; line ranges：行范围 startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式 awk -F: ‘/^root/,/^adm/{print $1}’ /etc/passwd 123456&gt; [root@cetos7 ~]#awk -F: '/^root/,/^adm/&#123;print $1&#125;' /etc/passwd&gt; root&gt; bin&gt; daemon&gt; adm&gt; awk -F: ‘(NR&gt;5&amp;&amp;NR&lt;10){print NR,$1}’ /etc/passwd 123456&gt; [root@cetos7 ~]#awk -F: '(NR&gt;5&amp;&amp;NR&lt;10)&#123;print NR,$1&#125;' /etc/passwd &gt; 6 sync&gt; 7 shutdown&gt; 8 halt&gt; 9 mail&gt; BEGIN/END模式 BEGIN{}：仅在开始处理文件中的文本之前执行一次 END{}：仅在文本处理完成之后执行一次 示例 : awk -F: ‘BEGIN{print “USER USERID”} {print 1”:”1”:”3} END{print “END FILE”}’ /etc/passwd 123456789&gt; [root@cetos7 ~]#awk -F: 'BEGIN&#123;print "USER USERID"&#125; &#123;print $1":"$3&#125; END&#123;print "END FILE"&#125;' /etc/passwd&gt; USER USERID&gt; root:0&gt; bin:1&gt; ······&gt; memcached:986&gt; httpd:80&gt; END FILE&gt; awk -F: ‘{print “USER USERID”;print 1”:”1”:”3} END{print “END FILE”}’ /etc/passwd 123456789101112&gt; [root@cetos7 ~]#awk -F: '&#123;print "USER USERID";print $1":"$3&#125; END&#123;print "END FILE"&#125;' /etc/passwd &gt; USER USERID&gt; root:0&gt; USER USERID&gt; bin:1&gt; ······&gt; USER USERID&gt; memcached:986&gt; USER USERID&gt; httpd:80&gt; END FILE&gt; awk -F: ‘BEGIN{print “USER UID \n————— “}{print 1,1,3}’ /etc/passwd 123456789&gt; [root@cetos7 ~]#awk -F: 'BEGIN&#123;print "USER UID \n--------------- "&#125;&#123;print $1,$3&#125;' /etc/passwd&gt; USER UID &gt; --------------- &gt; root 0&gt; bin 1&gt; ······&gt; memcached:986&gt; httpd:80&gt; awk -F: ‘BEGIN{print “USER UID \n—————– “}{print 1,1,3}END{print”=================”}’ /etc/passwd 12345678910&gt; [root@cetos7 ~]#awk -F: 'BEGIN&#123;print "USER UID \n----------------- "&#125;&#123;print $1,$3&#125;END&#123;print"================="&#125;' /etc/passwd &gt; USER UID &gt; ----------------- &gt; root 0&gt; bin 1&gt; ······&gt; memcached 986&gt; httpd 80&gt; =================&gt; seq 5 | awk ‘i=0’ 123&gt; [root@cetos7 ~]#seq 5 | awk 'i=0'&gt; [root@cetos7 ~]#&gt; seq 5 | awk ‘i=1’ 1234567891011121314&gt; [root@cetos7 ~]#seq 5 | awk 'i=1' &gt; 1&gt; 2&gt; 3&gt; 4&gt; 5&gt; ``` &gt; &gt;seq 5 | awk 'i=!i' &gt; ```bash&gt; [root@cetos7 ~]#seq 5 | awk 'i=!i' &gt; 1&gt; 3&gt; 5&gt; seq 5 | awk ‘{i=!i;print i}’ 1234567&gt; [root@cetos7 ~]#seq 5 | awk '&#123;i=!i;print i&#125;'&gt; 1&gt; 0&gt; 1&gt; 0&gt; 1&gt; seq 5 | awk ‘!(i=!i)’ 1234&gt; [root@cetos7 ~]#seq 5 | awk '!(i=!i)&gt; 2&gt; 4&gt; seq 5 | awk -v i=1 ‘i=!i’ 1234&gt; [root@cetos7 ~]#seq 5 | awk -v i=1 'i=!i'&gt; 2&gt; 4&gt; awk action常用的action分类 Expressions：算术，比较表达式等 Control statements：if, while等 Compound statements：组合语句 input statements output statements：print等 awk控制语句 if-else 语法：if(condition){statement;…}[else statement] if(condition1){statement1}else if(condition2){statement2}else{statement3} 使用场景：对awk取得的整行或某个字段做条件判断 示例： df -h|awk -F% ‘/^\/dev/{print 1}’|awk ‘1}’|awk ‘NF&gt;=10{print 1,1,5}’ 1234&gt; [root@cetos7 ~]#df -h|awk -F% '/^\/dev/&#123;print $1&#125;'|awk '$NF&gt;=10&#123;print $1,$5&#125;' &gt; /dev/sda2 21&gt; /dev/sda1 17&gt; awk ‘BEGIN{ test=100;if(test&gt;90){print “very good”}else if(test&gt;60){ print “good”}else{print “no pass”}}’ 123&gt; [root@cetos7 ~]#awk 'BEGIN&#123; test=100;if(test&gt;90)&#123;print "very good"&#125;else if(test&gt;60)&#123; print "good"&#125;else&#123;print "no pass"&#125;&#125;' &gt; very good&gt; while循环 语法：while(condition){statement;…} 条件“真”，进入循环；条件“假”，退出循环 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 示例： awk ‘/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length(i)&gt;=10){printi)&gt;=10){print1,length($i)};i++}}’ /etc/grub2.cfg 123456789&gt; [root@cetos7 ~]#awk '/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF)&#123;if(length($i)&gt;=10)&#123;print $1,length($i)&#125;;i++&#125;&#125;' /etc/grub2.cfg &gt; linux16 30&gt; linux16 46&gt; linux16 16&gt; linux16 16&gt; linux16 50&gt; linux16 46&gt; linux16 16&gt; do-while循环 语法：do {statement;…}while(condition) 意义：无论真假，至少执行一次循环体 示例： awk ‘BEGIN{total=0;i=0;do{ total+=i;i++ } while( i&lt;=100 );print total}’ 123&gt; [root@cetos7 ~]#awk 'BEGIN&#123;total=0;i=0;do&#123; total+=i;i++ &#125; while( i&lt;=100 );print total&#125;'&gt; 5050&gt; for循环 语法：for(expr1;expr2;expr3) {statement;…} 常见用法： for(variable assignment;condition;iteration process) {for-body} 特殊用法：能够遍历数组中的元素 语法：for(var in array) {for-body} 示例： awk ‘/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++) {print i,length(i,length(i)}}’ /etc/grub2.cfg 123456789101112131415161718&gt; ^ syntax error&gt; [root@cetos7 ~]#awk '/^[[:space:]]*linux16/&#123;for(i=1;i&lt;=NF;i++) &#123;print $i,length($i)&#125;&#125;' /etc/grub2.cfg&gt; linux16 7&gt; /vmlinuz-3.10.0-862.el7.x86_64 30&gt; root=UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 46&gt; ro 2&gt; crashkernel=auto 16&gt; rhgb 4&gt; quiet 5&gt; LANG=en_US.UTF-8 16&gt; linux16 7&gt; /vmlinuz-0-rescue-adda87b767b846f69b46c9188469daa7 50&gt; root=UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 46&gt; ro 2&gt; crashkernel=auto 16&gt; rhgb 4&gt; quiet 5&gt; switch语句 语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; case VALUE2 or /REGEXP2/: statement2; …; default: statementn} break和continue continue:满足条件则结束本次循环，不满足条件，继续执行。 awk ‘BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}’ 123&gt; [root@cetos7 ~]#awk 'BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++)&#123;if(i%2==0)continue;sum+=i&#125;print sum&#125;' &gt; 2500&gt; break:满足条件则结束整个循环 awk ‘BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==50)break;sum+=i}print sum}’ 123&gt; [root@cetos7 ~]#awk 'BEGIN&#123;sum=0;for(i=1;i&lt;=100;i++)&#123;if(i==50)break;sum+=i&#125;print sum&#125;' &gt; 1225&gt; next:提前结束对本行处理而直接进入下一行处理（awk自身循环） awk ‘{if (NR%2==0)next;print NR,$0}’ /etc/fstab 12345678&gt; [root@cetos7 ~]#awk '&#123;if (NR%2==0)next;print NR,$0&#125;' /etc/fstab &gt; 1 &gt; 3 # /etc/fstab&gt; 5 #&gt; 7 # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info&gt; 9 UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0&gt; 11 UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 /data xfs defaults 0&gt; awk数组 关联数组：array[index-expression] index-expression: 可使用任意字符串；字符串要使用双引号括起来如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”若要判断数组中是否存在某元素，要使用“index in array” 格式进行遍历 示例： awk ‘BEGIN{weekdays[“mon”]=”Monday”;weekdays[“tue”]=”Tuesday”;print weekdays[“mon”]}’ 1234567891011121314&gt; [root@cetos7 ~]#awk 'BEGIN&#123;weekdays["mon"]="Monday";weekdays["tue"]="Tuesday";print weekdays["mon"]&#125;'&gt; Monday&gt; ``` &gt; 2. 若要遍历数组中的每个元素，要使用for循环 &gt; for(var in array) &#123;for-body&#125; &gt; 注意：var会遍历array的每个索引 &gt; 示例： &gt; awk'BEGIN&#123;weekdays["mon"]="Monday";weekdays["tue"]="Tuesday";for(i in weekdays) &#123;print weekdays[i]&#125;&#125;' &gt; &gt;netstat -tan | awk '/^tcp/&#123;state[$NF]++&#125;END&#123;for(i in state) &#123; print i,state[i]&#125;&#125;'&gt; ```bash&gt; [root@cetos7 ~]#netstat -tan | awk '/^tcp/&#123;state[$NF]++&#125;END&#123;for(i in state) &#123; print i,state[i]&#125;&#125;'&gt; LISTEN 10&gt; ESTABLISHED 1&gt; awk ‘{ip[$1]++}END{for(i in ip) {print i,ip[i]}}’ /var/log/httpd/access_log 123456&gt; [root@cetos7 ~]#awk '&#123;ip[$1]++&#125;END&#123;for(i in ip) &#123;print i,ip[i]&#125;&#125;' /var/log/httpd/access_log &gt; 192.168.189.129 8&gt; 192.168.183.140 8&gt; 192.168.183.1 38&gt; 192.168.189.1 34&gt; awk函数 数值处理： rand()：返回0和1之间一个随机数 awk ‘BEGIN{srand(); for (i=1;i&lt;=5;i++)print int(rand()*100)}’ 1234567&gt; [root@cetos7 ~]#awk 'BEGIN&#123;srand(); for (i=1;i&lt;=5;i++)print int(rand()*100)&#125;' &gt; 87&gt; 77&gt; 39&gt; 61&gt; 76&gt; 字符串处理： length([s])：返回指定字符串的长度 sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s echo “2008:08:08 08:08:08” | awk ‘sub(/:/, “-“, $1)’ 123&gt; [root@cetos7 ~]#echo "2008:08:08 08:08:08" | awk 'sub(/:/,"-",$1)'&gt; 2008-08:08 08:08:08&gt; gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容 echo “2008:08:08 08:08:08” | awk ‘gsub(/:/,”-“,$0)’ 123&gt; [root@cetos7 ~]#echo "2008:08:08 08:08:08" | awk 'gsub(/:/,"-",$0)'&gt; 2008-08-08 08-08-08&gt; • split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所表示的数组中，第一个索引值为1,第二个索引值为2,… netstat -tn | awk ‘/^tcp&gt;/{split($5,ip,”:”);count[ip[1]]++}END{for (i in count) {print i,count[i]}}’ 123&gt; [root@cetos7 ~]#netstat -tn | awk '/^tcp\&gt;/&#123;split($5,ip,":");count[ip[1]]++&#125;END&#123;for (i in count) &#123;print i,count[i]&#125;&#125;'&gt; 192.168.183.1 1&gt; 自定义函数格式： 1234function name ( parameter, parameter, ... ) &#123;statementsreturn expression&#125; 示例： 1234567cat fun.awkfunction max(x,y) &#123;x&gt;y?var=x:var=yreturn var&#125;BEGIN&#123;a=3;b=2;print max(a,b)&#125;awk -f fun.awk awk中调用shell命令system命令空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用空格分隔，或者说除了awk的变量外其他一律用””引用起来awk ‘BEGIN{system(“hostname”) }’awk ‘BEGIN{score=100; system(“echo your score is “ score)}’ awk脚本将awk程序写成脚本，直接调用或执行示例： 123456789cat f1.awk&#123;if($3&gt;=1000)print $1,$3&#125;awk -F: -f f1.awk /etc/passwdcat f2.awk#!/bin/awk –f#this is a awk script&#123;if($3&gt;=1000)print $1,$3&#125;chmod +x f2.awkf2.awk –F: /etc/passwd 向awk脚本传递参数格式：awkfile var=value var2=value2… Inputfile注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变量都需要一个-v参数示例： 12345cat test.awk#!/bin/awk –f&#123;if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3&#125;chmod +x test.awktest.awk -F: min=100 max=200 /etc/passwd 练习 文件ip_list.txt如下格式，请提取” .magedu.com” 前面的主机名部分并写入到回到该文件中 1 blog.magedu.com 2 www.magedu.com … 999 study.magedu.com 1awk -F '[ .]' '&#123;print "."$3"."$4&#125;' ip_list.txt &gt;&gt; ip_list.txt 统计/etc/fstab文件中每个文件系统类型出现的次数 1awk '/^UUID/&#123;filetype[$3]++&#125;END&#123;for (i in filetype)&#123;print i,filetype[i]&#125;&#125;' /etc/fstab 统计/etc/fstab文件中每个单词出现的次数 1awk '&#123;i=1;while(i&lt;=NF)&#123;word[$i]++;i++&#125;&#125;END&#123;for(num in word)&#123;print num,word[num]&#125;&#125;' /etc/fstab 提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字 12echo "Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw"|awk 'gsub(/[^0-9]/,"",$0)'#把不是数字的全部用空代替掉 有一文件记录了1-100000之间随机的整数共5000个，存储的格式100,50,35,89…请取出其中最大和最小的整数 1awk -F',' '&#123;i=2;max=$1;min=$1;while(i&lt;=NF)&#123;if &#123;$i &gt; max&#125;&#123;max=$i&#125;else if&#123;$i&lt;min&#125;&#123;min=$i&#125;;i++&#125;END&#123;print "max="max,"min="min&#125;' random.txt 解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT 1awk '&#123;access[$1]++&#125;END&#123;for(i in access)&#123;if(access[i]&gt;=100)&#123;print i,access[i]&#125;&#125;&#125;' /var/log/httpd/access_log 将以下文件内容中FQDN取出并根据其进行计数从高到低排序 http://mail.magedu.com/index.html http://www.magedu.com/test.html http://study.magedu.com/index.html http://blog.magedu.com/index.html http://www.magedu.com/images/logo.jpg http://blog.magedu.com/20080102.html 1awk -F '/' '&#123;fqdn[$3]++&#125;END&#123;for (i in fqdn)&#123;print i fqdn[i]&#125;' filename | sort -k2 -nr 将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出同一inode中beginnumber的最小值和endnumber的最大值 inode|beginnumber|endnumber|counts| 106|3363120000|3363129999|10000| 106|3368560000|3368579999|20000| 310|3337000000|3337000100|101| 310|3342950000|3342959999|10000| 310|3362120960|3362120961|2| 311|3313460102|3313469999|9898| 311|3313470000|3313499999|30000| 311|3362120962|3362120963|2| 输出的结果格式为： 310|3337000000|3362120961|10103| 311|3313460102|3362120963|39900| 1awk -F'|' 'NR==1&#123;print;next&#125;&#123;a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4&#125;END&#123;l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS&#125;' f1.txt]]></content>
      <categories>
        <category>文本工具</category>
      </categories>
      <tags>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之sed]]></title>
    <url>%2F2018%2F06%2F16%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed%2F</url>
    <content type="text"><![CDATA[概述&ensp;&ensp;&ensp;&ensp;sed是一种流编辑器、行编辑器。它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。如果没有使诸如‘D’ 的特殊命令，那会在两个循环之间清空模式空间，但不会清空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。&ensp;&ensp;&ensp;&ensp;sed和我们之前的文本处理工具vim、grep是有区别的，vim是一种交互式的文本编辑工具，而sed是一种非交互式的文本编辑器（通过给定的条件自动的逐行去处理文件）；grep虽然也是一种流失的文本处理工具，但grep是用来检索条件关键字的，而sed却是搜索匹配处理文本公积&ensp;&ensp;&ensp;&ensp;sed的功能：主要用来自动编辑一个或多个文件,简化对文件的反复操作,编写转换程序等 sed语法sed [option]... &#39;script&#39; inputfile... -n 不输出模式空间内容到屏幕，即不自动打印-e 多点编辑123[root@localhost ~]#seq 10 | sed -n -e '2p' -e '6p' 26 -f /PATH/SCRIPT_FILE 从指定文件中读取编辑脚本-r 支持使用扩展正则表达式-i.bak 备份文件并原处编辑 地址定界 不给地址：对全文进行处理 1[root@localhost ~]#seq 10 | sed 'p' 单地址:#: 指定的行$： 最后一行/pattern/：被此处模式所能够匹配到的每一行 123[root@localhost ~]#seq 10 | sed -n &apos;1p&apos;[root@localhost ~]#seq 10 | sed -n &apos;$p&apos;[root@localhost ~]#sed -n &apos;/^root/p&apos; /etc/passwd 地址范围：#,##,+#/pat1/,/pat2/#,/pat1/ 1234[root@localhost ~]#seq 10 | sed -n '1,5p'[root@localhost ~]#seq 10 | sed -n '1,+4p'[root@localhost ~]#sed -n '/^b/,/^f/p' /etc/passwd[root@localhost ~]#sed -n '2,/^f/p' /etc/passwd ~：步进1~2 奇数行2~2 偶数行 12[root@localhost ~]#seq 10 | sed -n '1~2p'[root@localhost ~]#seq 10 | sed -n '2~2p' 编辑命令d 删除模式空间匹配的行，并立即启用下一轮循环12345[root@localhost ~]#seq 5 | sed '2d'1345 p 打印当前模式空间内容，追加到默认输出之后a []text 在指定行后面追加文本，支持使用\n实现多行追加12345678[root@localhost ~]#seq 5 | sed '$axxx\nyyy' 12345xxxyyy i []text 在行前面插入文本12345678[root@localhost ~]#seq 5 | sed '$ixxx\nyyy' 1234xxxyyy5 c []text 替换行为单行或多行文本 1234567[root@localhost ~]#seq 5 | sed '$cxxx\nyyy' 1234xxxyyy w /path/file 保存模式匹配的行至指定文件r /path/file 读取指定文件的文本至模式空间中匹配到的行后= 为模式空间中的行打印行号1[root@localhost ~]#sed -n &apos;/root/=&apos; /etc/passwd ! 模式空间中匹配行取反处理sed工具12[root@localhost ~]#seq 5 | sed ' 2 ! d' 2 s/// 查找替换,支持使用其它分隔符， s@@@， s###替换标记：g 行内全局替换p 显示替换成功的行 练习 删除centos7系统/etc/grub2.cfg文件中所有以空白开头的行行首的空白字符 1cat /etc/grub2.cfg | sed -nr 's@^([[:space:]]*)([[:alpha:]].*$)@\2@gp' 删除/etc/fstab文件中所有以#开头，后面至少跟一个空白字符的行的行首的#和空白字符 1cat /etc/fstab | sed -nr 's@^#[[:space:]]@@gp' 在centos6系统/root/install.log每一行行首增加#号 1cat /root/install.log | sed -nr 's@^In.*@#&amp;@g' 在/etc/fstab文件中不以#开头的行的行首增加#号 1cat /etc/fstab | sed -nr 's@^([^#]|$)@#&amp;@gp' 处理/etc/fstab路径,使用sed命令取出其目录名和基名 12dirname: echo /etc/fstab | sed -nr 's@(.*/)([^/]+/?$)@\1@gp'basename: echo /etc/fstab | sed -nr 's@(.*/)([^/]+/?$)@\2@gp' 利用sed取出ifconfig命令中本机的IPv4地址 1ifconfig | sed -nr '2!d;s@.*inet (addr:)?@@;s@ .*@@gp' 统计centos安装光盘中Package目录下的所有rpm文件的以.分隔倒数第二个字段的重复次数 1ls /run/media/root/CentOS\ 7\ x86_64/Packages/ | sed -nr 's@(.*\.)(.*)\.rpm$@\2@gp' |sort | uniq -c 统计/etc/init.d/functions文件中每个单词的出现次数，并排序（用grep和sed两种方法分别实现）12grep: cat /etc/init.d/functions | grep -Eow "[[:alpha:]]*_?" | sort | uniq -csed: 高级编辑命令&ensp;&ensp;&ensp;&ensp;sed除了模式空间外，还有一个“hold space”的内存空间，称为保持空间。&ensp;&ensp;&ensp;&ensp;sed工作机制是每次自动读取一行到模式空间中，在模式空间中完成处理，将处理结果输出至标准输出设备；在模式空间中处理一行内容后会继续处理下一行。那么对于处理过的行还有其他处理时，我们就把处理过的行送至保持空间中，然后在后续处理中在传回至模式空间中。常见命令： P： 打印模式空间开端至\n内容，并追加到默认输出之前h: 把模式空间中的内容覆盖至保持空间中H：把模式空间中的内容追加至保持空间中g: 从保持空间取出数据覆盖至模式空间G：从保持空间取出内容追加至模式空间x: 把模式空间中的内容与保持空间中的内容进行互换n: 读取匹配到的行的下一行覆盖至模式空间N：读取匹配到的行的下一行追加至模式空间d: 删除模式空间中的行D：如果模式空间包含换行符，则删除直到第一个换行符的模式空间中的文本，并不会读取新的输入行，而使用合成的模式空间重新启动循环。如果模式空间不包含换行符，则会像发出d命令那样启动正常的新循环 示例 seq 10 | sed -n ‘n;p’ (1)首先-n禁止默认的打印功能，因为没有地址定界，所以默认为全文，首先读第一行至模式空间，n表示匹配到的下一行覆盖至模式空间，即用第二行覆盖模式空间内的第一行; (2)然后读取第三行，继续-n操作，所以打印出来的都为偶数行。123456[root@localhost ~]#seq 10 | sed -n 'n;p' 246810 seq 10 | sed ‘1!G;h;$!d’ (1)依然是默认为全文，首先读取第一行，1！G，不做操作，h，覆盖至保持空间，因为保持空间本开始没有内容，所以此时保持空间内容为第一行，$!d，不是最后一行，执行删除。此第一行操作完毕，此时模式空间没有内容，保持空间为第一行； (2)再读取第二行，1！G，因为不是第一行，执行G操作，即从保持空间取出内容追加至模式空间，此时模式空间的内容为第二行+第一行，且第一行在下面，h，把模式空间中的内容覆盖至保持空间中，此时保持空间为原来的模式空间内容，$!d，不是最后一行，执行删除。此时模式空间为空，保持空间为第二行+第一行。 (3)直到读到最后一行，1！G，此时模式空间内为第十行到第一行，h，再把模式空间内容覆盖至保持空间，最后$!d,因为是最后一行，所以不予操作，最后将模式空间的内容打印出来，即逆序显示。1234567891011[root@localhost ~]#seq 10 | sed '1!G;h;$!d' 10987654321 seq 10 | sed ‘$!d’默认为全文内容，$!d表示不是最后一行执行d删除操作，所以只打印出最后一行 12[root@localhost ~]#seq 10 | sed '$!d'10 将文本文件的n和n+1行合并为一行， n为奇数行 1seq 10 | sed 'N;s@\n@ @']]></content>
      <categories>
        <category>文本工具</category>
      </categories>
      <tags>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux磁盘存储和文件系统]]></title>
    <url>%2F2018%2F05%2F19%2F%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[磁盘结构设备类型（1）块设备：block ，存取单位“块”，磁盘 （2）字符设备：char ，存取单位“字符”，键盘 设备号码（1）主设备号：major number, 标识设备类型 （2）次设备号：minor number, 标识同一类型下的不同设备 机械硬盘和固态硬盘&ensp;&ensp;&ensp;&ensp;机械硬盘（HDD）：即是传统普通硬盘，主要由：盘片，磁头，盘片转轴及控制电机，磁头控制器，数据转换器，接口，缓存等几个部分组成。机械硬盘中所有的盘片都装在一个旋转轴上，每张盘片之间是平行的，在每个盘片的存储面上有一个磁头，磁头与盘片之间的距离比头发丝的直径还小，所有的磁头联在一个磁头控制器上，由磁头控制器负责各个磁头的运动。磁头可沿盘片的半径方向运动，加上盘片每分钟几千转的高速旋转，磁头就可以定位在盘片的指定位置上进行数据的读写操作。数据通过磁头由电磁流来改变极性方式被电磁流写到磁盘上，也可以通过相反方式读取。硬盘为精密设备，进入硬盘的空气必须过滤。 &ensp;&ensp;&ensp;&ensp;固态硬盘（SSD）：用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元（FLASH 芯片、DRAM 芯片）组成。固态硬盘在接口的规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上也与普通硬盘一致。 比较： 相较于HDD ，SSD 在防震抗摔、传输速率、功耗、重量、噪音上有明显优势，SSD 传输速率性能是HDD 的2倍 相较于SSD ，HDD 在价格、容量、使用寿命上占有绝对优势 硬盘有价，数据无价，目前SSD 不能完全取代HHD 设备文件① 磁盘设备的设备文件命名： IDE: /dev/hd SCSI,SATA,SAS,USB: /dev/sd ② 不同磁盘标识：a-z,aa,ab… ​ /dev/sda, /dev/sdb, … /dev/sdaa,/dev/sdab… 同一设备上的不同分区：1,2, … ​ /dev/sda1, /dev/sda5 ③ 机械硬盘存储术语 head ：磁头 track ：磁道 cylinder: 柱面 secotr: 扇区，512bytes（最小单位） 两种寻址方法：CHS和LBA CHS： 采用24bit 位寻址 其中前10 位表示cylinder ，中间8 位表示head ，后面6 位表示sector。 。 最大寻址空间8GB LBA （logical block addressing）： LBA 是一个整数，通过转换成CHS 格式完成磁盘具体寻址 LBA 采用48 个bit 位寻址 最大寻址空间128PB 由于CHS 寻址方式的寻址空间在大概8GB 以内，所以在磁盘容量小于大概8GB 时，可以使用CHS 寻址方式或是LBA 寻址方式；在磁盘容量大于大概8GB 时，则只能使用LBA 寻址方式 使用分区空间1、 设备识别 2、 设备分区 3、 文件系统类型格式化 4、 在/etc/fstab 文件中创建条目 5、 mount 挂载新的文件系统 磁盘分区为什么分区1、 优化I/O 性能 2、 实现磁盘空间配额限制 3、 提高修复速度 4、 隔离系统和程序 5、 安装多个OS 6、 采用不同文件系统 分区两种分区方式：MBR ，GPT （1）MBR: Master Boot Record ，1982年， 使用32位表示扇区数 ， 分区不超过2T （2）如何分区：按柱面 （2）0 磁道0 扇区：512bytes 446bytes: boot loader 64bytes ：分区表 16bytes: 标识一个分区 2bytes: 55AA，结束标志 （2）4 个主分区；3 主分区+1 扩展(N 个逻辑分区) MBR分区结构&ensp;&ensp;&ensp;&ensp;硬盘主引导记录MBR 主要由 4 个部分组成 1、主引导程序（偏移地址0000H–0088H ），它负责从活动分区中装载，并运行系统引导程序。 2、出错信息数据区，偏移地址0089H–00E1H 为出错信息，00E2H–01BDH 全为0 字节。 3、分区表（DPT,Disk Partition Table ）含4 个分区项，偏移地址01BEH–01FDH, 每个分区表项长16 个字节，共64 字节为分区项1 、分区项2 、分区项3 、分区项4 4、 结束标志字，偏移地址01FE–01FF 的2 个字节值为结束标志 55AA GPT分区1、GPT:GUID （Globals Unique Identifiers） partitiontable 支持128个分区，使用64 位，支持8Z（512Byte/block ）64Z （4096Byte/block） 2、使用128 位UUID(Universally Unique Identifier) 表示磁盘区 和分区 GPT 分区表自动备份在头和尾两份，并有CRC 校验位 3、UEFI ( 统一扩展固件接口) 硬件支持GPT ，使操作系统启动 管理分区列出块设备123fdisk -l /dev/sda 看硬盘分区表lsblkcat /proc/partitions 查看内核是否已经识别新的分区 创建分区使用的命令（1） fdisk 创建MBR 分区 fdisk /dev/sdX进行分区（交互式），建立分区时 m 帮助 n 建立分区，建立分区时先选择 p主分区primary partition 或e 选择扩展分区extended，建议前3个建立逻辑分区，最后把所有空间给4扩展分区，有扩展分区可以创建多个逻辑分区。 d 删除分区 p 显示分区信息 t 转换分区类型 a 将指定分区设置/取消 活动分区 第一位为80活动 L 查看分区类型 o 重建分区表 v 验证分区表，显示剩余没有被分区划分的扇区数量 g 创建GPT格式的分区（centos7)不推荐使用，最好用gdisk q 退出不保存 w 退出并保存,同步 注：因为fdisk 是交互式创建分区，所以写入脚本时需要： echo -e &quot;n\np\n1\n\n+1G\nw\n&quot; |fdisk /dev/sdb 来实现非交互创建分区 （2） gdisk 创建GPT 分区（用法和fdisk相似） n创建分区时，直接从2-128进行分区，不分主分区，扩展分区 （3） parted 高级分区操作（创建、复制、调整大小等等）实时性，小心使用，不用再w已经保存，可以直接非交互式创建分区，aix, amiga, bsd, dvh, gpt, mac, msdos, pc98, sun, loop 都能创建。（不常用） parted /dev/sdX help 寻求帮助，有很清晰的帮助的信息。 mklabel help 有mklabel使用帮助信息 mklabel msdos 选择msdos 方式分区 mkpart 开始创建分区 rm 删除分区 p 查看分区信息 q 退出 （4）重置内存中分区信息（当系统正在使用的分区修改时，内存不会改变） 1234567centos 5和7可以使用新增分区时，同步 partx -a /dev/sdXcentos6新增分区时，同步 kpartx -a /dev/DEVICE -f: force删除分区时，同步 partx -d /dev/sdX 所有系统都能用，centos 6也可以 文件系统&ensp;&ensp;&ensp;&ensp;文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。操作系统中负责管理和存储文件信息的软件结构称为文件管理系统，简称文件系统 查看支持的文件系统：/lib/modules/uname –r/kernel/fs 文件系统类型（1） Linux 文件系统 ext2(Extended file system) :适用于那些分区容量不是太大，更新也不频繁的情况，例如 /boot 分区 ext3:是 ext2 的改进版本，其支持日志功能，能够帮助系统从非正常关机导致的异常中恢复。它通常被用作通用的文件系统 ext4:是 ext 文件系统的最新版。提供了很多新的特性，包括纳秒级时间戳、创建和使用巨型文件(16TB)、最大1EB的文件系统，以及速度的提升 xfs：SGI，支持最大8EB的文件系统 btrfs（Oracle）, reiserfs, jfs（AIX）, swap （2） 光盘：iso9660 （3） Windows ：FAT32, exFAT,NTFS （4） Unix: FFS （fast ）, UFS （unix ）, JFS2 （5） 网络文件系统：NFS, CIFS （6） 集群文件系统：GFS2, OCFS2 （oracle） 例：11.11 淘宝 （7） 分布式文件系统： fastdfs,ceph, moosefs, mogilefs,glusterfs, Lustre （8） RAW：未经处理或者未经格式化产生的文件系统 文件系统分类 根据其是否支持”journal” 功能： 日志型文件系统: ext3, ext4, xfs, … 非日志型文件系统: ext2, vfat 文件系统的组成部分： ​ 内核中的模块：ext4, xfs, vfat ​ 用户空间的管理工具：mkfs.ext4, mkfs.xfs,mkfs.vfat Linux的虚拟文件系统：VFS 查前支持的文件系统：cat /proc/filesystems 创建文件系统（1）mkfs 命令 mkfs. 能创建很多类文件系统 例：mkfs.xfs /dev/sda1 给/dev/sda1创建xfs类型的文件系统 （ext# xfs btrfs vfa） mkfs -t 是个c写的脚本，就是调用mkfs. 命令 例：mkfs -t ext4 /dev/sda1 给/dev/sda1创建ext4类型的文件系统 -f 强制重建，如果这个设备已经分过其他格式的文件系统了 （2）mke2fs ：创建文件系统，ext系列文件系统专用管理工具， 例：mke2fs -t ext4 -L test /dev/sdc1 给/dev/sdc1创建ext4卷标为test的文件系统 -t {ext2|ext3|ext4} 格式 -b {1024|4096} block快大小 -L ‘LABEL’ 卷标 -j: 于 相当于 -t ext3 mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -t ext3 -i #: 为数据空间中每多少个字节创建一个inode ；此大小不应该小于block 的大小 -N # ：指定分区中创建多少个inode -I 一个inode 记录占用的磁盘空间大小，128—4096 -m #: 默认5%, 为管理人员预留空间占总空间的百分比 -O FEATURE[,…] ：启用指定特性（只能开启以下特性） -O ^FEATURE 禁用指定特性 （3）tune2fs：修改文件系统信息，重新设定ext 系列文件系统可调整参数的值 例：tune2fs -o acl /dev/sdb2 开启/dev/sdb2的acl功能 -l ：查看指定文件系统超级块信息；super block -L ‘LABEL’ ：修改卷标（ext） mkfs -L ‘LABEL’ 或 mke2fs -L ‘LABEL’ 创建时设置卷标 e2label /dev/sd# 查看卷标 e2label /dev/sd# ‘LABEL’ 重命名卷标 -m # ：修预留给管理员的空间百分比 -j: 将ext2 升级为ext3 -O: 文件系统属性启用或禁用, –O ^has_journal -o: 调整文件系统的默认挂载选项，–o ^acl （centos7里默认开启acl 6 默认不开启） -U UUID: 修改UUID号 （4）查看信息 blkid：块设备属性信息查看（centos 7里默认显示sr0 6 里需blkid /dev/sr0显示光盘） -U UUID: 根据指定的UUID 来查找对应的设备 -L LABEL ：根据指定的LABEL findfs：查找分区(ext) findfs [options] LABEL= findfs [options] UUID= dumpe2fs /dev/sda# 查看文件系统信息：superblock信息及block group信息 -h ：查看超级块，不显示block group而只显示superblock 与tune2fs -l一致 小知识：超级块就是文件系统的内置，指定文件系统类型 block group 0里有super block ，后奇数组都有备份，能用于修复 （5）文件系统检测和修复 常发生于死机或者非正常关机之后，挂载为文件系统有几率标记为“no clean” ” 注意：一定不要在挂载状态下修复 fsck: File System Check​ fsck.FS_TYPE​ fsck -t FS_TYPE​ -p 自动修复错误​ -r 交互式修复错误​ FS_TYPE 一定要与分区上已经文件类型相同 e2fsck：ext系列文件专用的检测修复工具​ -y 自动回答为yes​ -f 强制修复 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[root@CentOS6 ~]#lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb 8:16 0 200G 0 disk ├─sdb1 8:17 0 10G 0 part ├─sdb2 8:18 0 2G 0 part └─sdb3 8:19 0 1K 0 part sda 8:0 0 200G 0 disk ├─sda1 8:1 0 1G 0 part /boot├─sda2 8:2 0 48.8G 0 part /├─sda3 8:3 0 29.3G 0 part /data├─sda4 8:4 0 1K 0 part └─sda5 8:5 0 2G 0 part [SWAP]sr0 11:0 1 3.7G 0 rom /media/CentOS_6.10_Final[root@CentOS6 ~]#dd if=/dev/zero of=/dev/sdb2 bs=1M count=2020+0 records in20+0 records out20971520 bytes (21 MB) copied, 0.110713 s, 189 MB/s[root@CentOS6 ~]#tune2fs -l /dev/sdb2tune2fs 1.41.12 (17-May-2010)tune2fs: Bad magic number in super-block while trying to open /dev/sdb2Couldn't find valid filesystem superblock.[root@CentOS6 ~]#fsck /dev/sdb2 -yfsck from util-linux-ng 2.17.2e2fsck 1.41.12 (17-May-2010)fsck.ext2: Superblock invalid, trying backup blocks.../dev/sdb2 was not cleanly unmounted, check forced.Resize inode not valid. Recreate? yesPass 1: Checking inodes, blocks, and sizesRoot inode is not a directory. Clear? yesPass 2: Checking directory structurePass 3: Checking directory connectivityRoot inode not allocated. Allocate? yes/lost+found not found. Create? yesPass 4: Checking reference countsPass 5: Checking group summary informationBlock bitmap differences: +(0--616)Fix? yesFree blocks count wrong for group #0 (32144, counted=32149).Fix? yesFree blocks count wrong (517078, counted=517083).Fix? yesInode bitmap differences: +1 +(3--10)Fix? yesFree inodes count wrong for group #0 (7732, counted=7733).Fix? yesDirectories count wrong for group #0 (3, counted=2).Fix? yesFree inodes count wrong (131636, counted=131637).Fix? yes/dev/sdb2: ***** FILE SYSTEM WAS MODIFIED *****/dev/sdb2: 11/131648 files (0.0% non-contiguous), 9045/526128 blocks 挂载，卸载任何块设备都不能直接访问，需挂载在目录上访问 挂载: 将额外文件系统与根文件系统某现存的目录建立起关联关系，进而使得此目录做为其它文件访问入口的行为（挂载的设备必须有文件系统） 卸载:为解除此关联关系的过程 mount [-选项] DEVICE（设备） MOUNT_POINT（挂载点） （1）device ：指明要挂载的设备 设备文件：例如/dev/sda5 卷标：-L ‘LABEL’, 如 例如 -L mage UUID, -U ‘UUID’ （2）挂载点下原有文件在挂载完成后会被临时隐藏 事先存在；建议使用空目录，进程正在使用中的设备无法被卸载 （3）/etc/mtab： 文件显示当前已挂载的所有设备（在CentOS 7中，是/proc/mounts的软连接，查看结果一样，centos 6中，ASCII text，查询结果和/proc/mounts不一样） mount：挂载常用命令选项查看挂载情况：findmnt 查看所有设备挂载情况（树状结构显示） findmnt 设备 查看单个设备的挂载情况 mount ：查看所有设备挂载情况 cat /proc/mounts：查看内核追踪到的已挂载的所有设备 mount -选项 设备 挂载点 -t：vsftype ：指定要挂载的设备上的文件系统类型（不常用，不加-t默认自带自己的文件系统类型），有时，系统报错提示，没指定文件系统类型，-t指定后，仍然有错。（注释1） -r：readonly ，只读挂载，不能进行其他操作，和权限无关，介质只能读，多用于冷备份。在mount 查询时时显示 ro 1例：mount -r /dev/sdb1 /app/sdb1 将/dev/sdb1只读挂载到/app/sdb上 -w：read and write, 读写挂载（defaults默认） -n：隐藏挂载信息不显示 ，但在/proc/mounts可以查到，卸载只能 umount /app/sdb2（挂载点） -a：自动挂载/etc/fstab文件没有挂载的设备( 定义在了/etc/fstab文件中，且挂载选项中有auto 功能，默认中包括) ，不看已挂载过的设备，如果在/etc/fstab里挂载过的设备修改了设置，不刷新； 如果想刷新修改过已挂载的设备，mount -o remount /dev/sdX（挂载点） -L ‘LABEL’： 以卷标指定挂载设备 -U ‘UUID’：以UUID 指定要挂载的设备 -B –bind：绑定目录到另一个目录上， 1例： mount -B /var/ftp/pub /app/apache /app/apache就是显示 /var/ftp/pub目录的东西 -o options：( 挂载文件系统的选项) ，多个选项使用逗号分隔 async（defaults)，sync 异步，同步，内存更改时，同时写磁盘（可以用于重要数据） atime(defaults),noatime 是否在读访问时更新atime diratime(defaults),nodiratime 目录的访问时间戳 auto(defaults)/noauto 写在/etc/fstab当中的分区，是否在mount -a时被挂载 exec(defatuls)/noexec 在该分区所挂载的目录中的脚本是否可以执行。 dev(defaults)/nodev：是否支持在此文件系统上使用设备文件 suid(defaults)/nosuid：是否支持suid和sgid权限 ro：只读 rw：读写(defaults) nouser(defaults)/user：是否允许普通用户挂载此设备，默认管理员才能挂载 acl（centos 7）/^acl（centos 6以下）：启用/禁用此文件系统上的acl功能 ​ defaults：相当于rw, suid, dev, exec, auto, nouser, async -o remount,选项：重新挂载，修改功能选项（和/etc/fstab选项冲突，则覆盖，不冲突就增加） 1例：mount -o remount,ro /dev/sdb1 umount 卸载 卸载时，若有正在进行的进程，不能卸载 查看正在访问指定文件系统的进程： lsof 设备或挂载点都可以 fuser -v 挂载点 终止所有在正访问指定的文件系统的进程： fuser -km 设备或挂载点都可以 终止完所有进程就可以卸载： umount DEVICE /etc/fstab 文件挂载配置文件（1）/etc/fstab 每行定义一个要挂载的文件系统 mount -a 自动挂载/etc/fstab文件没有挂载的设备，不管已挂载过的设备 如果想刷新修改过已挂载的设备，mount -o remount /dev/sdX（或挂载点） （2）格式（6列）： 要挂载的设备或伪文件系统：设备名称，LABEL，UUID，伪文件系统名称 挂载点（扩展为swap） 文件系统类型（auto 寻找默认的）， 普通设备挂载：ext#/xfs 等文件系统类型 交换分区 swap：swap 网络挂载地址 linux之间：nfs，windos挂载：cifs 光盘 iso9660，文件 cifs 挂载选项：defaults 有需要的功能可以添加，不能为空 转储频率： 0：（不做备份 ）1：（每天转储） 2：（每隔一天转储） 开机时自检顺序：（非0），允许的数字是0, 1, 和2（如果开机系统自检不过，就无法正常开机） ​ 0：不自检 ​ 1：首先自检；一般只有rootfs才用 ​ 2：非rootfs使用 （3）如果设备不小心被破坏，开机自检不过，无法正常启用，该怎么办？ 原理很简单，只需要修复一下文件系统就好了，（如果不能修复，可以去/etc/fstab中把自检改为0）具体操作如下： ① 手动破坏设备 dd if=/dev/zero of=/dev/sdc1 bs=1 count=2048 ② 开机过程，遇到错误提示 ③ 进入shell 操作，进行修复 （4）实验：迁移/home 家目录，从 / 下移到另一个磁盘，如/dev/sda6 ① init 1 进入单用户模式，防止自己在迁移时，其他用户进行操作，导致迁移后缺失东西。 ② 分区 /dev/sda6 fdisk ③ 文件系统格式化 mkfs.ext4 /dev/sda6 ④ 挂载在临时目录上/mnt ，把/home 下东西cp -a 到/mnt 目录 ⑤ 把现有/home 东西移走，卸载 /mnt ，把/dev/sda6 挂到 /home 下，并写入/etc/fstab，开机自动挂载。 1UUID=328a3f17-3e4e-426d-9538-c44be3e6465b /home ext4 defaults 0 2 ⑥ reboot或init 5 完成/home 搬迁]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>磁盘</tag>
        <tag>文件系统</tag>
        <tag>分区</tag>
        <tag>mount</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件包管理]]></title>
    <url>%2F2018%2F04%2F29%2F%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[静态和动态链接&ensp;&ensp;&ensp;&ensp;链接主要作用是吧各个模块之间互相引用的部分处理好，使得各个模块之间能够正确的链接，分为静态和动态 静态链接 ​ 把程序对应的依赖库复制一份到包 ​ 以.a为后缀 ​ 嵌入程序包 ​ 升级难 需重新编译 ​ 占用空间多 迁移容易 动态链接 只把依赖加做一个动态链接 以.so为后缀 连接指向 占用空间少 升级方便 若一个库被删，那么所有依赖此库的命令都受影响（使用相对较多） 软件包包命名和工具 源代码： name-VERSION.tar.gz|bz2|xz rpm包命名方式 name-VERSION-release.arch.rpm 例 bash-4.2.46-19.e17.x86_64.rpm 包：分类和拆包 1234Application-VERSION-ARCH.rpm 主包Application-devel-VERSION-ARCH.rpm 开发子包Application-utils-VERSION-ARHC.rpm 其它子包Application-libs-VERSION-ARHC.rpm 其它子包 包之间：可能存在依赖关系，甚至循环依赖 解决依赖包管理工具： yum： rpm包管理器的前端工具 apt-get： deb包管理器前端工具 zypper: suse上的rpm前端管理工具 dnf: Fedora 18+ rpm包管理器前端管理工具 库文件查看二进制程序所依赖的库文件 1ldd /PATH/TO/BINARY_FILE 管理及查看本机装载的库文件 1234567ldconfig 加载库文件/sbin/ldconfig -p 显示本机已经缓存的所有可用库文件名及文件路径映射关系/etc/ld.so.conf/etc/ld.so.conf.d/*.conf 配置文件/etc/ld.so.cache 缓存文件 包管理器&ensp;&ensp;&ensp;&ensp;功能：将编译好的应用程序的各组成文件打包一个或几个程序包文件，从而方便快捷地实现程序包的安装、卸载、查询、升级和校验等管理操作 包文件组成 (每个包独有) RPM包内的文件 RPM的元数据，如名称，版本，依赖性，描述等 安装或卸载时运行的脚本 数据库(公共)： /var/lib/rpm 程序包名称及版本 依赖关系 功能说明 包安装后生成的各文件路径及校验码信息 程序包的来源管理程序包的方式 使用包管理器： rpm 使用前端工具： yum, dnf 获取程序包的途径 系统发版的光盘或官方的服务器 CentOS镜像： https://www.centos.org/download/ http://mirrors.aliyun.com http://mirrors.aliyun.com http://mirrors.aliyun.com 项目官方站点 第三方组织 Fedora-EPELExtra Packages for Enterprise LinuxRpmforge:RHEL推荐，包很全搜索引擎：http://pkgs.org http://rpmfind.net http://rpm.pbone.net https://sourceforge.net/ 自己制作 注意：第三方包建议要检查其合法性包括来源合法性,程序包的完整性 RPM包管理器包安装1rpm &#123;-i|--install&#125; [install-options] PACKAGE_FILE… -i 安装选项​ -v 显示过程​ -h 以#显示程序包管理执行进度[install-options] –test 测试安装，但不真正执行安装，即dry run模式 操作走了一次但没装 1例：rpm -i --test vsftab-2* –nodeps 忽略依赖关系 1例：rpm -ivh httpd* --nodeps 能安装但是后期可能不能用 –replacepkgs | replacefiles 若删掉了包中的文件重新装包系统提示已经存在，此时可用此命令 1例：rpm -ivh --replacepkgs tree* replacefiles替代文件 即安装两个包，有同一个相同文件同时写入同一路径下 ​ 此时系统提示不能安装便可用此选项强制安装并覆盖 –nosignature: 不检查来源合法性 –nodigest：不检查包完整性 –noscripts：不执行程序包脚本 %pre: 安装前脚本； –nopre %post: 安装后脚本； –nopost %preun: 卸载前脚本； –nopreun %postun: 卸载后脚本； –nopostun rpm -ivh name1 name2… 一次安装多个包 rpm -V packagesname 查看包属性的变化 包升级（不建议使用）12rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE…rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE… upgrade：安装有旧版程序包，则“升级” 如果不存在旧版程序包，则“安装” freshen：安装有旧版程序包，则“升级” 如果不存在旧版程序包，则不执行升级操作 12rpm -Uvh PACKAGE_FILE …rpm -Fvh PACKAGE_FILE … ​ –oldpackage 降级 ​ –force 强制安装 升级注意项 不要对内核做升级操作； Linux支持多内核版本并存，因此，对直接安装新版本内核 如果原程序包的配置文件安装后曾被修改，升级时，新版本的提供的同一个配置文件并不会直接覆盖老版本的配置文件，而把新版本的文件重命名(FILENAME.rpmnew)后保留 包查询1rpm &#123;-q|--query&#125; [select-options][query-options] [select-options] -a 所有包 -f 查看指定的文件由哪个程序包安装生成 配合-P使用 后面跟磁盘上的某个文件（也可路径） -p rpmfile 针对尚未安装的程序包文件做查询操作 后面跟文件名（包的完整名）而不是包名 –whatprovides CAPABILITY 查询指定的CAPABILITY由哪个包所提供 –whatrequires CAPABILITY 查询指定的CAPABILITY（相当于关键字）被哪个包所依赖 rpm2cpio 包文件|cpio –itv 预览包内文件 相当于把rpm包转化成cpio格式 rpm2cpio 包文件|cpio –id “*.conf” 释放包内文件 [query-options] –changelog：查询rpm包的信息变化的过程 -c: 查询程序的配置文件 -d: 查询程序的文档 -i: information -l: 查看指定的程序包安装后生成的所有文件 –scripts：程序包自带的脚本 –provides: 列出指定程序包所提供的CAPABILITY（能力） -R: 查询指定的程序包所依赖的CAPABILITY 例： 12rpm -ql tree 查询tree包下的文件rpm -qR tree 查询tree所依赖的能力 包卸载1rpm &#123;-e|--erase&#125;[--allmatches][–-nodeps][–-noscripts][–-notriggers][–-test] PACKAGE_NAME … ​ -e 卸载 后面直接跟包名就可以不用写完整的名字 ​ –allmatches 若一个包有多个版本使用此选项可将全部卸载 包校验1rpm &#123;-V|--verify&#125; [select-options][verify-options]检查包的属性变化 后面跟包名 S file Size differs M Mode differs (includes permissions and file type) 5 digest (formerly MD5 sum) differs D Device major/minor number mismatch L readLink(2) path mismatch U User ownership differs G Group ownership differs T mTime differs P capabilities differ 导入所需要公钥123456789rpm -qa "gpg-pubkey*"rpm -K|checksig rpmfile 检查包的完整性和签名（若显示not ok）则此文件存在一定的风险建议不装若执行-K检查命令则必先执行以下命令rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6或 rpm --import /run/media/root/centos\7\x86_64/RPM-GPG-Centos-6rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7或 rpm --import /run/media/root/centos\7\x86_64/RPM-GPG-KEY-centos-7 rpm数据库 数据库重建 ​ /var/lib/rpm 1rpm &#123;--initdb|--rebuilddb&#125; ​ initdb: 初始化 如果事先不存在数据库，则新建之;否则，不执行任何操作 ​ rebuilddb：重建已安装的包头的数据库索引目录 YUM&ensp;&ensp;&ensp;&ensp;yum(Yellow dog Updater,Modified)主要的功能是方便添加、删除和更新rpm软件包。可以解决软件包依存问题，更便于管理大量的系统更新问题。它可以同时配置多个仓库或叫资源库(repository)，就是存放更新和依存的软件包的地方。 yum的由来&ensp;&ensp;&ensp;&ensp;为了解决程序间的依赖关系，RedHat曾推出了一款名为update的工具。这款工具虽然达到了目的，但用户体验并不是很好。后来一个基于RedHat的二次发行版yellowdog，由此也推出了一个工具：yellowdog update modifier，简写为yum. 由于比update好用，于是便流行开来。后来导致RedHat也弃update不用而使用yum yum的特性&ensp;&ensp;&ensp;&ensp;yum相对于rpm来说：rpm为基础包管理器，yum则是rpm的前端工具。yum无法独立存在系统,不允许有两个yum命令同时运行，如果有两个，第二次运行时会报错。这是为了防止yum之间的冲突 yum的配置文件/etc/yum.conf：为所有仓库提供公共配置 /etc/yum.repos.d/*.repo：为仓库的指向提供配置 yum repository: yum repo，存储了众多rpm包，以及包的相关的元数据文件（放置于特定目录repodata下）文件服务器： 1234http://https://ftp://file:// yum客户端配置文件：12345678910111213vim /etc/yum.conf：为所有仓库提供公共配置[main]语句块名称cachedir=/var/cache/yum/$basearch/$releasever #缓存文件夹keepcache=0 #1表示rpm包保存 0表示不保存debuglevel=2 #调试一般不用管logfile=/var/log/yum.log #yum的日志exactarch=1obsoletes=1gpgcheck=1plugins=1installonly_limit=5 #同时可装5个包bugtracker_url=http://bugs.centos.org/set_project.php?project_id=19&amp;ref=http://bugs.centos.org/bug_report_page.php?category=yumdistroverpkg=centos-release /etc/yum.repos.d/*.repo：为仓库的指向提供配置 后缀必须为.repo 仓库指向的定义：1234567891011[repositoryID] #第一行用一个单词不允许出现空格名字可以随意name=Some name for this repository #描述语句baseurl=url://path/to/repository/第二行路径 #repodata的父目录就是路径enabled=&#123;1|0&#125; #0表示禁用1表示启用gpgcheck=&#123;1|0&#125; #第三行是否检查包的完整性0表示不检查gpgkey=URLenablegroups=&#123;1|0&#125;failovermethod=&#123;roundrobin|priority&#125;# roundrobin：意为随机挑选，默认值# priority:按顺序访问cost= 默认为1000 yum源阿里云repo文件 CentOS系统的yum源 阿里云 清华大学 EPEL的yum源 阿里云 yum 命令1、显示仓库列表 1yum repolist [all|enabled|disabled] 2、显示程序包 123yum listyum list [all | glob_exp1] [glob_exp2] […]yum list &#123;available|installed|updates&#125; [glob_exp1] […] 3、安装程序包 12yum install package1 [package2] […]yum reinstall package1 [package2] […] (重新安装) 4、升级程序包 12yum update [package1] [package2] […]yum downgrade package1 [package2] […] (降级) 5、检查可用升级 1yum check-update 6、卸载程序包 1yum remove | erase package1 [package2] […] 7、查看程序包information 1yum info […] 8、查看指定的特性(可以是某文件)是由哪个程序包所提供 1yum provides | whatprovides feature1 [feature2] […] 9、清理本地缓存 12清除/var/cache/yum/$basearch/$releasever缓存yum clean [ packages | metadata | expire-cache | rpmdb | plugins | all ] 10、构建缓存 1yum makecache 11、搜索:以指定的关键字搜索程序包名及summary信息 1yum search string1 [string2] […] 12、查看指定包所依赖的capabilities 1yum deplist package1 [package2] […] 13、查看yum事务历史 123456yum history [info|list|packages-list|packages-info|summary|addon-info|redo|undo|rollback|new|sync|stats]yum historyyum history info 6yum history undo 6 14、日志 1/var/log/yum.log 15、安装及升级本地程序包 1234yum localinstall rpmfile1 [rpmfile2] […](用install替代)yum localupdate rpmfile1 [rpmfile2] […](用update替代) 16、包组管理的相关命令 12345yum groupinstall group1 [group2] […]yum groupupdate group1 [group2] […]yum grouplist [hidden] [groupwildcard] […]yum groupremove group1 [group2] […]yum groupinfo group1 […] yum的命令行选项： ​ –nogpgcheck：禁止进行gpg check ​ -y: 自动回答为“yes” ​ -q：静默模式 ​ –disablerepo=repoidglob：临时禁用此处指定的repo ​ –enablerepo=repoidglob：临时启用此处指定的repo ​ –noplugins：禁用所有插件 系统光盘作为本地yum仓库(1) 挂载光盘至某目录，例如/mnt/cdrom1mount /dev/cdrom /mnt/cdrom (2) 创建配置文件12345[base]name=base.repobaseurl=file:///mnt/cdromgpgcheck=0enabled=1]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>rpm</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之grep]]></title>
    <url>%2F2018%2F03%2F31%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bgrep%2F</url>
    <content type="text"><![CDATA[&ensp;&ensp;&ensp;&ensp;grep: Global search REgular expression and Print out the line,是一款文本过滤工具。&ensp;&ensp;&ensp;&ensp;作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行。&ensp;&ensp;&ensp;&ensp;模式：由正则表达式字符及文本字符所编写的过滤条件。&ensp;&ensp;&ensp;&ensp;正则表达式REGEXP： Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不表示字符字面意义，而表示控制或通配的功能。 正则表达式分两类： 基本正则表达式： BRE 扩展正则表达式： EREgrep工具支持基本正则表达式，egrep工具支持扩展的正则表达式，并且grep -E = egrep. grep语法grep [OPTIONS] PATTERN [FILE…] -v: 显示不被pattern匹配到的行 -i: 忽略字符大小写 -n： 显示匹配的行号 -c: 统计匹配的行数 -o: 仅显示匹配到的字符串 -q: 静默模式，不输出任何信息 -A #: after, 后#行 -B #: before, 前#行 -C #： context, 前后各#行 -e：实现多个选项间的逻辑or关系 -w：匹配整个单词 -E：使用ERE -F：相当于fgrep，不支持正则表达式 -f file: 根据模式文件处理 基本正则表达式元字符字符匹配 . &ensp; &ensp;&ensp;&ensp;匹配任意单个字符 1234[root@localhost data]#grep "r..t" /etc/passwd root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologin [] &ensp; &ensp;&ensp;匹配指定范围内的任意单个字符，示例:[wang] [0-9] [a-z] [a-zA-Z] [^] &ensp;&ensp;匹配指定范围外的任意单个字符 [:alnum:] 字母和数字 [:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z [:lower:] 小写字母,亦即 a-z [:upper:] 大写字母,亦即 A-Z [:blank:] 空白字符（空格和制表符） [:space:] 水平和垂直的空白字符（比[:blank:]包含的范围广） [:cntrl:] 不可打印的控制字符（退格、删除、警铃…） [:digit:] 十进制数字 [:xdigit:] 十六进制数字 [:graph:] 可打印的非空白字符 [:print:] 可打印字符 [:punct:] 标点符号例 12345[root@localhost data]#ifconfig ens33 | grep netmask | grep "[[:digit:]]." inet 192.168.183.132 netmask 255.255.255.0 broadcast 192.168.183.255等价于[root@localhost data]#ifconfig ens33 | grep netmask | grep "[0-9]." inet 192.168.183.132 netmask 255.255.255.0 broadcast 192.168.183.255 次数匹配用在要指定次数的字符后面，用于指定前面的字符要出现的次数123456789* 匹配前面的字符任意次，包括0次 贪婪模式：尽可能长的匹配.默认正则表达式为贪婪模式 .* 任意长度的任意字符 \? 匹配其前面的字符0或1次 \+ 匹配其前面的字符至少1次 \&#123;n\&#125; 匹配前面的字符n次 \&#123;m,n\&#125; 匹配前面的字符至少m次，至多n次 \&#123;,n\&#125; 匹配前面的字符至多n次 \&#123;n,\&#125; 匹配前面的字符至少n次正则表达式 例:12345678910111213141516[root@localhost data]#ifconfig ens33 | grep "[0-9]\&#123;1,3\&#125;" ens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.183.132 netmask 255.255.255.0 broadcast 192.168.183.255 inet6 fe80::bf41:5d04:86fa:37c9 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:30:79:38 txqueuelen 1000 (Ethernet) RX packets 7676 bytes 850492 (830.5 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 6678 bytes 2198697 (2.0 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0只显示ifconfig ens33 的ip[root@localhost data]#ifconfig ens33 | grep -o "[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;"192.168.183.132255.255.255.0192.168.183.255 位置锚定定位出现的位置12345678* ^ 行首锚定，用于模式的最左侧 * $ 行尾锚定，用于模式的最右侧 * ^PATTERN$ 用于模式匹配整行 * ^$ 空行 * ^[[:space:]]*$ 空白行* \&lt; 或 \b 词首锚定，用于单词模式的左侧 * \&gt; 或 \b 词尾锚定，用于单词模式的右侧 * \&lt;PATTERN\&gt; 匹配整个单词正则表达式 1234567例:只显示/etc/fstab非空的行[root@localhost data]#cat /etc/fstab | grep -v "^#" | grep -v "^$"UUID=d33ffb51-004a-4c4d-ac00-c40b9e2c2920 / xfs defaults 0 0UUID=7d1b5c8d-8054-4496-befe-267963e07605 /boot xfs defaults 0 0UUID=7556e4a8-128e-457f-99f7-3f1ccf517952 /data xfs defaults 0 0UUID=152e9015-e93a-44f9-8c7d-65fe67fb5201 swap swap defaults 0 0 12345显示以root为单词词首的行[root@localhost ~]#grep "\&lt;root" /etc/passwdroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin _分组_\(\) 将一个或多个字符捆绑在一起，当作一个整体处理，如： \(root\)\+ 分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命名方式为: \1, \2, \3, … \1 表示从左侧起第一个左括号以及与之匹配右括号之间的模式所匹配到的字符 123\(string1\+\(string2\)*\)\1 ： string1\+\(string2\)*\2 ： string2 后向引用：引用前面的分组括号中的模式所匹配字符(结果)， 而非模式本身 12345[root@localhost ~]#cat f1123ab123xxy123234xxx567[root@localhost ~]#cat f1 | grep "\([0-9]\)\&#123;3\&#125;.*\1"123ab123xxy123 或者：\|示例： a\|b: a或b C\|cat: C或cat \(C\|c\)at:Cat或cat 扩展的正则表达式egrep [OPTIONS] PATTERN [FILE…] 字符匹配 . 任意单个字符 [] 指定范围的字符 [^] 不在指定范围的字符基本和正则表达式相同 次数匹配12345678* 匹配前面的字符任意次，包括0次 .* 任意长度的任意字符 ? 匹配其前面的字符0或1次 + 匹配其前面的字符至少1次 &#123;n&#125; 匹配前面的字符n次 &#123;m,n&#125; 匹配前面的字符至少m次，至多n次 &#123;,n&#125; 匹配前面的字符至多n次 &#123;n,&#125; 匹配前面的字符至少n次正则表达式 位置锚定扩展正则表达式的位置锚定和基本正则表达式相同。 _分组_( )的内容不需要用\转义 或者：|示例： a|b: a或b C|cat: C或cat (C|c)at:Cat或cat 练习 利用df和grep，取出磁盘各分区利用率，并从大到小排序 1df | grep /dev/sd | grep -o "[0-9]\+%" | grep -o "[0-9]\+" |sort -nr 1df | grep -E /dev/sd | grep -oE "[0-9]+%" | grep -Eo "[0-9]+" |sort -nr 显示ifconfig命令结果中所有IPv4地址 1ifconfig ens33 | grep -o "\&lt;\(\([0-1][0-9]\?\&#123;2\&#125;\|2[0-4][0-9]\|25[0-5]\)\.\)\&#123;3\&#125;\([0-1][0-9]\?\&#123;2\&#125;\|2[0-4][0-9]\|25[0-5]\)\&gt;" 1ifconfig ens33 | egrep -o "\&lt;(([0-1][0-9]?&#123;2&#125;|2[0-4][0-9]|25[0-5])\.)&#123;3&#125;([0-1][0-9]?&#123;2&#125;|2[0-4][0-9]|25[0-5])\&gt;" 找出/etc/passwd用户名和shell同名的行 1grep "^\([[:alnum:]]\&#123;1,\&#125;\):.*\1$" /etc/passwd 1grep -E "^([[:alnum:]]&#123;1,&#125;):.*\1$" /etc/passwd 手机号 1grep -o "1[34578][0-9]\&#123;9\&#125;" 1grep -Eo "1[34578][0-9]&#123;9&#125;" 使用egrep取出/etc/rc.d/init.d/functions中其基名 1echo /etc/rc.d/init.d/functions/ | grep -o "[^/]\+/\?$" | grep -o ".*[^/]" 1echo /etc/rc.d/init.d/functions/ | egrep -o "[^/]+/?$" | egrep -o ".*[^/]" 显示CentOS7的/etc/grub2.cfg文件中，至少以一个空白字符开头的且后面有非空白字符的行 1grep "^[[:space:]]\+[^[:space:]]" /etc/grub2.cfg 1grep -E "^[[:space:]]+[^[:space:]]" /etc/grub2.cfg]]></content>
      <categories>
        <category>文本工具</category>
      </categories>
      <tags>
        <tag>grep</tag>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅议linux中的硬链接和软链接]]></title>
    <url>%2F2018%2F02%2F10%2F%E6%B5%85%E8%AE%AElinux%E4%B8%AD%E7%9A%84%E7%A1%AC%E9%93%BE%E6%8E%A5%E5%92%8C%E8%BD%AF%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[链接文件的概念&ensp;&ensp;&ensp;&ensp;Linux中的链接文件就相当于是Windows中的快捷方式，通过链接文件可以访问到链接指向的源文件。但是Linux下的链接文件和Windows中的快捷方式还是有一定的区别。Linux中有两种链接文件分别为硬链接和软链接（也称为符号链接）。在介绍链接文件之前先要介绍一下Linux文件系统中的inode。 节点的概念&ensp;&ensp;&ensp;&ensp;我们都知道文件数据都是储存在硬盘的”块”区域中。那么很显然，我们还必须找一块区域储存文件的元数据信息，比如文件的创建者、文件的创建时间、文件的大小等等，这种存储文件元数据信息的区域就叫做inode，中文译名为”索引节点” Inode（索引节点）包含有关文件的信息（元数据），具体有如下内容： 文件类型，权限，UID，GID 链接数（指向这个文件名路径名称个数） 该文件的大小和不同的时间戳 指向磁盘上文件的数据块指针 有关文件的其他数据 我们可以使用stat命令来查看某个文件的inode的信息：12345678910[root@localhost ~]#stat /data/f1 File: ‘/data/f1’ Size: 0 Blocks: 0 IO Block: 4096 regular empty fileDevice: 803h/2051d Inode: 67 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2018-09-29 10:34:06.156131723 +0800Modify: 2018-09-29 10:34:06.156131723 +0800Change: 2018-09-29 10:34:06.156131723 +0800 Birth: - 注意：文件名是不存在inode中的！！! 查看每个硬盘分区的inode总数和使用的数量，可以用df -i 来查看:1234567891011[root@localhost ~]#df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/sda2 26214400 122731 26091669 1% /devtmpfs 229181 397 228784 1% /devtmpfs 233163 1 233162 1% /dev/shmtmpfs 233163 881 232282 1% /runtmpfs 233163 16 233147 1% /sys/fs/cgroup/dev/sda1 524288 327 523961 1% /boot/dev/sda3 15728640 4 15728636 1% /datatmpfs 233163 9 233154 1% /run/user/42tmpfs 233163 1 233162 1% /run/user/0 空间满了和inode用光了都报No space left on device 下图就是磁盘空间占满了提示：12345678910111213[root@localhost data]#dd if=/dev/zero of=/boot/bigfile bs=1M count=860dd: error writing ‘/boot/bigfile’: No space left on device850+0 records in849+0 records out890306560 bytes (890 MB) copied, 2.25818 s, 394 MB/s[root@localhost data]#df -h /dev/sda1Filesystem Size Used Avail Use% Mounted on/dev/sda1 1014M 1014M 336K 100% /boot[root@localhost data]#df -i /dev/sda1 Filesystem Inodes IUsed IFree IUse% Mounted on/dev/sda1 1184 328 856 28% /boot 下图就是inode用光的提示：12345678[root@localhost dir1]#df -i /dev/sda1Filesystem Inodes IUsed IFree IUse% Mounted on/dev/sda1 524288 524288 0 100% /boot也会报touch: cannot touch ‘f524284’: No space left on devicetouch: cannot touch ‘f524285’: No space left on devicetouch: cannot touch ‘f524286’: No space left on device &ensp;&ensp;每个inode都有一个号码，操作系统用inode号码来识别不同的文件。对于系统来说，文件名只是inode号码便于识别的别称和绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步： ​ 首先，系统找到这个文件名对应的inode号码； ​ 其次，通过inode号码，获取inode信息； ​ 最后，根据inode信息，找到文件所在的block，读出数据。 使用ls -i命令，可以看出文件名对应的inode号码：12[root@localhost ~]#ls -i /data/f167 /data/f1 硬链接&ensp;&ensp;&ensp;&ensp;一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Linux系统允许多个文件名指向同一个inode号码。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名;删除一个文件名，不影响另一个文件名的访问。这种情况就被称为:硬链接”(hard link)。可以通过ln命令来创建硬链接：&ensp;&ensp;&ensp;&ensp;ln&ensp; 源文件&ensp; 目标文件 12345678910[root@localhost data]#ls2.txt f1[root@localhost data]#ln 2.txt 22.txt[root@localhost data]#ls22.txt 2.txt f1[root@localhost data]#ll -itotal 868 -rw-r--r--. 2 root root 22 Sep 25 15:41 22.txt68 -rw-r--r--. 2 root root 22 Sep 25 15:41 2.txt67 -rw-r--r--. 1 root root 0 Sep 25 14:16 f1 创建文件时链接数递增 123456[root@localhost data]#ll -i f167 -rw-r--r--. 1 root root 0 Sep 29 10:34 f1[root@localhost data]#ln f1 f11[root@localhost data]#ll -i f1 f1167 -rw-r--r--. 2 root root 0 Sep 29 10:34 f167 -rw-r--r--. 2 root root 0 Sep 29 10:34 f11 不能跨越驱动器或分区 12[root@localhost data]#ln /data/f2 /root/f22ln: failed to create hard link ‘/root/f22’ =&gt; ‘/data/f2’: Invalid cross-device link 不支持文件夹 12[root@localhost data]#ln dir1 dir11ln: ‘dir1’: hard link not allowed for directory 软链接&ensp;&ensp;&ensp;&ensp;除了硬链接以外，还有一种特殊情况。文件A和文件B的incode号码虽然不一样，但是文件A的内容就是文件B的路径。读取文件A时系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时文件A就称为文件B的”软链接”(soft link)或者”符号链接”(symbolic link)可以通过ln -s命令来创建软链接：&ensp;&ensp;&ensp;&ensp;ln -s &ensp;源文件或目录&ensp; 目标文件或目录 123456789101112131415[root@localhost data]#lltotal 8-rw-r--r--. 2 root root 22 Sep 25 15:41 22.txt-rw-r--r--. 2 root root 22 Sep 25 15:41 2.txt-rw-r--r--. 1 root root 0 Sep 25 14:16 f1[root@localhost data]#ln -s 2.txt 2.txt-link[root@localhost data]#lltotal 8-rw-r--r--. 2 root root 22 Sep 25 15:41 22.txt-rw-r--r--. 2 root root 22 Sep 25 15:41 2.txtlrwxrwxrwx. 1 root root 5 Sep 25 16:01 2.txt-link -&gt; 2.txt[root@localhost data]#cat 2.txt学习使我快乐！[root@localhost data]#cat 2.txt-link学习使我快乐！ 指向的是另一个文件的路径 其大小为指向的路径字符串的长度 不增加或减少目标文件inode的引用计数 硬链接和软链接的区别 是不是同一个文件? 这是根本的原因 硬链接本质上是一个文件，只是有多个名字。 软链接不是同一个文件 能不能跨分区？ 硬链接不能跨分区 软链接可以跨分区 链接数是否增长？ 硬链接的链接数会增加 软链接的链接数不会增加 inode Number 是否相同 硬链接的inode number完全一样 软链接的inode number不一样 原始文件删除，链接文件可否访问？ 硬链接：原始文件与链接文件是平级关系，原始文件删除，链接文件可以继续访问。 软链接：原始文件删除，软链接就找不到路径，无法访问 大小是否一样 硬链接的大小就是存储原始文件的大小 软链接的大小就是它指向路径的大小 支持目录 硬链接不支持目录 软链接支持目录 相对路径 硬链接：相对路径是相对当前目录的路径 软链接：相对路径是相对软链接的路径]]></content>
      <categories>
        <category>链接</category>
      </categories>
      <tags>
        <tag>Inode</tag>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[标准IO和管道]]></title>
    <url>%2F2018%2F01%2F06%2F%E7%AE%A1%E9%81%93%E5%92%8C%E6%A0%87%E5%87%86IO%2F</url>
    <content type="text"><![CDATA[标准输入和输出程序：指令+数据 读入数据：Input 输出数据：Output 打开的文件都有一个fd: file descriptor (文件描述符)123456[root@centos7 ~]#ll /proc/$$/fdtotal 0lrwx------ 1 root root 64 Oct 28 14:43 0 -&gt; /dev/pts/2lrwx------ 1 root root 64 Oct 28 14:43 1 -&gt; /dev/pts/2lrwx------ 1 root root 64 Oct 28 14:43 2 -&gt; /dev/pts/2lrwx------ 1 root root 64 Oct 28 19:33 255 -&gt; /dev/pts/2 Linux给程序提供三种I/O设备标准输入（STDIN） －0 默认接受来自键盘的输入标准输出（STDOUT）－1 默认输出到终端窗口标准错误（STDERR）－2 默认输出到终端窗口 I/O重定向改变文件保存的默认位置 标准输出和错误输出重定向格式: 命令 操作符号 文件名 支持的操作符号包括:> 把STDOUT重定向到文件12345[root@CentOS6 ~]#ls /datalost+found[root@CentOS6 ~]#ls /data &gt; f1.txt #f1为一空文件[root@CentOS6 ~]#cat f1.txtlost+found 2&gt; 把STDERR重定向到文件12345[root@CentOS6 ~]#ls /errorls: cannot access /error: No such file or directory[root@CentOS6 ~]#ls /error 2&gt; f2.txt[root@CentOS6 ~]#cat f2.txt ls: cannot access /error: No such file or directory &amp;&gt; 把所有输出重定向到文件12345[root@CentOS6 ~]#ls /data /error &amp;&gt;f3.txt[root@CentOS6 ~]#cat f3.txt ls: cannot access /error: No such file or directory/data:lost+found > 文件内容会被覆盖1234567[root@CentOS6 ~]#cat f1.txt lost+found[root@CentOS6 ~]#echo 123123[root@CentOS6 ~]#echo 123 &gt;f1.txt[root@CentOS6 ~]#cat f1.txt 123 >&gt; 原有内容基础上，追加内容12345[root@CentOS6 ~]#ls /data &gt;f1.txt [root@CentOS6 ~]#echo 123 &gt;&gt;f1.txt [root@CentOS6 ~]#cat f1.txt lost+found123 2&gt; 覆盖重定向错误输出数据流1234567[root@CentOS6 ~]#cat f2.txt ls: cannot access /error: No such file or directory[root@CentOS6 ~]#cdm-bash: cdm: command not found[root@CentOS6 ~]#cdm 2&gt; f2.txt [root@CentOS6 ~]#cat f2.txt -bash: cdm: command not found 2&gt;&gt; 追加重定向错误输出数据流1234[root@centos7 ~]#ls /error 2&gt;&gt; f2.txt[root@CentOS6 ~]#cat f2.txt -bash: cdm: command not foundls: cannot access /error: No such file or directory set –C 禁止将内容覆盖已有文件,但可追加1234567891011[root@CentOS6 ~]#cat f1.txt lost+found123[root@CentOS6 ~]#set -C[root@CentOS6 ~]#echo 345 &gt; f1.txt -bash: f1.txt: cannot overwrite existing file[root@CentOS6 ~]#echo 345 &gt;&gt; f1.txt [root@CentOS6 ~]#cat f1.txt lost+found123345 | file 强制覆盖123[root@CentOS6 ~]#echo 345 &gt;|f1.txt [root@CentOS6 ~]#cat f1.txt 345 set +C 允许覆盖1234[root@CentOS6 ~]#set +C[root@CentOS6 ~]#echo 123&gt;f1.txt[root@CentOS6 ~]#cat f1.txt 123 标准输出和错误输出各自定向至不同位置COMMAND &gt; /path/to/file.out 2&gt; /path/to/error.out123456[root@CentOS6 ~]#ls /data /error &gt;f1.txt 2&gt;f2.txt[root@CentOS6 ~]#cat f1.txt /data:lost+found[root@CentOS6 ~]#cat f2.txt ls: cannot access /error: No such file or directory 合并标准输出和错误输出为同一个数据流进行重定向 &amp;&gt; 覆盖重定向 &amp;&gt;&gt; 追加重定向 COMMAND &gt; /path/to/file.out 2&gt;&amp;1 （顺序很重要） COMMAND &gt;&gt; /path/to/file.out 2&gt;&amp;1 ()：合并多个程序的STDOUT( cal 2007 ; cal 2008 ) &gt; all.txt 重定向的实验：123456789101112131415161718192021222324252627282930313233343536373839404142434445ll a.txt b.txt 将输出一条标准输出和一条标准错误。如下：[root@CentOS6 ~]#ll a.txt-rw-r--r--. 1 root root 2 Oct 28 09:04 a.txt #这为内容A[root@CentOS6 ~]#ll b.txtls: cannot access b.txt: No such file or directory #这为内容B下面讨论各种变形的输出结果和原因：1、[root@CentOS6 ~]#ll a.txt b.txt 1&gt;file 2&gt;&amp;1[root@CentOS6 ~]#cat filels: cannot access b.txt: No such file or directory-rw-r--r--. 1 root root 2 Oct 28 09:04 a.txt file内容A和B 屏幕内容无 （因为标准输出定向到文件，标准错误定向到标准输出，所以也定向到文件）2、[root@CentOS6 ~]#ll a.txt b.txt 2&gt;&amp;1 1&gt;filels: cannot access b.txt: No such file or directory[root@CentOS6 ~]#cat file -rw-r--r--. 1 root root 2 Oct 28 09:04 a.txtfile内容A 屏幕输出B （因为标准错误重定向到了标准输出即屏幕上输出，标准输出定向到文件）3、[root@CentOS6 ~]#ll a.txt b.txt 2&gt;file 1&gt;&amp;2[root@CentOS6 ~]#cat file ls: cannot access b.txt: No such file or directory-rw-r--r--. 1 root root 2 Oct 28 09:04 a.txt file内容A和B 屏幕内容无（因为标准错误定向到文件，标准输出定向到标准错误，所以也定向到文件）4、[root@CentOS6 ~]#ll a.txt b.txt 1&gt;&amp;2 2&gt;file-rw-r--r--. 1 root root 2 Oct 28 09:04 a.txt[root@CentOS6 ~]#cat file ls: cannot access b.txt: No such file or directory file内容A 屏幕输出B（因为标准输出定向到了标准错误即屏幕，标准错误定向到文件）5、[root@CentOS6 ~]#ll a.txt b.txt 1&gt;file 1&gt;&amp;2ls: cannot access b.txt: No such file or directory-rw-r--r--. 1 root root 2 Oct 28 09:04 a.txt[root@CentOS6 ~]#cat file [root@CentOS6 ~]# file内容无 屏幕内容A和B （因为标准输出定向到文件，标准输出又定向的标准错误即屏幕，覆盖了1&gt;file，所以file内容无）6、[root@CentOS6 ~]#ll a.txt b.txt 2&gt;file 2&gt;&amp;1ls: cannot access b.txt: No such file or directory-rw-r--r--. 1 root root 2 Oct 28 09:04 a.txt[root@CentOS6 ~]#cat file [root@CentOS6 ~]# file内容无 屏幕内容A和B （因为标准错误定向到文件，标准错误又定向到标准输出即屏幕，覆盖了2&gt;file，所以file内容无） 输入重定向使用 &lt; 来重定向标准输入 某些命令能够接受从文件中导入的STDIN 12tr 'a-z' 'A-Z'&lt; /etc/issue # 该命令会把/etc/issue中的小写字符都转换成写写字符tr -d 'abc' &lt; /etc/fstab 删除fstab文件中的所有abc中任意字符 键盘输入 1234cat &gt; filemagewangxiaochun按ctrl+d离开 可以使用文件来代替键盘的输入 1Cat &gt; filea &lt; fileb #把fileb的文件内容重定向输入到filea中 把多行发送给STDIN使用“&lt;&lt;终止词”命令从键盘把多行重导向给STDIN,直到 终止词 位置的所有文本都发送给STDIN有时被称为就地文本（heretext） 12345678mail -s "Please Call" &lt;&lt;END&gt; Hi,&gt;&gt; Please give me a call when you get in. We may need&gt; to do some maintenance on server1.&gt;&gt; Details when you're on-site&gt; END tr命令转换和删除字符 语法： tr [OPTION]… SET1 [SET2]选项：​ -c 或 ——complerment：取代所有不属于第一字符集的字符；​ -d 或 ——delete：删除所有属于第一字符集的字符；​ -s 或 –squeeze-repeats：把连续重复的字符以单独一个字符表示；​ -t 或 –truncate-set1：先删除第一字符集较第二字符集多出的字符。 [:alnum:]：字母和数字[:alpha:]：字母[:cntrl:]：控制（非打印）字符[:digit:]：数字[:graph:]：图形字符[:lower:]：小写字母[:print:]：可打印字符[:punct:]：标点符号[:space:]：空白字符[:upper:]：大写字母[:xdigit:]：十六进制字符 实例：​ # echo “TANK” |tr A-Z a-z #大写字母转小写​ # echo “hello 123 world 456” | tr -d ‘0-9’ #删除字符串中的数字​ # cat text | tr ‘\t’ ‘ ‘ #将制表符转换成空格​ # echo “aa.,a 1 b#$bb 2 c*/cc 3 ddd 4” | tr -dc ‘0-9 \n’ # 删除除数字外的字符​ # tr ‘[:lower:]’ ‘[:upper:]’ #将小写字符转换成大写字符 管道连接程序，实现将前一个命令的输出直接定向后一个程序当作输入数据流管道左边的命令必须要有标准输出的功能，管道右边的命令一道要有标准输入功能的否者没有意义。 管道（使用符号“|”表示）用来连接命令命令1 | 命令2 | 命令3 | … 将命令1的STDOUT发送给命令2的STDIN，命令2的STDOUT发送到命令3的STDINSTDERR默认不能通过管道转发，可利用2&gt;&amp;1 或 |&amp; 实现最后一个命令会在当前shell进程的子shell进程中执行用来组合多种工具的功能ls | tr ‘a-z’ ‘A-Z123456less ：一页一页地查看输入 ls -l /etc | lessmail： 通过电子邮件发送输入 echo "test email" | mail -s "test" user@example.com lpr：把输入发送给打印机 echo "test print" | lpr -P printer_name 重定向到多个目标（tee）命令1 | tee [-a ] 文件名 | 命令2把命令1的STDOUT保存在文件中，做为命令2的输入-a 追加 使用： 保存不同阶段的输出复杂管道的故障排除同时查看和记录输出 练习 将/etc/issue文件中的内容转换为大写后保存至/tmp/issue.out文件中 1cat /etc/issue | tr "[a-z]" "[A-Z]" &gt;/tmp/issue.out 将当前系统登录用户的信息转换为大写后保存至/tmp/who.out文件中 1who | tr "[a-z]" "[A-Z]" &gt;/tmp/who.out 一个linux用户给root发邮件，要求邮件标题为”help”，邮件正文如下：Hello, I am 用户名,The system version is here,pleasehelp me to check it ,thanks! 操作系统版本信息 12345mail -s "root" &lt;&lt;EOF&gt; hello,i am $user&gt; The system version is here,please help me to check it,thanks!&gt;cat /etc/centos-release&gt;EOF 将/root/下文件列表，显示成一行，并文件名之间用空格隔开 1ls /root | tr "\n" " " 计算1+2+3+..+99+100的总和 1echo &#123;1..100&#125; | tr -s " " "+" | bc 删除Windows文本文件中的‘^M’字符 1tr -d "\15" win.txt 处理字符串“xt.,l 1 jr#!$mn2 c*/fe3 uz4”，只保留其中的数字和空格 123echo "xt.,l 1 jr#bcmn2 c*/fe3 uz4" | tr -d "[[:alpha:]]" | tr -d "[[:punct:]]" 或者echo "xt.,l 1 jr#bcmn2 c*/fe3 uz4" |tr -dc "[:digit:][:space:]" 将PATH变量每个目录显示在独立的一行 1echo $PATH |tr -s ":" "\n" 将指定文件中0-9分别替代成a-j 123先创建文件touch f1 给f1 vim 输入0-9 cat f1 | tr "[0-9]" "[a-j]" 将文件/etc/centos-release中每个单词（由字母组成）显示在独立一行，并无空行 1cat /etc/centos-release | tr -s " " "\n"]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
        <tag>IO</tag>
        <tag>管道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Linux basics]]></title>
    <url>%2F2017%2F12%2F16%2FHello%20Linux%20basics%2F</url>
    <content type="text"><![CDATA[计算机硬件组成&ensp;&ensp;&ensp;&ensp;根据冯·诺依曼体系结构，我们知道现代计算机硬件由控制器、运算器、存储器、输入设备和输出设备五大部分组成。 ​ 控制器：控制器是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，并根据具体要求进行控制、调度程序、数据、地址，协调计 算机各个部分工作，协调计算机各部分工作及内存、IO设备等的访问 ​ 运算器：对数据进行各种算数运算和逻辑运算也就是对数据进行加工，在现代计算机系统中将控制器和运算器合并在一起组成CPU。 ​ 存储器：存储器是存储程序、数据和各种信号、命令等信息，并在需要的时候提供这些信息；在现代计算机系统中就是内存。 ​ 输入设备:就是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机；比如键盘、鼠标等 ​ 输出设备：就是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息进行输出；比如显示器、打印机等 Linux发行版 slackware: SUSE Linux Enterprise Server (SLES) OpenSuse桌面 debian: ubuntu mint redhat: RedHat Enterprise Linux:红帽推出的收费的技术支持和更新的linux发行版，适用于企业服务器版Linux，稳定、安全。 CentOS:centos可以说是社区维护的RHEL克隆版本，免费使用。 Fedora:由社区维护的适用于个人桌面的Linux发行版 ArchLinux: 轻量简洁Gentoo: 极致性能，不提供传统意义的安装程序LFS: Linux From scratch 自制LinuxAndroid: kernel+busybox（工具集）+java虚拟机 Linux的哲学思想 一切都是一个文件（包括硬件) 小型，单一用途的程序 链接程序，共同完成复杂的任务 避免令人困惑的用户界面 配置数据存储在文本中命令echo主要是用于显示信息的1234567891011121314151617181920212223242526[root@CentOS7 data]#man echoECHO(1) User Commands ECHO(1)NAME echo - display a line of textSYNOPSIS echo [SHORT-OPTION]... [STRING]... echo LONG-OPTIONDESCRIPTION Echo the STRING(s) to standard out‐ put. -n do not output the trailing newline -e enable interpretation of backslash escapes -E disable interpretation of backslash escapes (default) --help display this help and exit --version 下面说明一些重要参数： -E （默认）不支持\解释功能 -n 不自动换行 -e 启用\字符的解释功能 启用命令选项-e，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出 \a 发出警告声 \b 退格键 \c 最后不加上换行符号 \n 换行且光标移至行首 \r 回车，即光标移至行首，但不换行 \t 插入tab \ \ 插入\字符 \0nnn 插入nnn（八进制）所代表的ASCII字符 \xHH 插入HH（十六进制）所代表的ASCII数字（man 7 ascii） date主要是显示操作系统的时间1234[root@CentOS7 data]#date --helpUsage: date [OPTION]... [+FORMAT] or: date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]]Display the current time in the given FORMAT, or set the system date 下面说明一些重要参数： -d 显示字符串所指的日期与时间,如果不指定，默认为当前系统时间。 12[root@CentOS7 data]#dateSun Sep 23 15:12:28 CST 2018 -s 根据字符串指定的日期、时间设定为当前的系统时间。 -d @ 把秒转化成具体的年月日，从1970年1月1号00：00:00算起12[root@CentOS7 data]#date -d @1537687300Sun Sep 23 15:21:40 CST 2018 如果需要以指定的格式显示日期或者日期，可以使用date “+”开头的字符串指定其格式，最常用的格式如下:%n : 下一行%t : 跳格%H : 小时(00-23)%M : 分钟(00-59)%p : 显示本地 AM 或 PM%r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M)%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数%S : 秒(00-60)%T : 直接显示时间 (24 小时制)%X : 相当于 %H:%M:%S%Z : 显示时区%d : 日 (01-31)%D : 直接显示日期 (mm/dd/yy))%m : 月份 (01-12)%Y : 完整年份 (0000-9999)%F : full date;相当于年月日12[root@CentOS7 data]#date +"%F %T"2018-09-23 15:33:21 history主要显示历史命令记录，或者下达历史纪录中的指令123456[root@CentOS7 data]#help historyhistory: history [-c] [-d offset] [n] or history -anrw [filename] or history -ps arg [arg...] Display or manipulate the history list. Display the history list with line numbers, prefixing each modified entry with a `*'. An argument of N lists only the last N entries. 其中一些重要的参数：n 数字,表示要列出最近的 n 条历史-c ：清空命令历史-a ：追加本次会话新执行的命令历史列表至历史文件-r ：读历史文件附加到历史列表-w ：保存历史列表到指定的历史文件-n: 读历史文件中未读过的行到历史列表-p: 展开历史参数成多行，但不存在历史列表中-s: 展开历史参数成一行，附加在历史列表后1234567[root@CentOS7 ~]#cat .bash_history exithistoryuname -rcat /etc/centos-releasehistoryexit 上图可以查看文件中的历史 Bash的快捷键 Ctrl + l 清屏，相当于clear命令 Ctrl + o 执行当前命令，并重新显示本命令 Ctrl + s 阻止屏幕输出，锁定 Ctrl + q 允许屏幕输出 Ctrl + c 终止命令 Ctrl + z 挂起命令 Ctrl + a 光标移到命令行首，相当于Home Ctrl + e 光标移到命令行尾，相当于End Ctrl + f 光标向右移动一个字符，相当于右方向键 Ctrl + b 光标向左移动一个字符，相当于左方向键 Alt + f 光标向右移动一个单词尾 Alt + b 光标向左移动一个单词首 Ctrl + x x光标在命令行首和光标之间移动 Ctrl + u 从光标处删除至命令行首 Ctrl + k 从光标处删除至命令行尾 Alt + r 删除当前整行 Ctrl + w 从光标处向左删除至单词首 Alt + d 从光标处向右删除至单词尾 Ctrl + d 删除光标处的一个字符 Ctrl + h 删除光标前的一个字符 Ctrl + y 将删除的字符粘贴至光标后 Alt + c 从光标处开始向右更改为首字母大写的单词 Alt + u 从光标处开始，将右边一个单词更改为大写 Alt + l 从光标处开始，将右边一个单词更改为小写 Ctrl + t 交换光标处和之前的字符位置 Alt + t 交换光标处和之前的单词位置 Alt + N 提示输入指定字符后，重复显示该字符N次]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
</search>
